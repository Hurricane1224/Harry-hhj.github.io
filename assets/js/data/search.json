[ { "title": "Config ccache", "url": "/posts/Config-ccache/", "categories": "Tutorial, ccache", "tags": "install, c/c++, ccache", "date": "2021-11-03 21:15:00 +0800", "snippet": "Ccache这篇博客介绍一个小工具 ccache ，可以提高再次编译的速度。其原理是通过吧项目的源文件用 ccache 编译器编译，然后缓存编译生成的信息，从而在下一次编译时，利用这个缓存加快编译的速度，目前支持的语言有 C 、 C++ 、 Objective-C 、 Objective-C++ ，如果找不到 ccache 编译器，还是会选择系统默认的编译器来编译源文件。接下来讲述 ccache 的利用过程。一、安装这里介绍 Ubuntu 的安装方法。首先通过 apt 安装：sudo apt install ccache安装完后我们不能直接使用，需要先进行配置:sudo gedit ~/.bashrc在新打开的文档末尾回车，添加如下语句，注意 &amp;lt;username&amp;gt; 要改成你的用户名。export CCACHE_DIR=&quot;/home/&amp;lt;username&amp;gt;/.ccache&quot;export CC=&quot;ccache gcc&quot;export CXX=&quot;ccache g++&quot;export PATH=&quot;$PATH:/usr/lib/ccache&quot;Ctrl+S 或点击 Save 按钮保存，然后需要更新 .bashrc 使其生效。source ~/.bashrc我们可以根据硬盘空间设置 ccache 允许使用的最大缓存空间， &amp;lt;xx&amp;gt; 修改为数字：ccache -M &amp;lt;xx&amp;gt;G二、使用1. CMake对于采用 CMake 的应用，只需要将以下的代码加入到命令 project() 行以后即可：find_program(CCACHE_PROGRAM ccache)if (CCACHE_PROGRAM) set_property(GLOBAL PROPERTY RULE_LAUNCH_COMPILE &quot;${CCACHE_PROGRAM}&quot;)endif ()add_compile_definitions(PROJECT_DIR=&quot;${PROJECT_SOURCE_DIR}&quot;)2. Xcode参考参考教程：ccache - 让Xcode编译速度飞起来。如果觉得本教程不错或对您有用，请前往项目地址 https://raw.githubusercontent.com/Harry-hhj/Harry-hhj.github.io 点击 Star :) ，这将是对我的肯定和鼓励，谢谢！三、参考教程 ubuntu配置ccache ccache - 让Xcode编译速度飞起来作者：Harry-hhj，Github主页：传送门" }, { "title": "Unreal Engine 4 课程目录", "url": "/posts/Unreal-Engine-Tutorial-Catalogue/", "categories": "Course, Unreal Engine", "tags": "catalog", "date": "2021-10-21 23:59:00 +0800", "snippet": "Unreal Engine Catalogue一、课程简介本课程以动手实践为主，在实践中理解相关原理，以能够实战进行项目为首要目标，不要求知识的系统性学习。Unreal介绍。。。二、课程教程 如果觉得本教程不错或对您有用，请前往项目地址 https://github.com/Harry-hhj/Harry-hhj.github.io 点击 Star :) ，这将是对我的肯定和鼓励，谢谢！作者：Harry-hhj，github主页：传送门" }, { "title": "RM 教程 5 —— 单目视觉", "url": "/posts/RM-Tutorial-5-Monocular-Vision/", "categories": "Course, RM", "tags": "getting started, robomaster, computer vision", "date": "2021-10-15 21:30:00 +0800", "snippet": "RM 教程 5 —— 单目视觉 机械是肉体， 电控是大脑， 视觉是灵魂一、仿射变换与透视变换0. 再谈其次坐标系在上一讲中，我们提到了齐次坐标系。对于二维平面上的点 $(x, y)$ ， 我们常常将它写成为 $(x, y, 1)^T$ ，这是一个典型的齐次坐标。同样的，在三维空间中，我们有坐标 $(x, y, z, 1)^T$ ，这也是一个齐次坐标形式。显然，对于齐次坐标和非齐次坐标，我们可以简单地通过删除最后一个坐标 $1$ 来实现他们之间的转换。但这样看来，齐次坐标的表述仍然非常奇怪，因为它多了一个莫名其妙的限制，就是最后一个坐标数值一定为 $1$ 。那么一个坐标三元组 $(x, y, 2)^T$ 是否也有自己的意义呢?对此，我们规定对于任何非零值 $k$ ， $(kx, ky, k)^T$ 表示二维坐标中的同一个点，也就是说，当两个三元组相差一个公共倍数时，他们是等价的，也被成为坐标三元组中的等价类。现在问题有出现了，在上面的定义中，我们规定 $k \\ne 0$ ，那么当 $k = 0$ 时， 坐标三元组 $(x, y, 0)^T$ 是否有它的意义?由于 $(x/0, y/0)^T$ 得到的应该是一个在无穷远方的点，因此我们称它为无穷远点。在二维空间中， 无穷远点形成无穷远直线。在三维中，他们形成无穷远平面。1. 线性变换在谈仿射变换之前，我们先要复习一下线性变换。线性变换从几何直观有三个要点： 变换前是直线的，变换后依然是直线 直线比例保持不变 变换前是原点的，变换后依然是原点线性变换是通过矩阵乘法来实现的。1. 仿射变换仿射变换是一种特殊的坐标变换，在仿射变换下，形状的两个平行性和体积比保持不变。如果从无穷远直线的角度理解仿射变换，那么：假设在空间 $s$ 下直线 $l$ 为无穷远直线，当经过仿射变换 $A$ 后得到直线 $l’$ ， $l’$ 仍然为仿射变换后的空间 $s’$ 中的无穷远直线。仿射变换的公式为：\\(\\begin{bmatrix}x&#39;\\\\y&#39;\\\\1\\\\\\end{bmatrix}=\\begin{bmatrix}\\mathbf A &amp;amp; \\mathbf t\\\\\\mathbf 0^T &amp;amp; 1\\\\\\end{bmatrix}\\begin{bmatrix}x\\\\y\\\\1\\\\\\end{bmatrix}\\)如果上述的表达方式太过数学化，我们可以用直观的方式帮助你理解仿射变换：对于仿射变换的感性理解就是，将输入图像想象为一个大的矩形橡胶片，然后通过在角上的推或拉变形来制作不同样子的平行四边形。简单来说，“仿射变换”就是：“线性变换”+“平移”。仿射变换的不变性： 线共点、点共线的关系不变 平行关系 中点 在一条直线上的几段线段的比例关系仿射变换会改变： 线段长度 夹角角度对于二维空间中的仿射变换，他有透视变换 $6$ 个自由度（参数）， 对于三维空间中的仿射变换，他有 $12$ 个自由度。补充知识仿射变换可以通过一系列的原子变换的复合来实现，包括：平移（Translation）、缩放（Scale）、翻转（Flip）、旋转（Rotation）和剪切（Shear）。理解这些特殊的变换对你理解仿射变换有一些帮助。我们介绍一下几种常见的特殊的仿射变换：平移变换 Translation平移变换是一种“刚体变换”，不会产生形变的理想物体。变换矩阵为：\\(\\begin{bmatrix}1 &amp;amp; 0 &amp;amp; t_x\\\\0 &amp;amp; 1 &amp;amp; t_y\\\\0 &amp;amp; 0 &amp;amp; 1\\\\\\end{bmatrix}\\)缩放变换 Scale将每一点的横坐标放大（缩小）至 $s_x$ 倍，纵坐标放大（缩小）至 $s_y$ 倍。变换矩阵为：\\(\\begin{bmatrix}s_x &amp;amp; 0 &amp;amp; 0\\\\0 &amp;amp; s_y &amp;amp; 0\\\\0 &amp;amp; 0 &amp;amp; 1\\\\\\end{bmatrix}\\)剪切变换 Shear相当于一个横向剪切与一个纵向剪切的复合。变换矩阵为： \\(\\begin{bmatrix}1 &amp;amp; sh_x &amp;amp; 0\\\\sh_y &amp;amp; 1 &amp;amp; 0\\\\0 &amp;amp; 0 &amp;amp; 1\\\\\\end{bmatrix}=\\begin{bmatrix}1 &amp;amp; 0 &amp;amp; 0\\\\sh_y &amp;amp; 1 &amp;amp; 0\\\\0 &amp;amp; 0 &amp;amp; 1\\\\\\end{bmatrix}\\begin{bmatrix}1 &amp;amp; sh_x &amp;amp; 0\\\\0 &amp;amp; 1 &amp;amp; 0\\\\0 &amp;amp; 0 &amp;amp; 1\\\\\\end{bmatrix}\\)旋转变换 Rotation目标图形围绕原点顺时针旋转 $\\theta$ 弧度。变换矩阵为： \\(\\begin{bmatrix}\\cos(\\theta) &amp;amp; -\\sin(\\theta) &amp;amp; 0\\\\\\sin(\\theta) &amp;amp; \\cos(\\theta) &amp;amp; 0\\\\0 &amp;amp; 0 &amp;amp; 1\\\\\\end{bmatrix}\\)组合旋转变换，目标图形以 $(x, y)$ 为轴心顺时针旋转 $\\theta$ 弧度，相当于两次平移变换与一次原点旋转变换的复合：先移动到中心节点，然后旋转，然后再移动回去。变换矩阵为： \\(\\begin{bmatrix}\\cos(\\theta) &amp;amp; -\\sin(\\theta) &amp;amp; y-x\\cos(\\theta)+y\\sin(\\theta)\\\\\\sin(\\theta) &amp;amp; \\cos(\\theta) &amp;amp; y-x\\sin(\\theta)-y\\cos(\\theta)\\\\0 &amp;amp; 0 &amp;amp; 1\\\\\\end{bmatrix}=\\begin{bmatrix}1 &amp;amp; 0 &amp;amp; -x\\\\0 &amp;amp; 1 &amp;amp; -y\\\\0 &amp;amp; 0 &amp;amp; 1\\\\\\end{bmatrix}\\begin{bmatrix}\\cos(\\theta) &amp;amp; -\\sin(\\theta) &amp;amp; 0\\\\\\sin(\\theta) &amp;amp; \\cos(\\theta) &amp;amp; 0\\\\0 &amp;amp; 0 &amp;amp; 1\\\\\\end{bmatrix}\\begin{bmatrix}1 &amp;amp; 0 &amp;amp; x\\\\0 &amp;amp; 1 &amp;amp; y\\\\0 &amp;amp; 0 &amp;amp; 1\\\\\\end{bmatrix}\\)这个转换矩阵也可以下面这样描述。一些常用转换矩阵如下：2. 透视变换仿射变换可以理解为透视变换的特殊形式。透视变换也叫投影变换。我们在仿射变换中提到，通过仿射变换，原图像中的无穷远线不变。与之相反，通过透视变换，原来的无穷远线不再是无穷远线。也就是说，对于一点 $(x, y, 0)^T$ ，它经过透视变换之后的坐标最后一元不再为零。透视变换不再保证平行性。在二维空间中，空间变换的一般形式公式如下：\\(\\begin{bmatrix}x&#39;\\\\y&#39;\\\\k&#39;\\\\\\end{bmatrix}=\\begin{bmatrix}a_{11} &amp;amp; a_{12} &amp;amp; a_{13}\\\\a_{21} &amp;amp; a_{22} &amp;amp; a_{23}\\\\a_{31} &amp;amp; a_{32} &amp;amp; a_{33}\\\\\\end{bmatrix}\\begin{bmatrix}x\\\\y\\\\k\\\\\\end{bmatrix}\\)如果想通过这样的一个变换使得变换结果中的 $k’ \\ne 0$ ，那么就必须满足 $a_{31}x + a_{32}y \\ne 0$ 。于是，我们自然而然地得到了透视变换的一般形式：\\(\\begin{bmatrix}x&#39;\\\\y&#39;\\\\k&#39;\\\\\\end{bmatrix}=\\begin{bmatrix}\\mathbf A &amp;amp; \\mathbf t\\\\\\mathbf a^T &amp;amp; v\\\\\\end{bmatrix}\\begin{bmatrix}x\\\\y\\\\k\\\\\\end{bmatrix}\\)如果想要感性地理解透视变换，那么你可以想想从不同角度看同一个物体的效果。例如下图就是一个透视变换的示意图：通过透视变换，我们可以转换原图的视角。例如下图中，我们就将车道从平视图转换为俯视图：下图中我们将车牌从侧视图转换为正视图：对于二维空间中的透视变换，它有 $8$ 个自由度，对于三维空间中的透视变换，它有 $15$ 个自由度。3. OpenCV中的仿射变换和透视变换在应用层面，仿射变换是图像基于 $3$ 个固定顶点的变换，如图所示：图中红点即为固定顶点，在变换先后固定顶点的像素值不变，图像整体则根据变换规则进行变换。同理，透视变换是图像基于 $4$ 个固定顶点的变换，如图所示：在OpenCV中，仿射变换和透视变换均有封装好的函数。仿射变换的函数是：void cv::warpAffine(InputArray src, OutputArray dst, InputArray M, Size dsize, int flags=INTER_LINEAR, int borderMode=BORDER_CONSTANT, const Scalar&amp;amp; borderValue=Scalar())参数： InputArray src：输入变换前图像 OutputArray dst：输出变换后图像，需要初始化一个空矩阵用来保存结果，不用设定矩阵尺寸 InputArray M：变换矩阵，用另一个函数 getAffineTransform() 计算 Size dsize：设置输出图像大小 int flags=INTER_LINEAR：设置插值方式，默认方式为线性插值生成仿射变换矩阵函数是 getAffineTransform()：cv::Mat cv::getAffineTransform(const Point2f* src, const Point2f* dst)参数： const Point2f* src：原图的 3 个固定顶点 const Point2f* dst：目标图像的 3 个固定顶点 注意，顶点数组长度超过 3 个，则会自动以前 3 个为变换顶点；数组可用 Point2f[] 或 Point2f* 表示 透视变换的函数是：void warpPerspective(InputArray src, OutputArray dst, InputArray M, Size dsize, int flags=INTER_LINEAR, int borderMode=BORDER_CONSTANT, const Scalar&amp;amp; borderValue=Scalar())参数与 warpAffine() 一致。生成透视变换矩阵函数是 getPerspectiveTransform()：cv::Mat cv::getPerspectiveTransform(InputArray src, InputArray dst, int solveMethod = DECOMP_LU)参数： 透视变换顶点为 4 个桌上有一张扑克牌，我们希望可以从正视的角度观察它。运行以下示例代码观察程序效果：二、Eigen1. 简介Eigen 是C++语言里的一个开源模版库，支持线性代数运算、矩阵和矢量运算、数值分析及其相关的算法。可以将它类比为 python 中的 numpy 。注意如果想要发挥出 Eigen 的作用，编译时一定要打开 gcc/g++ 编译优化 -O3 。Eigen 能算得快和它的设计思路有关，涵盖了算法加速的几个方法。第一，Eigen 使用 Lazy Evaluation 的方法。这个方法的好处是： 把所有能优化的步骤放在编译时去优化。让计算本身尽可能放在最后做，减少内存访问。例如下面一段代码： Eigen::MatrixXd Jacobian_i = Eigen::MatrixXd::Random(10, 10);Eigen::MatrixXd Jacobian_j = Eigen::MatrixXd::Random(10, 10);Eigen::MatrixXd Hessian = Eigen::MatrixXd::Zero(10, 10);Hessian += Jacobian_i.transpose() * Jacobian_j; 实际运行时，在 operator+=() 才真正去做内存读取和计算，而前面的步骤知识更新 flag 。具体见 Eigen/src/Core/EigenBase.h 。 不生成中间变量，减少内存搬运次数，而 Eigen 为了防止矩阵覆盖自己，对矩阵-矩阵乘法会生成一个中间变量。如果我们知道等式左右两边没有相同的项，则可以通知Eigen去取消中间变量。 第二，改变内存的分配方式。使用Eigen时应该尽可能用静态内存代替动态内存。 Eigen::MatrixXd 是如下的缩写：typedef MatrixXd Matrix&amp;lt;double, Dynamic, Dynamic, ColMajor&amp;gt;MatrixBase 第二和第三个选项是行列的长度，有一项是 Dynamic 就会用动态内存分配。所以已知矩阵大小时应尽可能声明大小，比如 Matrix&amp;lt;double, 10, 10&amp;gt; 。如果内存在整个程序中大小会变，但知道最大可能的大小，都可以告知 Eigen ， Eigen 同样会选择用静态内存。Eigen::Matrix&amp;lt;double, Eigen::Dynamic, Eigen::Dynamic, Eigen::ColMajor, 10, 10&amp;gt; Jacobian_i;Eigen::Matrix&amp;lt;double, Eigen::Dynamic, Eigen::Dynamic, Eigen::ColMajor, 10, 10&amp;gt; Jacobian_j;Eigen::Matrix&amp;lt;double, Eigen::Dynamic, Eigen::Dynamic, Eigen::ColMajor, 10, 10&amp;gt; Hessian = Eigen::Matrix&amp;lt;double, 10, 10&amp;gt;::Zero();Hessian += Jacobian_i.transpose() * Jacobian_j;静态内存分配不但让我们节省了 new/delete 的开销，还给 Eigen 内部继续优化提供了可能。 Eigen 内置 Single-Instruction-Multiple-Data （SIMD）指令集，对稠密矩阵有很好的优化，如果能触发 CPU SIMD 的指令，能收获成倍的计算效率。第三，矩阵自身的性质。如果矩阵本身有自身的性质，都可以通知 Eigen ，让 Eigen 用对应的加速方式。比如正定矩阵可以只用上三角进行计算，并且在求解时使用 Eigen::LLT 这样又快又数值稳定的解法等。2. 安装 Eigen终端 apt 命令安装：sudo apt-get install libeigen3-devEigen 只包含头文件，因此它不需要实现编译（只需要使用 #include ），指定好 Eigen 的头文件路径，编译项目即可。Eigen 头文件的默认安装位置是 /usr/include/eigen3 。3. Eigen 库的模块及其头文件为了应对不同的需求， Eigen 库被分为多个功能模块，每个模块都有自己相对应的头文件，以供调用。 其中， Dense 模块整合了绝大部分的模块，而 Eigen 模块更是整合了所有模块。4. 使用方法（1）构造Eigen::Matrix&amp;lt;double, 3, 3&amp;gt; A; // Fixed rows and cols. Same as Matrix3d.Eigen::Matrix&amp;lt;double, 3, Eigen::Dynamic&amp;gt; B; // Fixed rows, dynamic cols.Eigen::Matrix&amp;lt;double, Eigen::Dynamic, Eigen::Dynamic&amp;gt; C; // Full dynamic. Same as MatrixXd.Eigen::Matrix&amp;lt;double, 3, 3, Eigen::RowMajor&amp;gt; E; // Row major; default is column-major.有一些宏定义可以简短代码：typedef Eigen::Matrix&amp;lt;int, 3, 3&amp;gt; Eigen::Matrix2itypedef Eigen::Matrix&amp;lt;int, Eigen::Dynamic, 3&amp;gt; Eigen::MatrixX3itypedef Eigen::Matrix&amp;lt;int, 3, Eigen::Dynamic&amp;gt; Eigen::Matrix3Xi（2）特殊矩阵生成 实例 代码 零矩阵 Eigen::Matrix&amp;lt;int, 3, 3&amp;gt;::Zero() 一矩阵 Eigen::Matrix&amp;lt;int, 3, 3&amp;gt;::Ones() 单位矩阵 Eigen::Matrix&amp;lt;int, 3, 3&amp;gt;::Identity() 常量矩阵 Eigen::Matrix&amp;lt;int, 3, 3&amp;gt;::Constant(a) 随机矩阵 Eigen::Matrix&amp;lt;int, 3, 3&amp;gt;::Random() 线性空间向量 Eigen::Vector3i::LinSpaced(a, b) （3）随机访问Eigen 有重载 () 运算符提供随机访问的功能。下面是一段例程：Eigen::MatrixXd m(2,2);m(0,0) = 3;m(1,0) = 2.5;m(0,1) = -1;m(1,1) = m(1, 0) + m(0, 1);std::cout &amp;lt;&amp;lt; &quot;Here is the matrix m:\\n&quot; &amp;lt;&amp;lt; m &amp;lt;&amp;lt; std::endl;Eigen::VectorXd v(2);v(0) = 4;v(1) = v(0) - 1;std::cout &amp;lt;&amp;lt; &quot;Here is the vector v:\\n&quot; &amp;lt;&amp;lt; v &amp;lt;&amp;lt; std::endl;（4）赋值利用重载 &amp;lt;&amp;lt; 运算符或 = 运算符完成赋值。下面是一段例程：Eigen::Matrix3f m;m &amp;lt;&amp;lt; 1, 2, 3, 4, 5, 6, 7, 8, 9;std::cout &amp;lt;&amp;lt; m &amp;lt;&amp;lt; std::endl;（5）改变矩阵大小只能作用于大小没有通过模版确定的矩阵，即设置为 Eigen::Dynamic 的维度。 resize(rows, cols) ：可能改变矩阵数据的存储顺序。 conservativeResize(rows, cols)：不会改变矩阵数据的内存分布，因此如果新生成的大小不能覆盖原来的数据，会造成数据丢失。可以减少赋值操作。下面是一段例程：Eigen::Matrix&amp;lt;int, Eigen::Dynamic, Eigen::Dynamic&amp;gt; m = Eigen::Matrix&amp;lt;int, 3, 3&amp;gt;::Identity();m.resize(1, 9);（6）特殊 函数 作用 返回 transpose 转置 Matrix eval 返回矩阵的数值 Matrix transposeInPlace 自身进行转置 void inverse 取逆 Matrix 需要注意的是，由于 Eigen 使用 Lazy Evaluation，因此 mat = mat.transpose() 是不合法的。（7）单矩阵运算 函数 作用 mat.sum() 返回元素的和 mat.prod() 返回元素的乘积和 mat.maxCoeff() 返回最大元素 mat.minCoeff() 返回最小元素 mat.trace() 返回矩阵的迹 （8）子阵运算block 运算的功能是截取矩阵中的部分元素。 mat.block(i,j,p,q)：动态大小的 block 运算 mat.block&amp;lt;p,q&amp;gt;(i,j)：确定大小的 block 运算Eigen::Matrix&amp;lt;int, 3, 3, 0&amp;gt; matrix_1;matrix_1.block&amp;lt;2, 2&amp;gt;(0, 0) &amp;lt;&amp;lt; Eigen::Matrix2i::Ones();matrix_1.block&amp;lt;2, 1&amp;gt;(0, 2) &amp;lt;&amp;lt; Eigen::Vector2i::Random();matrix_1.block&amp;lt;1, 3&amp;gt;(2, 0) &amp;lt;&amp;lt; 2, 3, 4;std::cout &amp;lt;&amp;lt; matrix_1 &amp;lt;&amp;lt; std::endl; 函数 作用 mat.topLeftCorner(rows, cols) 取左上角的 block mat.topRightCorner(rows, cols) 取右上角的 block mat.bottomLeftCorner(rows, cols) 取左下角的 block mat.bottemRightCorner(rows, cols) 取右下角的 block mat.topRows(rows) 取上方 k 行 mat.bottomRows(rows) 取下方 k 行 mat.leftCols(cols) 取左侧 k 行 mat.rightCols(cols) 取右方 k 行 mat.cols(j) 取第 j 行 mat.rows(i) 取第 i 行 （9）广播将一个矩阵的一个大小为 $1$ 或缺失的维度重复补全后和另一个矩阵进行计算。例如，一个矩阵 A 维度为 $(3,3)$ ，另一个矩阵B维度为 $(3,1)$ 。那么运算 $A+B$ 中就发生了广播，矩阵 A 的维度被补全为 $(3,3)$ 后和 B 进行运算。下面是一段例程：Eigen::MatrixXf mat(2,4);Eigen::VectorXf v(2);mat &amp;lt;&amp;lt; 1, 2, 6, 9, 3, 1, 7, 2;v &amp;lt;&amp;lt; 0, 1;mat.colwise() += v;std::cout &amp;lt;&amp;lt; mat &amp;lt;&amp;lt; std::endl;三、PnPPnP 常用于单目测距和姿态解算。如果场景的三维结构已知，利用多个控制点在三维场景中的坐标及其在图像中的透视投影坐标即可求解出摄像机坐标系与表示三维场景结构的世界坐标系之间的绝对位姿关系，包括绝对平移向量 $t$ 以及旋转矩阵 $R$ ，该类求解方法统称为 N 点透视位姿求解（ Perspective-N-Point ， PNP 问题）。这里的控制点是指准确知道三维空间坐标位置，同时也知道对应图像平面坐标的点。对于透视投影来说，要使得 PNP 问题有确定解，需要至少三组控制点。在解决任何 PnP 问题之前，我们都需要准确地标定出相机的内参矩阵和畸变矩阵，标定的质量会影响最后外参矩阵（旋转矩阵+平移矩阵）的精度。这一部分在之前的教程中已经教过了。1. P3P 问题P3P 需要利用给定的 3 个点的几何关系。输入数据为 3 对 3D-2D 匹配点。记 3D 点为 A 、 B 、 C ， 2D 点为 a 、 b 、 c 。其中，小写字母代表点的为对应大写字母代表的点在相机成像平面上的投影。此外， P3P 还需要使用一对验证点，从可能的解中选出正确的那一个（验证点记为 D-d ），相机的光心为 O 。请注意，我们知道的是 ABC 三个点在世界坐标系中的坐标，而不是在相机坐标系中的坐标。由图可得，显然有如下相似三角形的关系：\\(\\begin{cases}\\triangle Oab \\sim \\triangle OAB \\\\\\triangle Obc \\sim \\triangle OBC \\\\\\triangle Oac \\sim \\triangle OAC \\\\\\end{cases}\\)采用余弦定理，有\\(\\begin{cases}OA^2 + OB^2 - 2 \\cdot OA \\cdot OB \\cos&amp;lt;a, b&amp;gt; = AB^2 \\\\OB^2 + OC^2 - 2 \\cdot OB \\cdot OC \\cos&amp;lt;b, c&amp;gt; = BC^2 \\\\OA^2 + OC^2 - 2 \\cdot OA \\cdot OC \\cos&amp;lt;a, c&amp;gt; = AC^2 \\\\\\end{cases}\\)左右两边同时除以 $OC^2$ ，令 $x = \\cfrac{OA}{OC}, y = \\cfrac{OB}{OC}$ ，有\\(\\begin{cases}x^2 + y^2 - 2xy \\cos&amp;lt;a, b&amp;gt; = \\cfrac{AB^2}{OC^2} \\\\y^2 + 1^2 + 2y \\cos&amp;lt;b, c&amp;gt; = \\cfrac{BC^2}{OC^2} \\\\x^2 + 1^2 + 2x \\cos&amp;lt;a, c&amp;gt; = \\cfrac{AC^2}{OC^2} \\\\\\end{cases}\\)再令 $u = \\cfrac{AB^2}{OC^2}, v = \\cfrac{BC^2}{AB^2}, w = \\cfrac{AC^2}{AB^2}$ ，有\\(\\begin{cases}x^2 + y^2 - 2xy \\cos&amp;lt;a, b&amp;gt; -v = 0 \\\\y^2 + 1^2 + 2y \\cos&amp;lt;b, c&amp;gt; - uv = 0 \\\\x^2 + 1^2 + 2x \\cos&amp;lt;a, c&amp;gt; - wv = 0 \\\\\\end{cases}\\)将第一个等式带入后面两个，得：\\(\\begin{cases}(1-u)y^2 - ux^2 - y \\cos&amp;lt;b, c&amp;gt; + 2uxy \\cos&amp;lt;a, b&amp;gt; + 1 = 0 \\\\(1-w)x^2 - wy^2 - x \\cos&amp;lt;a, c&amp;gt; + 2wxy \\cos&amp;lt;a, b&amp;gt; + 1 = 0 \\\\\\end{cases}\\)2D 点的图像坐标已知， 3 个余弦角已知。 3D 点的坐标已知，只有 xy 未知。可以采用吴消元法来解上述方程。该方法最多可以获得 4 个解，但可以通过第四个点，来获得最可能的解。进一步地， EPnP （需要 4 对不共面的点）、 UPnP 等则是利用更多的信息来迭代，对相机的位姿进行优化，以尽可能消除噪声的影响。至于进一步的运算这里就不推倒了，难度有点大，感兴趣的可以看这篇博客。2. PnP 问题PnP 和 P3P 问题类似，但是它有足够的信息确定一组解。 PnP 算法通过至少四个点的约束，求出世界坐标系到相机坐标系的旋转矩阵和平移向量。\\(\\begin{bmatrix}u\\\\v\\\\1\\\\\\end{bmatrix}=\\mathbf K\\begin{bmatrix}1 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\\\0 &amp;amp; 1 &amp;amp; 0 &amp;amp; 0 \\\\0 &amp;amp; 0 &amp;amp; 1 &amp;amp; 0 \\\\\\end{bmatrix}\\begin{bmatrix}\\mathbf R &amp;amp; \\mathbf T \\\\\\mathbf 0^T &amp;amp; 1 \\\\\\end{bmatrix}\\begin{bmatrix}X_w\\\\Y_w\\\\Z_w\\\\1\\\\\\end{bmatrix}\\)3. OpenCV 中的 solvePnp()声明如下：void solvePnP(InputArray objectPoints, InputArray imagePoints, InputArray cameraMatrix, InputArray distCoeffs, OutputArray rvec, OutputArray tvec, bool useExtrinsicGuess=false, int flags=CV_ITERATIVE)参数： objectPoints ：视觉坐标系中的点 imagePoints ：像素坐标系中的点 cameraMatrix ：相机内参 disCoeffs ：相机畸变矩阵 rvec ：求出来的旋转向量 tvec ：求出来的平移向量 useExtrinsicGuess：是否输出平移矩阵和旋转矩阵，默认为 false flags ：选择算法 SOLVEPNP _ITERATIVE SOLVEPNP _P3P SOLVEPNP _EPNP SOLVEPNP _DLS SOLVEPNP _UPNP 如何用这函数来实现测距呢？我们只需要把世界坐标系的原点设置在我们感兴趣的点就可以了，那么函数返回的平移向量的的模长就是相机和那个点的距离。例如TODO4. 旋转角度、旋转向量与旋转矩阵我们再补充一下旋转矩阵和旋转响向量之间的转换关系。三维空间中的旋转矩阵有 $9$ 个量，而三维空间中的旋转只有 $3$ 个自由度，因此我们很自然地想到， 是否可以用更少的量描述一个三维运动。事实上，对于坐标系的旋转，任意旋转都可以用一个旋转轴和一个旋转角来刻画。于是，我们可以使用一个方向与旋转轴垂直、长度等于旋转角的向量描述旋转运动，这个向量成为旋转向量。通过这样的方式，我们就可以只通过一个三维的旋转向量和一个三维的平移向量描述三维空间中刚体的运动。旋转矩阵和旋转向量是可以互相转化的，有旋转向量推导旋转矩阵的公式也被成为罗德里格斯公式：\\(\\theta \\leftarrow \\norm{\\vec{r}}\\\\\\vec{r} \\leftarrow \\vec{r}/\\theta\\\\R(\\vec{n}, \\theta) = \\cos(\\theta) \\mathbf I + (1-\\cos \\theta)\\vec{r}\\vec{r}^T + \\sin(\\theta) \\begin{bmatrix}0 &amp;amp; -r_z &amp;amp; r_y \\\\r_z &amp;amp; 0 &amp;amp; -r_x \\\\-r_y &amp;amp; r_x &amp;amp; 0 \\\\\\end{bmatrix}\\)其中，旋转向量的长度（模）表示绕轴逆时针旋转的角度（弧度）， $\\theta$ 表示旋转角度， $\\mathbf{I}$ 表示单位矩阵，最后一个矩阵表示 $\\vec r$ 的反对称矩阵。旋转角 $\\theta$ 也可以由公式\\(\\theta = \\arccos(\\cfrac{tr(R)-1}{2})\\)计算得到。OpenCV 中的旋转向量和旋转矩阵转换的函数是int cvRodrigues2( const CvMat* src, CvMat* dst, CvMat* jacobian=0 );参数： src：为输入的旋转向量（ $3\\times1$ 或者 $1\\times3$ ）或者旋转矩阵（ $3\\times3$ ）。该参数向量表示其旋转的角度，用向量长度表示。 dst：为输出的旋转矩阵（ $3\\times3$ ）或者旋转向量（ $3\\times1$ 或者 $1\\times3$ ）。 jacobian：为可选的输出雅可比矩阵（ $3\\times9$ 或者 $9\\times3$ ），是输入与输出数组的偏导数。例子如下：cv::Mat r = (cv::Mat_&amp;lt;float&amp;gt;(3,1) &amp;lt;&amp;lt; -2.100418, -2.167796, 0.273330);cv::Mat R(cv::Size(3,3), CV_16FC1);cv::Rodrigues(r, R);std::cout &amp;lt;&amp;lt; &quot;r=&quot; &amp;lt;&amp;lt; r &amp;lt;&amp;lt; std::endl;std::cout &amp;lt;&amp;lt; &quot;R=&quot; &amp;lt;&amp;lt; R &amp;lt;&amp;lt; std::endl;程序结果：5. 欧拉角和四元数（1）欧拉角上图是一个示意图。欧拉角定义如下： 绕物体的 z 轴旋转，得到偏航角 yaw 绕旋转之后的 y 轴旋转，得到俯仰角 pitch 绕旋转之后的 x 轴旋转，得到滚转角 roll如果选用的轴的旋转顺序不同，则欧拉角不同。上述的欧拉角为 $rpy$ 欧拉角，以 $z$ 轴， $y$ 轴， $x$ 轴顺序旋转，是比较常用的一种。下面举个例子（来自参考资料 5 ）。这里，我把三个 Gimbal 环用不同的颜色做了标记，底部三个轴向， RGB 分别对应 XYZ 。 假设现在这个陀螺仪被放在一艘船上，船头的方向沿着 +Z 轴，也就是蓝色右前方。现在假设，船体发生了摇晃，是沿着前方进行旋转的摇晃，也就是桶滚。由于转子和旋转轴具有较大的惯性，只要没有直接施加扭矩，就会保持原有的姿态。由于上图中绿色的活动的连接头处是可以灵活转动的，此时将发生相对旋转，从而出现以下的情形：再次假设，船体发生了pitch摇晃，也就是俯仰。同样，由于存在相应方向的可以相对旋转的连接头（红色连接头），转子和旋转轴将仍然保持平衡，如下图：最后假设，船体发生了yaw摇晃，也就是偏航，此时船体在发生水平旋转。相对旋转发生在蓝色连接头。如下图：最终，在船体发生 Pitch 、 Yaw 、 Roll 的情况下，陀螺仪都可以通过自身的调节，而让转子和旋转轴保持平衡。但是欧拉角有一个致命的问题导致死锁，称为万向节死锁。（2）万向节死锁现在看起来，这个陀螺仪一切正常，在船体发生任意方向摇晃都可以通过自身调节来应对。然而，真的是这样吗？假如，船体发生了剧烈的变化，此时船首仰起了90度（虽然可能不合理），此时的陀螺仪调节状态如下图：此时，船体再次发生转动，沿着当前世界坐标的 +Z 轴（蓝色轴，应该正指向船底）进行转动，那么来看看发生了什么情况。现在，转子不平衡了，陀螺仪的三板斧不起作用了。它失去了自身的调节能力。那么这是为什么呢？之前陀螺仪之所以能通过自身调节，保持平衡，是因为存在可以相对旋转的连接头。在这种情况下，已经不存在可以相对旋转的连接头了。 那么连接头呢？去了哪里？显然，它还是在那里，只不过是，连接头可以旋转的相对方向不是现在需要的按着+Z轴方向。从上图中，我们清楚地看到： 红色连接头：可以给予一个相对俯仰的自由度。 绿色连接头：可以给予一个相对偏航的自由度。 蓝色连接头：可以给予一个相对偏航的自由度。没错，三个连接头，提供的自由度只对应了俯仰和偏航两个自由度，桶滚自由度丢失了。这就是陀螺仪上的“万向节死锁”问题。我们可以用小程序来重现万向节死锁问题。首先，预设一下接下来的欧拉角变化顺序。见下图：上图中，红色框内的部分的列表，记录了接下来欧拉角的增长变化过程。即它会从 $(0,0,0)$ 变化到 $(90,0,0)$ ，再变化到 $(90,90,0)$ ，再变化到 $(90,180,0)$ ，再变化到 $(90,180,90)$ ，再变化到 $(90,180,180)$ 。下图是变化的过程演示：现在可以看到： 当先执行X轴旋转 90 度，此时在执行Pitch(俯仰)变化。 再在Y轴进行变化 0-180 度，此时在执行相对自身的 Roll (桶滚)变化。 再在Z轴进行变化 0-180 度，此时仍在执行相对自身的 Roll (桶滚)变化。这里所说的俯仰、桶滚、偏航都是相对自己局部坐标系的。这与上述的陀螺仪中出现的问题是一样的，万向节死锁。也就是尽管欧拉角在 XYZ 三个轴向进行进动(持续增长或者减少)，但是影响最终的结果，只对应了两个轴向。这一点在 Unity 编程中也应该注意。为了解决这一问题，我们引入四元数。由于万向锁的存在，欧拉角并不是一个完备的描述旋转的方式。事实上，我们找不到不带奇异性的三维向量描述方式。（3）四元数四元数的定义如下：\\(q = \\begin{bmatrix}w &amp;amp; x &amp;amp; y &amp;amp; z\\\\ \\end{bmatrix}^T, \\text{ where }|q|^2 = 1\\)定义 $\\psi,\\theta,\\phi$ 分别为绕Z轴、Y轴、X轴的旋转角度，如果用 Tait-Bryan angle 表示，分别为 Yaw 、 Pitch 、 Roll 。旋转角度-&amp;gt;四元数通过旋转轴和绕该轴旋转的角度可以构造一个四元数：\\(w = \\cos(\\alpha/2)\\\\x = \\sin(\\alpha/2)\\cos(\\beta_x)\\\\y = \\sin(\\alpha/2)\\cos(\\beta_y)\\\\z = \\sin(\\alpha/2)\\cos(\\beta_z)\\\\\\)其中 $\\alpha$ 是绕旋转轴旋转的角度， $\\cos(\\beta_x),\\cos(\\beta_y),\\cos(\\beta_z)$ 为旋转轴在 $x,y,z$ 方向的分量（由此确定了旋转轴)。欧拉角-&amp;gt;四元数\\[q =\\begin{bmatrix}w\\\\x\\\\y\\\\z\\\\\\end{bmatrix}=\\begin{bmatrix}\\cos(\\phi/2)\\cos(\\theta/2)\\cos(\\psi/2)+\\sin(\\phi/2)\\sin(\\theta/2)\\sin(\\psi/2)\\\\\\sin(\\phi/2)\\cos(\\theta/2)\\cos(\\psi/2)-\\cos(\\phi/2)\\sin(\\theta/2)\\sin(\\psi/2)\\\\\\cos(\\phi/2)\\sin(\\theta/2)\\cos(\\psi/2)+\\sin(\\phi/2)\\cos(\\theta/2)\\sin(\\psi/2)\\\\\\cos(\\phi/2)\\cos(\\theta/2)\\sin(\\psi/2)-\\sin(\\phi/2)\\sin(\\theta/2)\\cos(\\psi/2)\\\\\\end{bmatrix}\\]四元数-&amp;gt;欧拉角\\[\\begin{bmatrix}\\phi\\\\\\theta\\\\\\psi\\end{bmatrix}=\\begin{bmatrix}\\text{atan2}(2(wx+yz), 1-2(x^2+y^2))\\\\\\arcsin(2(wy-zx))\\\\\\text{atan2}(2(wz+xy), 1-2(y^2+z^2))\\end{bmatrix}\\]其他坐标系在其他坐标系下，需根据坐标轴的定义，调整一下以上公式。如在 Direct3D 中，笛卡尔坐标系的 X 轴变为 Z 轴， Y 轴变为 X 轴， Z 轴变为 Y 轴（无需考虑方向）。\\(q =\\begin{bmatrix}w\\\\x\\\\y\\\\z\\\\\\end{bmatrix}=\\begin{bmatrix}\\cos(\\phi/2)\\cos(\\theta/2)\\cos(\\psi/2)+\\sin(\\phi/2)\\sin(\\theta/2)\\sin(\\psi/2)\\\\\\cos(\\phi/2)\\sin(\\theta/2)\\cos(\\psi/2)+\\sin(\\phi/2)\\cos(\\theta/2)\\sin(\\psi/2)\\\\\\cos(\\phi/2)\\cos(\\theta/2)\\sin(\\psi/2)-\\sin(\\phi/2)\\sin(\\theta/2)\\cos(\\psi/2)\\\\\\sin(\\phi/2)\\cos(\\theta/2)\\cos(\\psi/2)-\\cos(\\phi/2)\\sin(\\theta/2)\\sin(\\psi/2)\\\\\\end{bmatrix}\\)\\[\\begin{bmatrix}\\phi\\\\\\theta\\\\\\psi\\end{bmatrix}=\\begin{bmatrix}\\text{atan2}(2(wz+xy), 1-2(x^2+z^2))\\\\\\arcsin(2(wx-yz))\\\\\\text{atan2}(2(wy+xz), 1-2(x^2+y^2))\\end{bmatrix}\\]三、作业链接: https://pan.baidu.com/s/19jWghlU5FS9YfwG4EcMADA 提取码: q5bg【其中部分题目提供了参考答案】 对数据包中的汽车照片中的车牌进行透视变换，可自行决定难度： 通过画图工具等手动确定透视变换 4 个像素点坐标 通过 OpenCV 窗口鼠标回调函数点击确定像素点坐标 通过传统视觉识别确定像素点坐标 项目实战：对桌面的扑克牌进行透视变换，给出扑克牌的正视图。要求用算法识别出角点并排序。 效果如下： 使用 PnP 算法求解相机相对于标定板的位置，相机标定结果已经在数据包中给出与 hw3.zip 压缩包。 使用 OpenCV （与 Eigen ）完成深度图重投影，文件位于 hw4.zip 压缩包，其中包含了图片、其对应的深度信息、以及相机内参矩阵与相机透视变换矩阵。 如果觉得本教程不错或对您有用，请前往项目地址 https://github.com/Harry-hhj/Harry-hhj.github.io 点击 Star :) ，这将是对我的肯定和鼓励，谢谢！四、参考资料 如何通俗地讲解「仿射变换」这个概念？ 仿射变换 学习笔记之——P3P与ICP位姿估计算法及实验 Eigen的速度为什么这么快？（部分代码有误） 【Unity编程】欧拉角与万向节死锁（图文版） 学习笔记—四元数与欧拉角之间的转换作者：Harry-hhj，Github主页：传送门作者：E-T-E-R-N-A-L-B-L-U-E，传送门" }, { "title": "神经网络集训 —— Numpy 的使用", "url": "/posts/Numpy-Tutorial/", "categories": "Course, Nerual Network", "tags": "getting started, robomaster, numpy", "date": "2021-10-14 22:00:00 +0800", "snippet": "神经网络集训 —— Numpy 的使用在讲解具体的知识点之前，先来做做以下的问卷，进行一个基础的自查。这样，既能避免过分地自信导致学习态度的降低，也能有针对性地学习自己不理解的知识。当然，做题时请不要借助外部资料！链接: https://pan.baidu.com/s/1Ip4Dz6sAel3htlETxWbOYg 提取码: op3f一、Python 基础（1）import 机制对于 Python 脚本， import 的顺序不同，运行脚本不同，程序执行的代码可能不同，结果自然也不会相同。我们来看以下三个脚本：A.py ：# A.pyx=1def func(val): print(val) return x + valx = func(4)B.py ：# B.pydef func(val): print(val)func(1)import AA.func(2)C.py ：# C.pyimport AA.x = 10import BB.func(2)print(A.x)那么 C.py 的运行结果是：412210为什么最后是 10 而不是 5 ？原因在于 python 的 import 机制。1）标准 importPython 中所有加载到内存的模块都放在 sys.modules 。当 import 一个模块时首先会在这个列表中查找是否已经加载了此模块，如果加载了则只是将模块的名字加入到正在调用 import 的模块的 Local 名字空间中。如果没有加载则从 sys.path 目录中按照模块名称查找模块文件，模块可以是 py 、 pyc 、 pyd ，找到后将模块载入内存，并加到 sys.modules 中，并将名称导入到当前的 Local 名字空间。一个模块不会重复载入。多个不同的模块都可以用 import 引入同一个模块到自己的 Local 名字空间，其实背后的 PyModuleObject 对象只有一个。这里说一个容易忽略的问题： import 只能导入模块，不能导入模块中的对象（类、函数、变量等）。例如：模块 A（A.py）中有个函数 getName ，另一个模块不能通过 import A.getName 将 getName 导入到本模块，只能用 from A import getName 。注意，虽然有一种写法 from A import * 可以一次性导入模块中的所有对象，但是我们无法确保所有模块的对象不重名，可能会造成内存覆盖的问题，这在项目中非常难 debug ，所以不要使用！2）嵌套 import1. 顺序嵌套例如：本模块导入 A 模块（import A）， A 中又 import B ， B 模块又可以 import C ……这中嵌套比较容易理解，需要注意的一点就是各个模块的 Local 名字空间是独立的。对于上面的例子，本模块 import A 之后本模块只能访问模块 A ，不能访问模块 B 及其他模块。虽然模块 B 已经加载到内存了，如果访问还要再明确的在本模块中 import B 。2. 循环嵌套举个例子：# A.pyfrom B import Dclass C: pass# B.pyfrom A import Cclass D: pass结果会报错 ImportError: cannot import name &#39;D&#39; from partially initialized module &#39;B&#39; (most likely due to a circular import) 。如果将 A.py 改为： import B 就可以了。为什么？这跟 Python 内部 import 的机制是有关的，具体到 from B import D ， Python 内部会分成几个步骤： 在 sys.modules 中查找符号 “B” 如果符号 B 存在，则获得符号 B 对应的 module 对象。从 的 `__dict__` 中获得符号 `“D”` 对应的对象，如果 `“D”` 不存在，则抛出异常。 如果符号 B 不存在，则创建一个新的 module 对象 &amp;lt;module B&amp;gt;，注意，此时， module 对象的 __dict__ 为空。执行 B.py 中的表达式，填充 &amp;lt;module B&amp;gt; 的 __dict__ 。从 &amp;lt;module B&amp;gt; 的 __dict__ 中获得 “D” 对应的对象，如果 “D” 不存在，则抛出异常。所以这个例子的执行顺序如下： 执行 A.py 中的 from B import D 由于是执行的 python A.py ，所以在 sys.modules 中并没有 &amp;lt;module B&amp;gt; 存在， 首先为 B.py 创建一个 module 对象 (&amp;lt;module B&amp;gt;) ， 注意，这时创建的这个 module 对象是空的，里边啥也没有，在 Python 内部创建了这个 module 对象之后，就会解析执行 B.py ，其目的是填充 &amp;lt;module B&amp;gt; 这个 __dict__ 。 执行 B.py 中的 from A import C 在执行 B.py 的过程中，会碰到这一句， 首先检查 sys.modules 这个 module 缓存中是否已经存在 &amp;lt;module A&amp;gt; 了， 由于这时缓存还没有缓存 &amp;lt;module A&amp;gt; ， 所以类似的，Python 内部会为 A.py 创建一个 module 对象(&amp;lt;module A&amp;gt;)， 然后，同样地，执行 A.py 中的语句。 再次执行 A.py 中的 from B import D 这时，由于在第 1 步时，创建的 &amp;lt;module B&amp;gt; 对象已经缓存在了 sys.modules 中， 所以直接就得到了 &amp;lt;module B&amp;gt; ， 但是，注意，从整个过程来看，我们知道，这时 &amp;lt;module B&amp;gt; 还是一个空的对象，里面啥也没有， 所以从这个 module 中获得符号 &quot;D&quot; 的操作就会抛出异常。 如果这里只是 import B ，由于 &quot;B&quot; 这个符号在 sys.modules 中已经存在，所以是不会抛出异常的。 3）包 import只要一个文件夹下面有个 __init__.py 文件，那么这个文件夹就可以看做是一个包。包导入的过程和模块的基本一致，只是导入包的时候会执行此包目录下的 __init__.py 而不是模块里面的语句了。另外，如果只是单纯的导入包，而包的 __init__.py 中又没有明确的其他初始化操作，那么此包下面的模块是不会自动导入的。例如有下面的包结构：PA|---- __init__.py|---- wave.py|---- PB1 |---- __init__.py |---- pb1_m.py|---- PB2 |---- __init__.py |---- pb2_m.py有如下程序：import sysimport PA.wave #1import PA.PB1 #2import PA.PB1.pb1_m as m1 #3import PA.PB2.pb2_m #4PA.wave.getName() #5m1.getName() #6PA.PB.pb2_m.getName() #7程序执行过程如下： 当执行 #1 后， sys.modules 会同时存在 PA 、 PA.wave 两个模块，此时可以调用 PA.wave 的任何类或函数了。不能调用 PA.PB1(2) 下的任何模块。当前 Local 中有了 PA 名字。 当执行 #2 后，只是将 PA.PB1 载入内存， sys.modules 中会有 PA 、 PA.wave 、 PA.PB1 三个模块，但是 PA.PB1 下的任何模块都没有自动载入内存，此时如果直接执行 PA.PB1.pb1_m.getName() 则会出错，因为 PA.PB1 中并没有 pb1_m 。当前 Local 中还是只有 PA 名字，并没有 PA.PB1 名字。 当执行 #3 后，会将 PA.PB1 下的 pb1_m 载入内存， sys.modules 中会有 PA 、 PA.wave 、 PA.PB1 、 PA.PB1.pb1_m 四个模块，此时可以执行 PA.PB1.pb1_m.getName() 了。由于使用了 as ，当前 Local 中除了 PA 名字，另外添加了 m1 作为 PA.PB1.pb1_m 的别名。 当执行 #4 后，会将 PA.PB2 、 PA.PB2.pb2_m 载入内存， sys.modules 中会有 PA 、 PA.wave 、 PA.PB1 、 PA.PB1.pb1_m 、 PA.PB2 、 PA.PB2.pb2_m 六个模块。当前 Local 中还是只有 PA 、 m1 。 下面的 #5 ， #6 ， #7 都是可以正确运行的。注意的是：如果 PA.PB2.pb2_m 想导入 PA.PB1.pb1_m 、 PA.wave 是可以直接成功的。最好是采用明确的导入路径，对于 ./.. 相对导入路径还是不推荐用。（2）避免使用全局表达式一个模块中定义的全局变量一般是可以被其他模块所修改的，比如之前的例子中，模块 B 相信 A.x 值是 1 ，但是它不知道在 C.py 中已经对它进行了修改。这些修改直接修改变量值的操作都应该放在 if __name__ == &#39;__main__&#39;: 中。if __name__ == &#39;__main__&#39;: 是指在终端运行该 python 脚本时才会执行的语句，除此之外的所有情况下这些代码都不会执行。（3）变量含义在 Python 中所有的变量名都是一个符号，其实现是将变量名和它的值绑定。 = 号并不代表赋值，而是重新将一个变量名与新的值进行绑定。有了这个理解，你就会对下面的示例有更好地理解：def func1(a): a = &quot;world&quot;def func2(a): a[0] = &quot;world&quot;x = &quot;hello&quot;func1(x)print(x)x = [&quot;hello&quot;]func2(x)print(x)在 func1 中，调用时先将 x 的值同时绑定到参数 a 上，然后将 a 重新绑定到常量 “world” 上，这并不影响 x 绑定在 &quot;hello&quot; 上。而在 func2 中，调用时先将 x 的值（数组）同时绑定到参数 a 上，然后将这个数组的第 0 个数据指向常量 “world” 上，这时 x 绑定的值也发生了变化。如果你有 C/C++ 基础，你可以把所有变量符号想象成一个指针， = 的右操作数就是指针要指向的对象，而 = 就是对指针赋值的过程。（4）原地运算在 Python 中，一些运算是返回备份的，而另一些是直接修改原值的，叫做原地运算。这些运算很多，不可能一一枚举，但我们需要有这样一个概念。例如下面的函数：def minus_one(minuend): minuend -= 1如果你没有办法区分这个函数是否可以直接修改调用时传入的参数值，那么我们推荐将所有函数写成 return 的形式返回运算结果。def minus_one(minuend): return minuend - 1x = 10x = minus_one(x)二、Numpy 基础（0）广播 （broadcasting）在讲解 Numpy 运算之前，我们先要讲一个非常有用的机制——广播（broadcasting），它能自动将两个大小不等的张量通过复制扩展自动变成两个相同大小的张量然后进行运算。尽管它非常有用，但是它也是程序没有报错却也运行结果不对的杀手！（因为程序不会报错，因此你可以使用 assert 确保程序符合你的想法）广播用于对应元素的二元运算，如+-*/等。对应元素的二元运算一般要求两个张量的shape相同，当shape不同时，会触发广播。广播的原则：如果两个数组的后缘维度（trailing dimension，即从末尾开始算起的维度）的轴长度相符，或其中的一方的长度为 1 ，则认为它们是广播兼容的。1. 后缘维度的轴长相符import numpy as npx = np.array([[0, 0, 0],[1, 1, 1],[2, 2, 2], [3, 3, 3]]) y = np.array([1, 2, 3]) print(x + y)上例中 x 的shape为 $(4, 3)$ ，y 的shape 为 $(3, )$ 。虽然前者是一维的，后者是二维的，但是比较后缘维度可知：(4,3) ^ (3, ) ^它们的后缘维度相等， x 的第二维长度为 3 ，和 y 的维度相同。因此他们可以通过广播机制完成相加，在这个例子当中是将 y 沿着 0 轴进行扩展。同样，下图也是可以的。2. 后缘维度不全相同，有一方长度为1import numpy as npx = np.array([[0, 0, 0],[1, 1, 1],[2, 2, 2], [3, 3, 3]]) y = np.array([[1],[2],[3],[4]]) print(x + y)虽然 x 的 shape 为 $(4, 3)$ ， y 的 shape 为 $(4, 1)$ ，但第二个数组在 1 维轴上长度为 1 ，所以可以在 1 轴上进行广播。(4,3) ^ ^(4,1) ^ ^反例：import numpy as npx = np.ones((4,3,5))y = np.ones((4,1,3))print(x + y)代码会报错无法计算，因为从后缘维度数起 2 轴上 x 、 y 大小即不相同也不为 1 。Numpy 中表示张量的数据类型是 ndarray 。我们先介绍 ndarray 对象的基本概念，理解这些概念对你以后了解张量运算和实现有非常大的帮助！（1）张量整体的属性一个张量是由一个数据头和一个数据块指针组成的。数据头中存放了张量的属性值，包括数据类型、数组形状和每个维度的 stride 。数据块指针指向的是张量的数据值，对应内存中的一块连续的内存空间。数据类型很容易理解，比如 int 、 float 、 bool ，这些值代表了多少个内存单元表示一个数据，例如 int 表示一个数据占用 4 个字节。数组形状表示张量的形状大小，它指定了张量的各个维度，例如 $(3,4,5)$ 表示一个 $3\\times4\\times5$ 的张量。我们规定：张量的最后一维称为低维，在低维上数据的内存分布是连续的，而第一个维称为高维。例如上面的例子中最高维是 $3$ 维，最低维是 $5$ 维。每个维度的 stride 是为了方便数据的索引、存放和运算。 stride 表示在每一个维度上加一时需要越过多少个数据。它是通过公式计算得出的，你很快会发现计算过程非常简单。例如，对于 shape 等于 $(3, 4, 5)$ ，那么 stride 等于 $(20, 5, 1)$。记得，最低维的数据是连续的，所以最低维索引加一意味着只要前进一个数据就能得到下一个数据，对于更高维，索引加一意味着需要越过比它维度低的所有数据，也就是比它低维的乘积。下面有个直观的示例，在上图中，紫色数据块第 0 维索引加一，对应红色数据块，此时它需要越过第 0 维大小的数据块个数 5 。之后你也会发现通过改变张量的 shape 和 stride 可以直接实现运算而不需要改变数据内存块！（2）张量中元素的属性一个元素的属性包括 元素值 元素坐标想象一下，对于转置，我们不需要改变数据块，只需要把每个元素的坐标颠倒一下就可以了。（3）张量运算张量有三种运算的方式： 返回 view ，即返回的是数据本身，修改返回值将导致原变量的值发生变化 返回 copy ，即返回的数据的拷贝，后续操作与原变量无关 原地运算，即直接修改数据本身，无返回值三、Numpy 运算下面举的例子都建议你手动在命令行输一遍，我们也提供了 ipynb 教程：链接: https://pan.baidu.com/s/1MOTfMB7XB2eQ-aEwS4z8_g 提取码: twd3。（1） ndarray 对象的创建np.array() ：从 python 列表创建，显式指定每个元素的值。np.empty() ：只指定形状，不指定值。元素值随机。np.zeros() ：只指定形状。元素值全 0 。np.ones() ：只指定形状。元素值全 1 。np.eye() ：创建二维张量，对角线为 1 ，其余为 0 。np.random.randn() ：只指定形状，非元组。元素值标准正态分布。np.random.uniform() ：指定形状和上下限。元素值均匀分布。闭区间。np.random.randint() ：指定形状和上下限。元素值均匀分布，但只会取整数。前闭后开。np.arange() ：创建一维张量。指定起点终点步长，类似 range 。前闭后开。np.linspace() ：创建一维等差数列。指定起点终点数量。闭区间。np.concatenate() ：在某个维度上拼接若干个张量。维度数不变。返回 copy 。除了拼接的维度外要求其它维度大小相等。特殊： torch.cat 。 可以想象成对于索引进行分类讨论，在一些时候选择某一个张量选择值np.stack() ：在某个维度上堆叠若干个张量。维度数增加。返回 copy 。要求所有维度大小相等。 除了第 0 维堆叠不破坏内存连续性外，其他都会破坏。np.meshgrid()：创建网格张量，返回两个张量，分别代表网格的 x 轴和 y 轴。 坐标矩阵其实有大量的重复—— $X$ 的每一行都一样， $Y$ 的每一列都一样。基于这种强烈的规律性， numpy 提供的 numpy.meshgrid() 函数可以让我们快速生成坐标矩阵 $X$ ，$Y$ 。 举例： x, y = np.meshgrid(np.array([0,1,2]), np.array([0,1])) print(x) # [[0,1,2], # [0,1,2]] print(y) # [[0,0,0], # [1,1,1]] （2） ndarray 对象的常用操作shape ：获取当前张量的维度信息（维数以及每一维的长度）。reshape() ：返回更改维度后的 view 。 更改的方式是不破坏内存连续性，只要各维度大小的乘积与原来各维度大小的乘积相等即可。因此，可以想象只需要强行改变 shape ，然后根据 shape 重新计算 stride，就能实现这一功能。例如， shape=(3,4,5) ， stride=(20, 5, 1) 经过 reshape(15, 4) 后 shape=(15, 4) ， stride=(4, 1) ，原数据块不用改变。resize() ：更改自己的维度，无返回值。 不破坏内存连续性transpose() ：返回更改维度顺序后的 view 。返回值内存不连续，但内存地址不变。特殊： torch.permute 。 这个操作通过改变shape 、 stride 即可实现。例如 shape=(3, 4, 5) ， stride=(20, 5, 1) 经过 transpose(2, 0, 1) 后变成 shape=(5, 3, 4) ， stride=(1, 20, 5) 。即对 stride 也进行相同的 transpose ，而不是根据公式重新计算！T ： transpose() 的特殊情况，针对二维张量，返回 view 。squeeze() ：删除长度为 1 的维度，返回 view 。特殊： torch.unsqueeze() ：添加某个长度为 1 的维度，返回 view 。view() ：提供对内存区域不同的切割方式，来完成数据类型的转换，而无须要对数据进行额外的copy，来节约内存空间，返回 view 。转换的数据内存必须是连续分布的。特殊： torch.view 。repeat() ：将某个维度复制 n 次，每个元素复制（因此在某个维度上复制出的数据是聚在一起的），返回 copy 。特殊： torch.repeat 。特殊： torch.expand 。tile() ：相当于多个张量 concatenate() 在一起，但可以同时复制多个维度。copy() ：返回自身的 copy 。特殊： torch.clone() 。astype() ：更改元素数据类型，返回 copy 。（3） ndarray 对象的索引（维度索引和整体索引）切片索引：一次只能索引一个维度。返回 view 。支持原地修改。 一个索引结构如下： [start:end:step] ，其中区间是左闭右开， step 表示一次跳过多少。这三个参数都可以参略，当 start 省略时，默认从第一个开始，即 0 ，当 end 省略时，默认从直到最后一个（包括），当 step 省略时，默认步长为 1 。第一个 : 不能参略。注意对于大小 (3, 4, 5) ，索引 [:, :4, :] 和 [:, :, :] 不同。坐标（列表）索引：一次只能索引一个维度。返回 copy 。支持原地修改。 举例，对一个 $3\\times3\\times3$ 的张量，在第二维度进行索引，并按照 [2, 0] 的顺序返回结果。布尔索引：一次索引整个张量。返回 copy 。支持原地修改。 用一个相同大小的 bool_ 型张量， 1 表示保留该值， 0 表示舍弃该值。返回一维张量，按照数据在内存中的排列顺序排列。区域索引：利用 np.ix_ ，产生笛卡尔积的映射关系。返回 copy 。支持原地修改。 举例，[np.ix_([0,2], [2, 1])] 提取的元素分别是 (0, 2), (0, 1), (2, 2), (2, 1) ，组成一个 $2\\times2$ 的张量。（4） ndarray 对象的运算max() ， min() ， mean() ：在某个维度/整个张量上计算最大值，最小值，平均值。argmax() ， argmin() ：在某个维度上计算最大值坐标，最小值坐标。+-*/ ：对应元素计算。注意 * 表示对应元素相乘，因此两个输入张量大小必须相等。dot() 和 @ ：针对二维张量，矩阵乘法。指数对数三角函数等：每个元素计算。大于小于等于比较运算：每个元素计算。返回布尔张量。floor() ， ceil() ， round() ：向下取整，向上取整，四舍五入。where() ：输入一个布尔张量和两个同形状的其他张量，根据布尔值选择两个张量中的值。即对于每个坐标，如果对应布尔值为 1 ，则选择第一个张量对应位置的值，否则选择第二个张量对应位置的值。（5）np.linalg 线性代数相关运算np.linalg.det() ：求二维矩阵的行列式，输入多维时以最低两维对高维分别进行计算np.linalg.inv() ：求逆np.linalg.eig() ：求特征值特征向量np.linalg.norm() ：求范数 范数是具有“长度”概念的函数。 L0 范数：向量中非 0 的元素的个数。( L0 范数很难优化求解) L1 范数：向量中各个元素绝对值之和。L1 会趋向于产生少量的特征，而其他的特征都是 0 。 L2 范数：向量各元素的平方和然后求平方根。可以防止过拟合，提升模型的泛化能力。L2 会选择更多的特征，这些特征都会接近于 0 。（6）文件 ionp.save 和 np.load ：用于保存和加载一个 ndarray 张量np.savetxt 和 np.loadtxt ：以 txt 格式保存和加载一个二维 ndarray 张量，可以指定分隔符np.savez 和 np.load ：用于同时保存多个 ndarray 张量，输入字典键值对，读取出一个字典四、可视化Matlab 是一个常用的数据分析和绘图软件，在 Python 我们也可以使用 matplotlib 库绘制图形。在进行可视化时，我们使用的是 matplotlib.pyplot 子库。 plt.plot() ：绘制折线图 plt.scatter() ：绘制散点图 plt.bar() ：绘制柱形图 plt.hist() ：绘制柱形图的频率分布 plt.imshow() ：绘制图像（RGB 格式，与 OpenCV 的 BGR 不同） plt.matshow() ：可视化数组（热力图） plt.savefig() ：保存最新绘制的一幅图，在 plt.show() 之前调用 plt.savefig() ；否则保存出去会是白纸一张。 plt.show() ：显示绘制好的图像 plt.imsave() ：保存绘制好的图像 seaborn 库，对 matplotlib 的二次封装，提供更美观的可视化。注意点：形状是参数列表（参数类型）还是以元组/列表（数据类型）表示、区间开闭、运算方式。讲了这么多，一定记住一点：在神经网络中，如果有可能不是用 for 循环，就不要使用 for 循环！五、课后作业为了巩固我们刚才讲解的知识，提升代码的实战能力，请完成以下课后作业 Quiz ，我们提供了参考答案，但这并不是唯一的正确答案。在下面的链接中还有一道较难的机器视觉实战题，我们并不是为了考察机器视觉，所以给出了计算方式，请用 Numpy 运算实现。百度网盘链接: https://pan.baidu.com/s/1OHNeqrErD8zIaBiRyR0lUw 提取码: 60kf如果觉得本教程不错或对您有用，请前往项目地址 https://raw.githubusercontent.com/Harry-hhj/Harry-hhj.github.io 点击 Star :) ，这将是对我的肯定和鼓励，谢谢！六、参考教程 Python 被导入模块多次被加载的问题（基于python的import机制） Numpy学习——广播机制理解作者：Harry-hhj，Github主页：传送门讲师：xinyang，Github主页：传送门" }, { "title": "神经网络课程目录", "url": "/posts/NN-Tutorial-Catalogue/", "categories": "Course, Nerual Network", "tags": "catalog, robomaster", "date": "2021-10-13 00:00:00 +0800", "snippet": "NN Tutorial Catalogue 机械是血肉，电控是大脑，视觉是灵魂。一、培训安排二、培训教程 神经网络集训 —— Numpy 的使用 如果觉得本教程不错或对您有用，请前往项目地址 https://github.com/Harry-hhj/Harry-hhj.github.io 点击 Star :) ，这将是对我的肯定和鼓励，谢谢！作者：Harry-hhj，github主页：传送门" }, { "title": "RM 教程 4 —— 相机", "url": "/posts/RM-Tutorial-4-Camera/", "categories": "Course, RM", "tags": "getting started, robomaster, camera", "date": "2021-10-10 10:00:00 +0800", "snippet": "RM 教程 4 —— 相机 机械是肉体， 电控是大脑， 视觉是灵魂一、相机结构简介广义的相机由两部分组成： 工业相机 镜头（1）工业相机了解工业相机的相关参数能够帮助我们更好的理解相机功能，进而帮助我们完成对相机的选型工作。所谓外行看热闹，内行看门道，工业相机的门道就从其参数开始。1. 分辨率相机的传感器 sensor 是有许多像素点按照矩阵的形式排列而成，分辨率就是以水平方向和垂直方向的像素来表示的。分辨率越高，成像后的图像像素数就越高，图像就越清晰。常用的工业面阵相机分辨率有 130 万、 200 万、 500 万等；对于线阵相机而言，分辨率就是传感器水平方向上的像素数，常见有 1 K、 2 K、 6 K等。在相机分辨率的选型上，要根据我们的项目需求而定，并不一定是分辨率越高就越好，分辨率高带来的图像数据量就大，后期的算法处理复杂度就高，而且一般分辨率大的相机，帧率一般都不会太高。2. 传感器尺寸传感器尺寸是以有效面积（宽x高）或以对角线大小（英寸）来表示的，常见的传感器尺寸如下： 型号 有效面积 宽x高（mm） 1/4″ 3.2mm×2.4mm 1/3″ 4.8mm×3.6mm 1/2″ 6.4mm×4.8mm 2/3″ 8.8mm×6.6mm 1″ 12.8mm×9.6mm 传感器尺寸越大，一定程度上表示相机可容纳像素个数越多，成像的画幅越大（并不一定是视野更大）。3. 像元尺寸像元尺寸就是每个像素的面积。单个像素面积小，单位面积内的像素数量多，相机的分辨率增加，利于对细小缺陷的检测和增大检测视场。随着像素面积的缩小，满阱能力（每个像素能够储存的电荷数量）也随之减小，造成相机动态范围的降低。 4. 像素深度像素深度是指每个像素用多少比特位表示。通常，每个像素的比特位数多，表达图像细节的能力强，这个像素的颜色值更加丰富、分的更细，颜色深度就更深。一般像素深度有1位、8位、16位、24位和32位。灰度显示就是 8 个二进制位， RGB 显示就是 24 个二进制位。5. 动态范围动态范围是用来描述每个像素能够分辨出的灰度等级。它是饱和电压（最大的输出电平）相机输出的噪声之比。宽动态范围能够使场景中非常亮和非常昏暗部分的细节同时被清晰的显示。一般来说，低动态范围的相机噪声比较多，照片会缺失亮部细节和暗部细节。6. 最大帧率最大帧率表示的是面阵工业相机每秒能够采集并输出的最大帧数，这往往和传感器芯片和数据输出接口带宽有关。根据项目需求，对于拍摄运动物体，建议选取高帧率相机，具体帧率数要根据拍摄精度来确定。7. 曝光方式工业相机常见的曝光方式有帧曝光（global shutter）和行曝光（rolling shutter）。帧曝光是指传感器阵列中所有像素同时曝光，曝光周期由预先设定的快门时间确定。这种曝光方式的相机适合拍摄运动物体，图像不会偏移，不会失真。行曝光是指同一行上的像素同时曝光，不同行的曝光起始时间不同，每行的曝光时间是相同的，行间的延迟不变。这种曝光方式的相机适用于拍摄静止的物体，拍摄运动物体，图像会偏移。在工业相机的选型中，一般参数表中会标注全局快门或卷帘快门，他们分别对应帧曝光和行曝光。8. 曝光时间传感器将光信号转换为电信号形成一帧图像，每个像元接受光信号的过程叫曝光，所花费的时间叫曝光时间，也叫快门速度。这个时间是整个算法处理性能的上限。9. 采集模式采集模式分为了连续采集、外触发采集和软触发采集三种。 连续采集指相机进行连续曝光，输出实时图像。这是我们一般连接在电脑上使用相机的方式。 外触发采集是指当相机处于外触发模式后，相机处于待机模式，不曝光，只有当相机通过I/O口接收到相机规定的单个脉冲（方波）信号后，传感器曝光一次，部分相机支持信号的上升沿、下降沿和高低电平的触发。这种方法也是我们比赛所使用的方式，这样的好处是通过固定频率的触发信号，使得相机的数据与陀螺仪的信号尽可能在同一时刻产生，使其数据对齐。 软触发是指当相机处于外触发模式后，相机处于待机模式，不曝光，只有当相机软件发出指令后，传感器曝光一次。10. 增益工业相机通常具有一个对传感器的信号进行放大的视频放大器，其放大倍数称为增益。增益越大，噪声就会变大，对传统图像处理越不利。但这也是减少曝光时间提高图像亮度的一种方式。（2）镜头镜头是摄像机中的光学元件，直接影响成像质量的优劣。分类： 按照焦距分类：焦距决定了相机适合观察什么距离的物体，短焦一般适合观察近距离物体，长焦一般适合观察远距离物体。 按照视角大小分类： 广角：视角大，可观测范围广。但同时会产生较大畸变。 标准：视角小，但产生的畸变也较小。下图是一个畸变的例子： 一般来说，在没有特殊需求的情况下，镜头选型选择标准镜头。 光圈焦距调整方式 固定光圈定焦镜头 手动光圈定焦镜头 自动光圈定焦镜头 手动变焦镜头 自动变焦镜头 …… 在选择镜头时，一般是根据视野的大小确定焦距的。因此我们需要了解 FOV （视场角）。FOV 的全称是 Field of View 。如下图，如果成像平面的宽度 W 固定， FOV 的大小直接由 Focal Length （焦距）决定。 Focal Length 越大，看得越远，但 FOV 越小。 Focal Length 越小，看得越近，但 FOV 变大。如果已知 W 和 Focal Length ， FOV 可以用简单的三角函数关系就可以求出：\\(\\alpha = 2 \\tan^{-1} \\frac{w}{2f}\\)FOV 有三种： HFOV：由 Focal Length 和 senor 的宽度（W）决定 VFOV：由 Focal Length 和 sensor 的高度（H）决定 DFOV：由 Focal Length ， W ， H 共同决定当我们选定了一个相机时，我们就知道了相机芯片的参数，为其配置镜头。当我们选定了一个工业相机时，我们就已经知道它的感光芯片的参数，而我们需要为其配置一个合适的镜头，使得它的视野在我们的需求附近。视野过大，意味着图像中出现大量无关的目标，增加处理负担，同时也会导致目标所占的像素点降低，减少拍摄的特征；视野过小，那么没办法完整地记录目标，从而丧失处理的能力。视野的计算方法比较简单，就是一个相似三角形计算。同样，我们可以用类似的方法估计焦距大小，这也是相机标定的完成方式。（3）队内使用的相机队内现在主要使用的相机型号为 MINDVISION 公司生产的 MV-SUA133GC 。下面为组装好的摄像机图片： 二、相机成像模型相机成像的过程就是世界坐标系向像素坐标系转换的过程，即：世界坐标系(3d) -&amp;gt; 相机坐标系(3d) -&amp;gt; 像平面坐标系(2d) -&amp;gt; 像素坐标系(2d)，经过这样一级一级的转换之后，物体在空间中的坐标即转换为在图像中的像素坐标。四个坐标系的表示如下： 世界坐标系 $X_w, Y_w, Z_w$ 相机坐标系 $(X_c, Y_c, Z_c)$ 像平面坐标系 $(x, y)$ 像素坐标系 $(u, v)$1）世界坐标系(3d) -&amp;gt; 相机坐标系(3d)从世界坐标系到相机坐标系的转换是刚体变换，是旋转动作和平移动作的结果，如下所示：\\(\\begin{bmatrix}X_c\\\\Y_c\\\\Z_c\\\\1\\\\\\end{bmatrix}=\\begin{bmatrix}R&amp;amp;t\\\\0&amp;amp;1\\\\\\end{bmatrix}\\begin{bmatrix}X_w\\\\Y_w\\\\Z_w\\\\1\\\\\\end{bmatrix}\\)旋转矩阵R是正交矩阵，可通过罗德里格斯（Rodrigues）变换转换为只有三个独立变量的旋转向量：\\(\\left\\{\\begin{array}{c}\\theta \\leftarrow norm(r)\\\\r \\leftarrow r/\\theta\\end{array}\\right .\\\\R = \\cos(\\theta)I + (1-\\cos(\\theta))rr^T + \\sin(\\theta) \\begin{bmatrix}0&amp;amp;-r_z&amp;amp;r_y\\\\r_z&amp;amp;0&amp;amp;-r_x\\\\-r_y&amp;amp;r_x&amp;amp;0\\\\\\end{bmatrix}\\)因此，刚体变换可用 6 个参数来描述，这 6 个参数就称为相机的外参（Extrinsic），相机外参决定了空间点从世界坐标系转换到相机坐标系的变换，也可以说外参描述了相机在世界坐标系中的位置和朝向。2）相机坐标系(3d) -&amp;gt; 像平面坐标系(2d)相机坐标系到像平面坐标系的转换如下图所示：根据相似三角形，点 P 在相机坐标系和像平面坐标系中的坐标满足如下关系：\\(\\left \\{ \\begin{array}{c}\\cfrac{x}{f} = \\cfrac{X_c}{Z_c}\\\\\\cfrac{y}{f} = \\cfrac{Y_c}{Z_c}\\\\\\end{array}\\right .\\Longrightarrow\\left \\{ \\begin{array}{c}x = f \\cfrac{X_c}{Z_c}\\\\y = f \\cfrac{Y_c}{Z_c}\\\\\\end{array}\\right .\\)3）像平面坐标系(2d) -&amp;gt; 像素坐标系(2d)图像坐标系坐标轴的单位通常为毫米（mm），原点是相机光轴与相面的交点（称为主点），即图像的中心点，轴、轴分别与轴、轴平行。故两个坐标系实际是平移关系，即可以通过平移就可得到。像素坐标是光在平面成像的一个模拟量，所以需要对成像平面上的像进行采样和量化，得到物体的像在像素平面上的坐标值。像素平面与成像平面之间，相差一个缩放和原点的平移。如下式所示，在 $u$ 轴上放大了 $\\alpha$ 倍，在 $v$ 轴上放大 $\\beta$ 倍，原点平移 $c_x$ ， $c_y$ 。\\(\\left \\{\\begin{array}{c}u = \\alpha x + c_x\\\\v = \\beta y + c_y\\end{array}\\right .\\)这里忽略了相机畸变的影响。代入 $x, y$ 得到：\\(\\left \\{\\begin{array}{c}u = f_x \\cfrac{x_c}{z_c} + c_x\\\\v = f_y \\cfrac{y_c}{z_c} + c_y\\\\\\end{array}\\right .\\)整理成齐次形式：\\(\\begin{bmatrix}u\\\\v\\\\1\\\\\\end{bmatrix}=\\cfrac{1}{z_c}\\begin{bmatrix}f_x&amp;amp;0&amp;amp;c_x\\\\0&amp;amp;f_y&amp;amp;c_y\\\\0&amp;amp;0&amp;amp;1\\\\\\end{bmatrix}\\begin{bmatrix}x_c\\\\y_c\\\\z_c\\\\\\end{bmatrix}\\)最终得到\\(\\begin{bmatrix}u\\\\v\\\\1\\\\\\end{bmatrix}=\\cfrac{1}{z_c}\\begin{bmatrix}f_x&amp;amp;0&amp;amp;c_x\\\\0&amp;amp;f_y&amp;amp;c_y\\\\0&amp;amp;0&amp;amp;1\\\\\\end{bmatrix}\\begin{bmatrix}1&amp;amp;0&amp;amp;0&amp;amp;0\\\\0&amp;amp;1&amp;amp;0&amp;amp;0\\\\0&amp;amp;0&amp;amp;1&amp;amp;0\\\\\\end{bmatrix}\\begin{bmatrix}R&amp;amp;t\\\\0&amp;amp;1\\\\\\end{bmatrix}\\begin{bmatrix}X_w\\\\Y_w\\\\Z_w\\\\1\\\\\\end{bmatrix}\\)即世界坐标到像素坐标的转换过程。三、相机畸变理想的针孔成像模型确定的坐标变换关系均为线性的，而实际上，现实中使用的相机由于镜头中镜片因为光线的通过产生的不规则的折射，镜头畸变（lens distortion）总是存在的，即根据理想针孔成像模型计算出来的像点坐标与实际坐标存在偏差。畸变的引入使得成像模型中的几何变换关系变为非线性，增加了模型的复杂度，但更接近真实情形。畸变导致的成像失真可分为径向失真和切向失真两类：畸变类型很多，总体上可分为径向畸变和切向畸变两类。 径向畸变的形成原因是镜头制造工艺不完美，使得镜头形状存在缺陷，包括枕形畸变和桶形畸变等，可以用如下表达式来描述：\\(\\left \\{\\begin{array}{c}x_0 = x (1 + k_1 r^2+ k_2r^4 + k_3 r^6 )\\\\y_0 = y (1 + k_1 r^2+ k_2r^4 + k_3 r^6 )\\\\\\end{array}\\right .\\) 切向畸变又分为薄透镜畸变和离心畸变等，薄透镜畸变则是因为透镜存在一定的细微倾斜造成的；离心畸变的形成原因是镜头是由多个透镜组合而成的，而各个透镜的光轴不在同一条中心线上。切向畸变可以用如下数学表达式来描述：\\(\\left \\{\\begin{array}{c}x_0 = x + [2p_1y + p_2(r^2 + 2x^2)]\\\\y_0 = y + [2p_2x + p_1(r^2 + 2y^2)]\\\\\\end{array}\\right .\\) 实际计算过程中，如果考虑太多高阶的畸变参数，会导致标定求解的不稳定。在上述的径向畸变和切向畸变的数学模型中，我们一共使用了 $5$ 个参数描述畸变。它们分别是 $[k_1, k_2, k_3, p_1, p_2]$ 。它们被称为畸变参数。注意：鱼眼畸变需要用专门的鱼眼模型。对于相机坐标系中的一个点 $P(X, Y, Z)$ ，我们能够通过 $5$ 个畸变系数找到这个点在像素平面上的正确位置： 将三维空间点投影到归一化图像平面。设它的归一化坐标为 $[x, y]^T$ 。 对归一化平面上的点进行径向畸变和切向畸变纠正。给定归一化坐标，可以求出原始图像上的坐标。\\(\\left \\{\\begin{array}{c}x_{\\text{distorted}} = x (1 + k_1 r^2+ k_2r^4 + k_3 r^6 ) + [2p_1y + p_2(r^2 + 2x^2)]\\\\y_{\\text{distorted}} = y (1 + k_1 r^2+ k_2r^4 + k_3 r^6 ) + [2p_2x + p_1(r^2 + 2y^2)]\\\\\\end{array}\\right .\\) 将纠正后的点通过内参数矩阵投影到像素平面，得到该点在图像上的正确位置。\\(\\left \\{\\begin{array}{c}u = f_x x_{\\text{distorted}} + c_x\\\\v = f_y y_{\\text{distorted}} + c_y\\\\\\end{array}\\right .\\) 四、相机标定我们可以使用标定板辅助进行相机标定。这是一个非常贵重且易损坏的工具，使用时一定要小心！1）相机标定的程序实现1. 寻找标定板角点OpenCV提供了寻找标定板棋盘格角点的函数findChessboardCorners()，他的声明如下：bool cv::findChessboardCorners(InputArray image, Size patternSize, OutputArray corners, int flags = CALIB_CB_ADAPTIVE_THRESH+CALIB_CB_NORMALIZE_IMAGE)你只需在意前三个参数，他们分别意为： image 输入的图像 patternSize 棋盘格的大小，例如这一棋盘格的大小为(11, 8)，要注意的是棋盘格的大小只考虑内侧的角点数 corners 输出结果，用向量的形式储存输出的角点2. 对找到的角点亚像素精化OpenCV提供了函数find4QuadCornerSubpix()来实现对棋盘格角点的亚像素精化，他的声明如下：bool cv::find4QuadCornerSubpix(InputArray img, InputOutputArray corners, Size region_size)。它的功能为在给定的点的周围一定范围内以亚像素的精度逼近角点。下面说明部分参数意义： corners 需要逼近的角点的初始值 region_size 在region_size内寻找角点 利用find4QuadCornerSubpix函数可以更精确的找到角点，提高标定的精度。3. 相机标定OpenCV提供了函数calibrateCamera()来实现相机标定的相关功能，他的声明如下double cv::calibrateCamera(InputArrayOfArrays objectPoints, InputArrayOfArrays imagePoints, Size imageSize, InputOutputArray cameraMatrix, InputOutputArray distCoeffs, OutputArrayOfArrays rvecs, OutputArrayOfArrays tvecs, int flags = 0, TermCriteria criteria = TermCriteria(TermCriteria::COUNT+TermCriteria::EPS, 30, DBL_EPSILON) ) 下面说明他的参数的意义： objectPoints 棋盘格上的角点对应的世界坐标系中的位置 imagePoints 棋盘格上找到的角点 imageSize 图片的大小 cameraMatrix 输出的相机内参矩阵 distCoeffs 输出的相机畸变矩阵 rvecs 相机坐标系与世界坐标系的旋转向量 tvecs 相机坐标系与世界坐标系的平移向量 4. 程序以下为程序的实现：链接: https://pan.baidu.com/s/1I0PD_DWOrrHCjrLXzzAo_g 提取码: 1ur9#include &amp;lt;iostream&amp;gt;#include &amp;lt;opencv2/opencv.hpp&amp;gt;#include &amp;lt;opencv2/core/core.hpp&amp;gt;using namespace cv;int main() { const int board_w = 11, board_h = 8; const int board_n = board_w * board_h; Size board_size( 11, 8 ); Mat gray_img, drawn_img; std::vector&amp;lt; Point2f &amp;gt; point_pix_pos_buf; std::vector&amp;lt; std::vector&amp;lt;Point2f&amp;gt; &amp;gt; point_pix_pos; int found, successes = 0; Size img_size; int cnt = 0; int k = 0, n = 0; for (int i = 0; i &amp;lt; 20; i++){ cv::Mat src0 = cv::imread(std::__cxx11::to_string(i).append(&quot;.jpg&quot;)); if ( !cnt ) { img_size.width = src0.cols; img_size.height = src0.rows; } found = findChessboardCorners( src0, board_size, point_pix_pos_buf ); if ( found &amp;amp;&amp;amp; point_pix_pos_buf.size() == board_n ) { successes++; cvtColor( src0, gray_img, COLOR_BGR2GRAY ); find4QuadCornerSubpix( gray_img, point_pix_pos_buf, Size( 5, 5 ) ); point_pix_pos.push_back( point_pix_pos_buf ); drawn_img = src0.clone(); drawChessboardCorners( drawn_img, board_size, point_pix_pos_buf, found ); imshow( &quot;corners&quot;, drawn_img ); waitKey( 50 ); } else std::cout &amp;lt;&amp;lt; &quot;\\tbut failed to found all chess board corners in this image&quot; &amp;lt;&amp;lt; std::endl; point_pix_pos_buf.clear(); cnt++; }; std::cout &amp;lt;&amp;lt; successes &amp;lt;&amp;lt; &quot; useful chess boards&quot; &amp;lt;&amp;lt; std::endl; Size square_size( 10, 10 ); std::vector&amp;lt; std::vector&amp;lt; Point3f &amp;gt; &amp;gt; point_grid_pos; std::vector&amp;lt; Point3f &amp;gt; point_grid_pos_buf; std::vector&amp;lt; int &amp;gt; point_count; Mat camera_matrix( 3, 3, CV_32FC1, Scalar::all( 0 ) ); Mat dist_coeffs( 1, 5, CV_32FC1, Scalar::all( 0 ) ); std::vector&amp;lt; Mat &amp;gt; rvecs; std::vector&amp;lt; Mat &amp;gt; tvecs; for (int i = 0; i &amp;lt; successes; i++ ) { for (int j = 0; j &amp;lt; board_h; j++ ) { for (int k = 0; k &amp;lt; board_w; k++ ){ Point3f pt; pt.x = k * square_size.width; pt.y = j * square_size.height; pt.z = 0; point_grid_pos_buf.push_back( pt ); } } point_grid_pos.push_back( point_grid_pos_buf ); point_grid_pos_buf.clear(); point_count.push_back( board_h * board_w ); } std::cout &amp;lt;&amp;lt; calibrateCamera( point_grid_pos, point_pix_pos, img_size, camera_matrix, dist_coeffs, rvecs, tvecs ) &amp;lt;&amp;lt; std::endl; std::cout &amp;lt;&amp;lt; camera_matrix &amp;lt;&amp;lt; std::endl &amp;lt;&amp;lt; dist_coeffs &amp;lt;&amp;lt; std::endl; return 0;}如果想要将畸变的图像还原为原图，可以使用函数cvUndistort2( ImageC1, Show1, &amp;amp;intrinsic_matrix, &amp;amp;distortion_coeffs);来进行图像矫正。五、作业请你自己编写一个相机标定程序，对下压缩包内的两个相机进行标定，分别给出标定的结果（重投影误差，相机内参矩阵，畸变矩阵）。不要复制粘贴！链接: https://pan.baidu.com/s/1yzcor8vEUOs2CmfF6BVGRw 提取码: 01b4如果觉得本教程不错或对您有用，请前往项目地址 https://github.com/Harry-hhj/Harry-hhj.github.io 点击 Star :) ，这将是对我的肯定和鼓励，谢谢！六、参考教程 浅析相机FOV 工业相机常见参数 相机成像模型 相机的那些事儿 (二)成像模型第一作者：Harry-hhj，Github主页：传送门第二作者：E-T-E-R-N-A-L-B-L-U-E，传送门" }, { "title": "RM 教程 3 —— OpenCV 传统视觉", "url": "/posts/RM-Tutorial-3-Getting-Started-with-OpenCV/", "categories": "Course, RM", "tags": "getting started, robomaster, opencv", "date": "2021-10-02 18:05:00 +0800", "snippet": "RM 教程 3 —— OpenCV 传统视觉 机械是血肉，电控是大脑，视觉是灵魂。本片教程主要集中于边缘及轮廓检测。一、OpenCV 基本组件 - MatMat 是 OpenCV 中常用的基本类型，即矩阵类。在计算机内存中，数字图像以矩阵的形式存储和运算，因此 OpenCV 中常常用 Mat 储存图像数据。Mat 本质上由两个数据部分组成：矩阵头和一个指向像素数据的指针。矩阵头部的大小是恒定的。然而，矩阵本身的大小因图像的不同而不同。这一数据结构的好处是： Mat 的每个对象具有其自己的头，但可通过矩阵指针指向同一地址让两个实例之间共享该矩阵。除非你明确指明需要复制数据，不然 Mat 只会复制矩阵头部，并将数据指针指向同一地址，而不会复制矩阵本身。1）构造函数Mat 常用的构造方式有两种： Mat() ：这种 Mat 由于未定义维度和大小，无法直接使用，一般用来接收函数的输出，被重新赋值 Mat (int rows, int cols, int type) ：创建一个行数为 rows ，列数为 cols ，数据类型为 type 的矩阵。 type ：CV_[位数][有无符号][数据类型][通道数] ，对于图片值一般为 CV_8UC3 ，其中 8U 代表 8 位无符号整数， C3 代表 3 通道，这是一般用来储存 3 通道图像的格式。当然 type 还有很多其他类型，例如 CV_64FC1 表示一般的实数矩阵。 2）初始化初始化一个矩阵有两种方式：等号赋值或 create() 成员函数 。cv::Mat src = imread(&quot;logo.png&quot;);cv::Mat src;if (src.empty()) { src.create(3, 3, CV_8UC3); // 这种方法创建的内存空间一定是连续的}3）成员变量和函数比较常用的获取矩阵信息的变量和函数有：cv::Mat src1(3, 3, CV_8UC3);std::cout &amp;lt;&amp;lt; src1.cols &amp;lt;&amp;lt; std::endl; // 图片行数：3std::cout &amp;lt;&amp;lt; src1.rows &amp;lt;&amp;lt; std::endl; // 图片列数：3std::cout &amp;lt;&amp;lt; src1.channels() &amp;lt;&amp;lt; std::endl; // 图片通道数，注意是成员函数：34）拷贝通过下面这个例子，你会很容易理解为什么当我们想复制数据时必须显示指明：cv::Mat src2(4, 4, CV_8UC3);std::cout &amp;lt;&amp;lt; &quot;Pointer src2.data points to&quot; &amp;lt;&amp;lt; (void*)src2.data &amp;lt;&amp;lt; std::endl;cv::Mat src2_copy1 = src2;std::cout &amp;lt;&amp;lt; &quot;Pointer src2_copy1.data points to&quot; &amp;lt;&amp;lt; (void*)src2_copy1.data &amp;lt;&amp;lt; std::endl;cv::Mat src2_copy2 = src2.clone();std::cout &amp;lt;&amp;lt; &quot;Pointer src2_copy2.data points to&quot; &amp;lt;&amp;lt; (void*)src2_copy2.data &amp;lt;&amp;lt; std::endl;程序运行结果：可以看到通过等号赋值的 src2_copy1 的指针与 src2 指向同一片内存地址，这意味着对任意一个变量的操作会影响另一个，而通过使用 clone() ，系统为新的变量 src_copy2 创建了一块新的内存空间，并把原始变量拷贝了过去。除了 clone() 外，成员函数 copyto(cv::Mat dst) 也有相同的效果。TODO：refcount5）格式化输出使用 std::cout 来格式化输出 Mat 类型的变量，仅限于二维的。cv::Mat src3 = cv::Mat::zeros(5, 5, CV_64F);// 默认格式std::cout &amp;lt;&amp;lt; src3 &amp;lt;&amp;lt; std::endl;// python 格式std::cout &amp;lt;&amp;lt; cv::format(src3, cv::Formatter::FMT_PYTHON) &amp;lt;&amp;lt; std::endl;// C 格式std::cout &amp;lt;&amp;lt; cv::format(src3, cv::Formatter::FMT_C) &amp;lt;&amp;lt; std::endl;// numpy 格式std::cout &amp;lt;&amp;lt; cv::format(src3, cv::Formatter::FMT_NUMPY) &amp;lt;&amp;lt; std::endl;输出结果如下：6）矩阵的随机访问Mat 类型本身没有实现 [] 的随机访问，因此如果想要随机访问矩阵中的元素，需要其他方法。 Mat 提供了 at 方法，其声明如下： template&amp;lt;typename _Tp &amp;gt;_Tp&amp;amp; cv::Mat::at(int row, int col) 通过 at 方法，可以随机访问 row 行 col 列的元素，下面是一个简单的例子： cv::Mat src4 = cv::Mat::eye(3, 3, CV_8UC1);src4.at&amp;lt;uint8_t&amp;gt;(1, 1) = static_cast&amp;lt;uint8_t&amp;gt;(2);std::cout &amp;lt;&amp;lt; src4 &amp;lt;&amp;lt; std::endl; 从结果可以看出，第 1 行 1 列的元素从 $1$ 变成了 $2$ ： Mat 类提供的 ptr 方法也可以借助指针的方式实现随机访问，其声明如下： uchar* cv::Mat::ptr(int i0 = 0) 通过 ptr 方法，可以返回矩阵第 i0 行的指针，通过指针进一步访问矩阵的元素，下面是一个 简单的例子： cv::Mat src5 = cv::Mat::eye(3, 3, CV_8UC1);uchar *ptr = src5.ptr(1);ptr[1] = 2;std::cout &amp;lt;&amp;lt; src5 &amp;lt;&amp;lt; std::endl; 从结果可以看出，该代码达到了和 at() 一样的效果： 7）Mat 简单运算 复制 clone() 为什么要使用 clone() 而不能使用 = 在上面已经讲过了，这里举个例子让读者直观感受两种操作的不同： cv::Mat src6 = cv::Mat::eye(3, 3, CV_8UC1);cv::Mat src6_copy1 = src6;cv::Mat src6_copy2 = src6.clone();src6.at&amp;lt;uint8_t&amp;gt;(1, 1) = 5;std::cout &amp;lt;&amp;lt; &quot;src6_copy1:\\n&quot; &amp;lt;&amp;lt; src6_copy1 &amp;lt;&amp;lt; std::endl;std::cout &amp;lt;&amp;lt; &quot;src6_copy2:\\n&quot; &amp;lt;&amp;lt; src6_copy2 &amp;lt;&amp;lt; std::endl; 结果是 = 复制的矩阵 src6_copy1 被同时修改，而通过 clone() 复制的 src6_copy2 没有变化： 如果想要安全地复制，使用 OpenCV 提供的矩阵复制函数。 + 、 - 、 * + OpenCV中重载了矩阵的 + 运算符，同时有 virtual void cv::MatOp::add(const MatExpr &amp;amp;expr1, const MatExpr &amp;amp;expr2, MatExpr &amp;amp;res) 方法实现了加法运算。 - OpenCV中重载了矩阵的 - 运算符，同时有 virtual void cv::MatOp::subtract(const MatExpr &amp;amp;expr1, const MatExpr &amp;amp;expr2, MatExpr &amp;amp;res) 方法实现了减法运算。 * OpenCV中重载了矩阵的 * 运算符，对应矩阵乘法。而 void cv::multiply(const MatExpr &amp;amp;expr1, const MatExpr &amp;amp;expr2, MatExpr &amp;amp;res) 函数实现的是矩阵的对应位数据相乘，而不是矩阵乘法。 cv::Mat src7 = cv::Mat::eye(2, 2, CV_64FC1);cv::Mat src8 = (cv::Mat_&amp;lt;double&amp;gt;(2, 2) &amp;lt;&amp;lt; 1, 1, 1, 1);std::cout &amp;lt;&amp;lt; &quot;src7 * src8 = \\n&quot; &amp;lt;&amp;lt; src7 * src8 &amp;lt;&amp;lt; std::endl;cv::Mat res;cv::multiply(src7, src8, res);std::cout &amp;lt;&amp;lt; &quot;cv::multiply(src7, src8, res) = \\n&quot; &amp;lt;&amp;lt; res &amp;lt;&amp;lt; std::endl; 最终两种运算的结果是不同的： 8）读写图片和视频OpenCV 中提供了函数 Mat cv::imread(const String &amp;amp;filename, int flags = IMREAD_COLOR) 实现从指定文件中读取图片，通过函数 cv::imwrite(const String &amp;amp;location, const cv::Mat &amp;amp;src) 实现。OpenCV 中提供了 VideoCapture 类完成读取视频的工作。cv::VideoCapture cap(PROJECT_DIR&quot;/assets/test.avi&quot;);assert(cap.isOpened());std::cout &amp;lt;&amp;lt; (int)cap.get(cv::CAP_PROP_FRAME_HEIGHT) &amp;lt;&amp;lt; &quot; &quot; &amp;lt;&amp;lt; (int)cap.get(cv::CAP_PROP_FRAME_WIDTH) &amp;lt;&amp;lt; std::endl;cv::VideoWriter writer(PROJECT_DIR&quot;/assets/test_copy.avi&quot;, cv::VideoWriter::fourcc(&#39;M&#39;, &#39;J&#39;, &#39;P&#39;, &#39;G&#39;), 10, {(int)cap.get(cv::CAP_PROP_FRAME_WIDTH), (int)cap.get(cv::CAP_PROP_FRAME_HEIGHT)}, true);cv::Mat src10;cv::namedWindow(&quot;video&quot;);std::cout &amp;lt;&amp;lt; &quot;press q to exit.&quot; &amp;lt;&amp;lt; std::endl;while (cap.read(src10)) { cv::imshow(&quot;video&quot;, src10); writer.write(src10); // writer &amp;lt;&amp;lt; src10; char k = cv::waitKey(200); if (k == &#39;q&#39;) break;}cv::destroyWindow(&quot;video&quot;);cap.release();writer.release();二、为什么要做边缘检测大多数图像处理软件的最终目的都是识别与分割。识别即“是什么”，分割即“在哪里”。而为了将目标物体从图片中分割出来，如果这个物体有着鲜明的特征，使得目标物体和背景有着极大的区分度（如黑暗中的亮点，大面积的色块），我们就可以比较容易的将这个物体提取出来。因为现在的目标物体和背景有着极大的区分度，也就意味着目标和背景有着明显的“分界线”，也就是边缘；而多个连续的边缘点，就构成了这个物体的轮廓。所以我们可以将检测物体这个任务，转换为检测物体和背景的分界线，也就是边缘检测。三、如何进行边缘检测在进行边缘检测之前，我们首先需要明确，我们想对图像中的哪种信息进行边缘检测。一般来讲，我们会对图像的亮度信息进行边缘检测，也就是在单色灰度图上检测边缘，此时检测到的边缘点是亮度变化较大的点。但有的时候，目标和背景的亮度差异不大，没法通过亮度边缘确定目标和背景的分界线；但目标和背景的颜色差异可能很大，这时就会对图像的颜色信息进行边缘检测，此时检测到的边缘点就是颜色变化最大的点。在确定了我们想检测怎样的边缘后，我们就需要一个方法把边缘给找出来。下面介绍几个常用的方法（假设我们现在是要检测亮度边缘）为了进行对一个图片的亮度进行判断，我们需要把一个 RGB 图片转成灰度图片，转换后越亮的像素点越接近白色（255），而越暗的像素点越接近黑色（0），图像由三通道变为单通道。其原理是：RGB 值和灰度的转换，实际上是人眼对于彩色的感觉到亮度感觉的转换，这是一个心理学问题，有一个公式：\\(Grey = 0.299*R + 0.587*G + 0.114*B\\)可以通过将浮点数运算转化为整数运算，整数运算转换为位操作进行优化。在 OpenCV 中，提供了 cv::cvtColor() 函数完成各种颜色空间的转换：void cv::cvtColor(cv::InputArray src, cv::OutputArray dst, int code, int dstCn = 0); 例如对于下面这张图片：我们通过以下代码将其转化为灰度图：cv::Mat img = cv::imread(PROJECT_DIR&quot;/assets/apple.jpg&quot;);cv::Mat gray;cv::cvtColor(img, gray, cv::COLOR_BGR2GRAY);cv::imshow(&quot;gray&quot;, gray);cv::waitKey(0);有另一种方法是在读如图片时指定读取灰度图，但是由于其实用性较低，不与赘述。1）二值化由于目标和背景的亮度差异很大，那么最简单的想法就是设定一个阈值，亮度高于该阈值的像素设为目标，亮度低于该阈值的像素设为背景。而这两片区域的交界处便是边缘。再特殊一点：目标的亮度不一定就是很高，或者很低，而是在一个范围内（如100~150），此时我们的二值化就和上面有一定的区别，将这两个阈值范围内的像素设为目标，不在该范围内的设为边缘。更进一步：二值化指的是一个函数 f(x) ，其自变量是某个像素的亮度值，其因变量（或者说函数的输出）是 $255$ 或 $0$ ，分别代表目标和背景。在 OpenCV 中，对应实现这一功能的函数是：double cv::threshold(InputArray src, OutputArray dst, double thresh, double maxval, int type)参数： src：输入 dst：输出 thres：设定的二值化阈值 maxval：使用 THRESH_BINARY 或 THRESH_BINARY_INV 进行二值化时使用的最大值 type：二值化算法类型 THRESH_BINARY：将小于 thres 的值变为 0 ，大于 thres 的值变为 255 THRESH_BINARY_INV：将小于 thres 的值变为 255, 大于 thres 的值变为 0 THRESH_TRUNC：将大于 thres 的值截取为 thres, 小于 thres 的值不变 THRESH_TOZERO：将小于 thres 的值变为 0 , 大于 thres 的值不变 THRESH_TOZERO_INV：将大于 thres 的值变为 0 , 小于 thres 的值不变 举个例子，现在我们需要将这样一种图进行二值化，提取其中棋盘格黑色的区域：我们用下面这段程序实现了这一功能：可以看到我们很好地提取出了黑色的部分。2） 自适应二值化1. 全局自适应由于图片的亮度很容易受到环境的影响，比如环境亮度不同，相机曝光不同等因素都可能影响到最终成像出来的图片的亮度。这样，原本在较亮环境下设定的 180 的亮度阈值可以较好和分割出目标，到了较暗环境下效果就变差，甚至完全不起作用了。但是环境对成像图片亮度的影响是整体的，也就是说整张图片一起变亮或者一起变暗，原本比背景亮的目标物体，在较暗环境下同样应该比背景亮。基于这一点，我们可以提出一个简易的自适应二值化方法：对图像所有像素的亮度值进行从大到小排序，取前 20%（该数值为人为设定的阈值参数）的像素作为目标，其余为背景。OpenCV 中常用的方法有 大津二值化 方法。对于之前提到的函数 threshold() ，当 type = cv::THRESH_OTSU 时，参数 thresh 无效，具体数值由大津法自行计算，并在函数的返回值中返回。下面是一个使用 大津法 计算 thresh 的例子。double thres = cv::threshold(src, binary_img, 100, 255, cv::THRESH_OTSU);程序运行的结果与手动设定阈值的结果相似。但是设定单一阈值的方法仍然有明显的缺点，对于一张图中有明显的光线亮度渐变的图像，单一阈值往往难以起到好的效果。2. 局部自适应例如下图这张图片，左侧的亮度明显高于右下角：如果使用大津法自动求阈值并直接二值化，会得到类似下图的结果：为了解决这种问题，我们需要对每个区域局部适应区域内的灰度情况，对每个区域使用不同的阈值分别二值化。 OpenCV 中提供了 adaptiveThreshold 方法实现这一功能。函数的声明如下：void cv::adaptiveThreshold(InputArray src, OutputArray dst, double maxValue, int adaptiveMethod, int thresholdType, int blockSize, double C)其中： adaptiveMethod 为自适应二值化算法使用的方法； blockSize 为自适应二值化的算子大小，注意必须为奇数； C 为用来手动调整阈值的偏置量大小。自适应二值化算法的运行结果如下：3） 基于梯度的边缘在上述全局的方法中，通过一个阈值将整张图片分为两个部分，而两部分的交界处就作为边缘。这样的一个做法还有另一个缺点，如果图像中有一片区域亮度从低逐渐过渡到高，二值化同样会把这片区域分为两块。即，二值化得出的边缘，并不一定是图像中亮度变化最大（或较大）的地方。由于目标和背景亮度差异较大，所以交界处一定是图像中亮度变化最大（或较大）的地方。为了解决该问题，还可以使用基于梯度的边缘。二值化和梯度检测是两种不同的方法。其基本思想是：首先计算图片中每个像素点的亮度梯度大小（一般使用Sobel算子），然后设定一个阈值，梯度高于该阈值的作为边缘点。同样，类似与自适应二值化，这个阈值也可以设定成一个比值。在实际使用中，我们通常会使用 Canny 算法进行基于梯度的边缘检测，这个算法中做了很多额外措施，使得边缘检测的效果较好。OpenCV 中 Canny 算法的函数声明如下：void cv::Canny(InputArray image, OutputArray edges, double threshold1, double threshold2, int apertureSize = 3, bool L2gradient = false)对于下面这张图：我们使用下面的程序进行梯度边缘检测：cv::Mat task3_img = cv::imread(PROJECT_DIR&quot;/assets/energy.jpg&quot;, cv::IMREAD_GRAYSCALE);cv::Mat task3_result;cv::Canny(task3_img, task3_result, 125, 225, 3);cv::imshow(&quot;task3_canny&quot;, task3_result);cv::waitKey(0);程序的结果是：4）补充：检测颜色边缘在上面几种方法中，我们都是进行亮度边缘检测，亮度边缘检测有一个明显的特征，即每个像素的亮度都可以用一个数值进行表达。但当我们想进行颜色边缘检测时，我们似乎并不能用一个数值来表达该像素的颜色差异，必须使用 RGB 三通道数值才能表达一个像素的颜色。首先，在 RGB 颜色表示方法中，每个颜色分量都包含了该像素点的颜色信息和亮度信息。我们希望对 RGB 颜色表示进行一个变换，使得像素点的颜色信息和亮度信息可以独立开来。为此，我们可以使用 HSV 颜色空间。hsv 六棱锥在 HSV 颜色空间中， H 分量代表色度，即该像素是哪种颜色； S 分量代表饱和度； V 分量代表亮度（和光强度之间并没有直接的联系）。这种颜色表示方法很好地将每个像素的颜色、饱和度和亮度独立开。至于 RGB 颜色空间如何转换为 HSV 颜色空间，这里不作介绍，有兴趣可以自行百度。有了 HSV 颜色空间，由于其 H 通道就代表了像素的颜色，我们就可以在 H 通道上使用上述几种边缘检测方式，从而得出颜色边缘。以下是几种常见颜色的 hsv 阈值，每种颜色对应 HSV 空间中的一块区域，在各通道上呈现一个或两个区间：这些数值可以作为调参的一个初值。OpenCV 提供了 inRange() 函数完成区间的筛选：void cv::inRange(InputArray src, InputArray lowerb, InputArray upperb, OutputArray dst)其中 lowerb 和 upperb 分别对应 HSV 空间中坐标范围的下界和上界。如果需要提取多个 HSV空间范围中的颜色，那么需要执行多次 inRange 并将得到的颜色取并集。我们以下图为例：我们想要提取的颜色为红色和橙色的区域，通过百度搜索，我们了解到红色和橙色的颜色在 HSV 空间中处于区间 $[(0, 43, 46), (255, 255, 255)] \\cup [(156, 43, 46), (180, 255, 255)]$ 中。cv::Mat task4_img = cv::imread(PROJECT_DIR&quot;/assets/energy.jpg&quot;);cv::Mat task4_hsv;cv::cvtColor(task4_img, task4_hsv, cv::COLOR_BGR2HSV);cv::Mat task4_hsv_part1, task4_hsv_part2;cv::inRange(task4_hsv, cv::Scalar(0, 43, 46), cv::Scalar(25, 255, 255), task4_hsv_part1);cv::inRange(task4_hsv, cv::Scalar(156, 43, 46), cv::Scalar(180, 255, 255), task4_hsv_part2); // 提取红色和橙色cv::Mat task4_ones_mat = cv::Mat::ones(cv::Size(task4_img.cols, task4_img.rows), CV_8UC1);cv::Mat task4_hsv_result = 255 * (task4_ones_mat - (task4_ones_mat - task4_hsv_part1 / 255).mul(task4_ones_mat - task4_hsv_part2 / 255));// 对hsv_part1的结果和hsv_part2的结果取并集cv::imshow(&quot;hsv&quot;, task4_hsv_result);cv::waitKey(0);程序结果如下：当然， HSV 颜色提取虽然是一种非常优秀的二值化方法，但他也存在自己的局限性。例如亮度的变化会对 HSV 数值造成干扰。同时，在实际使用过程中，如果相机的感光元件敏感度较高，也会造成图像中出现噪点，形成椒盐噪声。此外，在感光角度不同时，相机获取到的颜色饱和度和色相也会发生一定程度的变化，造成 HSV空洞 。这里我们顺便提供一段 HSV 的调参界面代码：void HSV_calib(const cv::Mat img, int *thres, int mode) { // mode: 0 for red; 1 for green; 2 for blue; cv::Mat imgHSV; cv::cvtColor(img, imgHSV, cv::COLOR_BGR2HSV); cv::namedWindow(&quot;Control&quot;, cv::WINDOW_AUTOSIZE); //create a window called &quot;Control&quot; thres[0] = (mode == 0) ? 156 : ((mode == 1) ? 100 : 35); thres[1] = (mode == 0) ? 180 : ((mode == 1) ? 140 : 70); thres[2] = (mode == 0) ? 43 : ((mode == 1) ? 90 : 43); thres[3] = (mode == 0) ? 255 : ((mode == 1) ? 255 : 255); thres[4] = (mode == 0) ? 46 : ((mode == 1) ? 90 : 43); thres[5] = (mode == 0) ? 255 : ((mode == 1) ? 255 : 255); //Create trackbars in &quot;Control&quot; window cv::createTrackbar(&quot;LowH&quot;, &quot;Control&quot;, &amp;amp;thres[0], 179); //Hue (0 - 179) cv::createTrackbar(&quot;HighH&quot;, &quot;Control&quot;, &amp;amp;thres[1], 179); cv::createTrackbar(&quot;LowS&quot;, &quot;Control&quot;, &amp;amp;thres[2], 255); //Saturation (0 - 255) cv::createTrackbar(&quot;HighS&quot;, &quot;Control&quot;, &amp;amp;thres[3], 255); cv::createTrackbar(&quot;LowV&quot;, &quot;Control&quot;, &amp;amp;thres[4], 255); //Value (0 - 255) cv::createTrackbar(&quot;HighV&quot;, &quot;Control&quot;, &amp;amp;thres[5], 255); std::vector&amp;lt;cv::Mat&amp;gt; hsvSplit; //因为我们读取的是彩色图，直方图均衡化需要在HSV空间做 cv::split(imgHSV, hsvSplit); cv::equalizeHist(hsvSplit[2], hsvSplit[2]); cv::merge(hsvSplit, imgHSV); cv::Mat imgThresholded; while (true) { cv::inRange(imgHSV, cv::Scalar(thres[0], thres[2], thres[4]), cv::Scalar(thres[1], thres[3], thres[5]), imgThresholded); //Threshold the image //开操作 (去除一些噪点) cv::Mat element = getStructuringElement(cv::MORPH_RECT, cv::Size(5, 5)); cv::morphologyEx(imgThresholded, imgThresholded, cv::MORPH_OPEN, element); //闭操作 (连接一些连通域) cv::morphologyEx(imgThresholded, imgThresholded, cv::MORPH_CLOSE, element); cv::imshow(&quot;Thresholded Image&quot;, imgThresholded); //show the thresholded image cv::imshow(&quot;Original&quot;, img); //show the original image char key = (char) cv::waitKey(300); if (key == 27) { cv::destroyWindow(&quot;Control&quot;); break; } else continue; }}四、边缘检测的后处理不论是使用二值化、还是自适应二值化、还是基于梯度的边缘检测方法，其检测结果都不可能正好分毫不差的将目标完整保留下来，并将背景完全剔除。即使图像质量极佳，或者目标特征极为明显，使得正好将目标和背景区分开，检测结果也还停留于像素层面，即每个像素是目标还是背景，而我们想要的则是目标在哪片区域。所以后处理的目的主要有三个：剔除错误的背景边缘、补充缺失的目标边缘、将目标表达成一个区域。对于前两点，我们通常会首先使用开闭运算处理二值化图或边缘图（取决于之前你采用的策略）。其中开运算连接断开区域，闭运算删除游离的噪声区域。详细算法的计算方式，这里不作介绍，有兴趣可以自行百度。图像滤波亦能达到类似的效果。对于第三点，我们会使用轮廓检测。轮廓可以理解为一系列连通的边缘点，并且这些边缘点可以构成一个闭合曲线。1）滤波滤波通常是对二值化方法使用的。在对现实中的图像进行二值化时，二值化的结果往往难以达到最佳状态。许多情况下，二值化会产生空洞或形成噪点。在这种情况下就需要滤波和形态学运算这两大工具来提升二值化结果的质量。滤波类似于卷积，有一个叫做算子的东西处理图像的局部特征。在开始之前，我们本节中的所有实例会针对以下图片进行。下面介绍几个比较常用的滤波算法。1. 均值滤波均值滤波是最简单的滤波，也被成为线性平滑滤波。其算子可以表达为：\\(K = \\cfrac{1}{\\text{ksize.width} \\times \\text{ksize.height}}\\begin{bmatrix}1&amp;amp;1&amp;amp;\\cdots&amp;amp;1\\\\\\vdots&amp;amp;\\vdots&amp;amp;\\ddots&amp;amp;\\vdots\\\\1&amp;amp;1&amp;amp;\\cdots&amp;amp;1\\\\\\end{bmatrix}\\)即对大小为 $M \\times N$的矩形框内的像素取平均值。OpenCV 中对应的函数是：void cv::blur(InputArray src, OutputArray dst, Size ksize, Point anchor = Point(-1,-1), int borderType = BORDER_DEFAULT)对例子中的图片应用均值滤波：cv::Mat blured_img;cv::blur(img, task5_blured_img, cv::Size(7, 7));结果如下中值滤波的效果是使得图片更加模糊，削弱噪声的边缘梯度，使其看起来不那么显著，但是噪声本身并没有得到很好的消除，同时有用的信息也被削弱了。均值滤波是最快速的滤波算法之一，但同时它的效果却也不够理想，一般无法有效地去除椒盐噪声。2. 高斯滤波高斯滤波通过对图像卷积高斯滤波算子实现滤波的效果。高斯算子如下：\\(G(x, y) = \\cfrac{1}{2\\pi\\rho^2} e^{-c\\frac{x^2+y^2}{2\\rho^2}}\\)例如这就是一个高斯算子：\\(\\frac{1}{16} \\times \\begin{bmatrix}1&amp;amp;2&amp;amp;1\\\\2&amp;amp;4&amp;amp;2\\\\1&amp;amp;2&amp;amp;1\\\\\\end{bmatrix}\\)高斯算子的思想是：有用的信息会以一定的数量聚在一起，而噪声是随机游离的；最中间的信息对于该位数据最有用，但也应当考虑边缘信息的影响。OpenCV 中对应的函数是：void cv::GaussianBlur(InputArray src, OutputArray dst, Size ksize, double sigmaX, double sigmaY = 0, int borderType = BORDER_DEFAULT)其中 ksize 为高斯算子的大小 sigmaX 和 sigmaY 为高斯函数在 x 和 y 方向上的偏置对例子中的图片应用高斯滤波：cv::Mat gaussian_blured_img;cv::GaussianBlur(src, gaussian_blured_img, cv::Size(7, 7), 0, 0);结果如下可以看到虽然结果的噪声仍然很大，但图像在平滑效果和特征保留上相对均值滤波都有一定的提升，例如边缘信息更加明显一些。3. 中值滤波中值滤波与前两者最大的不同在于，均值滤波和高斯滤波均为线性滤波，而中值滤波为非线性滤波。非线性滤波相对于线型滤波，往往都有更好的滤波效果，但代价是会有远高于线型滤波的时间开销。中值滤波是基于排序统计理论的一种能有效抑制噪声的非线性信号处理技术，基本原理是把数字图像或数字序列中一点的值用该点的一个邻域中各点值的中值代替，让周围的像素值接近的真实值，从而消除孤立的噪声点。中值滤波对于滤除脉冲干扰及图像扫描噪声最为有效，还可以克服线性滤波器（如邻域简单平滑滤波）带来的图像细节模糊。中值滤波算子不易用公式描述，总结如下：用某种结构的二维滑动模板，将板内像素按照像素值的大小进行排序，生成单调上升（或下降）的为二维数据序列。二维中值滤波输出为 $g(x,y)=med{f(x-k,y-l),\\ k,l \\in W}$ ，其中 $f(x,y)$ ， $g(x,y)$ 分别为原始图像和处理后图像。 $W$ 为二维模板，通常为 $3\\times3$ ， $5\\times5$ 区域，也可以是不同的的形状，如线状、圆形、十字形圆、环形等。对例子中的图片应用中值滤波：cv::Mat median_blured_img;cv::medianBlur(src, median_blured_img, 7);结果如下可以看到中值滤波在去除椒盐噪声上有着良好的表现，但在信息的保存上劣于高斯滤波。中值滤波不仅对孤立杂点的消除效果显著，对稍密集的杂点也有很好的去除效果。2）形态学处理形态学处理一般处理二值图像。结构元（Structuring Elements）：一般有矩形和十字形。结构元有一个锚点 O ，O 一般定义为结构元的中心。下图是几个不同形状的结构元，紫红色块为锚点 O 。常见的形态学运算有腐蚀、膨胀、开闭，常用于中击不中变换、边界提取和跟踪、区域填充、提取连通分量、细化和像素化， 以及凸壳。OpenCV 中构造结构元的函数是cv::Mat getStructuringElement(int shape, cv::Size esize, cv::Point anchor = Point(-1, -1));参数： shape ：内核的形状，有三种形状可以选择 cv::MORPH_RECT ：矩形 cv::MORPH_CROSS ：交叉形 cv::MORPH_ELLIPSE ：椭圆形 为了增强例子的可展示性，下面的例子中都采用了大结构元，但平时我们一般不会用那么大。cv::Mat element = cv::getStructuringElement(cv::MORPH_CROSS, cv::Size(21, 21));膨胀 Dilation将结构元 $s$ 在图像 $f$ 上滑动，把结构元锚点位置的图像像素点的灰度值设置为结构元值为1的区域对应图像区域像素的最大值。膨胀运算示意图如下，从视觉上看图像中的前景仿佛“膨胀”了一样：OpenCV 中的实现函数是void dilate(InputArray src, OutputArray dst, InputArray kernel, Point anchor=Point(-1,-1), int iterations=1, int borderType=BORDER_CONSTANT, const Scalar&amp;amp; borderValue=morphologyDefaultBorderValue());对中值滤波的结果图进行膨胀：cv::Mat task7_src = task5_median_blured_img.clone();cv::Mat element = cv::getStructuringElement(cv::MORPH_CROSS, cv::Size(21, 21));cv::Mat task7_dilated;cv::dilate(task7_src, task7_dilated, element);cv::imshow(&quot;dilate&quot;, task7_dilated);cv::waitKey(0);效果如下：腐蚀 Erosion将结构元 $s$ 在图像 $f$ 上滑动，把结构元锚点位置的图像像素点的灰度值设置为结构元值为 1 的区域对应图像区域像素的最小值。腐蚀运算示意图如下，从视觉上看图像中的前景仿佛被“腐蚀”了一样：OpenCV 中的实现函数是void erode(InputArray src, OutputArray dst, InputArray kernel, Point anchor=Point(-1,-1), int iterations=1, int borderType=BORDER_CONSTANT, const Scalar&amp;amp; borderValue=morphologyDefaultBorderValue());对中值滤波的结果图进行膨胀：cv::Mat task7_src = task5_median_blured_img.clone();cv::Mat task7_eroded;cv::erode(task7_src, task7_eroded, element);cv::imshow(&quot;eroded&quot;, task7_eroded);cv::waitKey(0);效果如下：开运算 Opening对图像 $f$ 用同一结构元 $s$ 先腐蚀再膨胀称之为开运算。开运算示意图如下，从视觉上看仿佛将原本连接的物体“分开”了一样：开运算能够除去孤立的小点，毛刺和小桥，而总的位置和形状不便。OpenCV 中的实现函数是void morphologyEx(InputArray src, OutputArray dst, int op, InputArray kernel, Point anchor=Point(-1,-1), int iterations=1, int borderType=BORDER_CONSTANT, const Scalar&amp;amp; borderValue=morphologyDefaultBorderValue());参数： op ：表示形态学运算的类型 MORPH_OPEN – 开运算（Opening operation） MORPH_CLOSE – 闭运算（Closing operation） MORPH_GRADIENT - 形态学梯度（Morphological gradient） MORPH_TOPHAT - 顶帽（Top hat） MORPH_BLACKHAT - 黑帽（Black hat） 对中值滤波的结果图进行膨胀：cv::Mat task7_src = task5_median_blured_img.clone();cv::Mat task7_opened;cv::morphologyEx(task7_src, task7_opened, cv::MORPH_OPEN, element);cv::imshow(&quot;open&quot;, task7_opened);cv::waitKey(0);效果如下：闭运算 Closing对图像 $f$ 用同一结构元 $s$ 先膨胀再腐蚀称之为闭运算。开运算示意图如下，从视觉上看仿佛将原本分开的部分“闭合”了一样：闭运算能够填平小湖（即小孔），弥合小裂缝，而总的位置和形状不变。OpenCV 中的实现函数同开运算。对中值滤波的结果图进行膨胀：cv::Mat task7_src = task5_median_blured_img.clone();cv::Mat task7_closed;cv::morphologyEx(task7_src, task7_closed, cv::MORPH_CLOSE, element);cv::imshow(&quot;close&quot;, task7_closed);cv::waitKey(0);效果如下：其他下面提供一段比较实用的代码，通过以下代码，你可以轻松地去除二值图中大于或者小于某一面积的区域而不需要进行轮廓提取：// CheckMode: 0 代表去除黑区域， 1 代表去除白区域; NeihborMode： 0 代表 4 邻域， 1 代表 8 邻域;void RemoveSmallRegion(cv::Mat &amp;amp;Src, cv::Mat &amp;amp;Dst, int AreaLimit, int CheckMode, int NeihborMode) { int RemoveCount = 0; // 记录除去的个数 // 记录每个像素点检验状态的标签， 0 代表未检查， 1 代表正在检查， 2 代表检查不合格（需要反转颜色）， 3 代表检查合格或不需检查 cv::Mat Pointlabel = cv::Mat::zeros(Src.size(), CV_8UC1); if (CheckMode == 1) {// std::cout &amp;lt;&amp;lt; &quot;Mode: 去除小区域. &quot;; for (int i = 0; i &amp;lt; Src.rows; ++i) { uchar *iData = Src.ptr&amp;lt;uchar&amp;gt;(i); uchar *iLabel = Pointlabel.ptr&amp;lt;uchar&amp;gt;(i); for (int j = 0; j &amp;lt; Src.cols; ++j) { if (iData[j] &amp;lt; 10) { iLabel[j] = 3; } } } } else {// std::cout &amp;lt;&amp;lt; &quot;Mode: 去除孔洞. &quot;; for (int i = 0; i &amp;lt; Src.rows; ++i) { uchar *iData = Src.ptr&amp;lt;uchar&amp;gt;(i); uchar *iLabel = Pointlabel.ptr&amp;lt;uchar&amp;gt;(i); for (int j = 0; j &amp;lt; Src.cols; ++j) { if (iData[j] &amp;gt; 10) { iLabel[j] = 3; } } } } std::vector&amp;lt;cv::Point2i&amp;gt; NeihborPos; // 记录邻域点位置 NeihborPos.push_back(cv::Point2i(-1, 0)); NeihborPos.push_back(cv::Point2i(1, 0)); NeihborPos.push_back(cv::Point2i(0, -1)); NeihborPos.push_back(cv::Point2i(0, 1)); if (NeihborMode == 1) {// std::cout &amp;lt;&amp;lt; &quot;Neighbor mode: 8 邻域.&quot; &amp;lt;&amp;lt; std::endl; NeihborPos.push_back(cv::Point2i(-1, -1)); NeihborPos.push_back(cv::Point2i(-1, 1)); NeihborPos.push_back(cv::Point2i(1, -1)); NeihborPos.push_back(cv::Point2i(1, 1)); } // else std::cout &amp;lt;&amp;lt; &quot;Neighbor mode: 4 邻域.&quot; &amp;lt;&amp;lt; std::endl; int NeihborCount = 4 + 4 * NeihborMode; int CurrX = 0, CurrY = 0; // 开始检测 for (int i = 0; i &amp;lt; Src.rows; ++i) { uchar *iLabel = Pointlabel.ptr&amp;lt;uchar&amp;gt;(i); for (int j = 0; j &amp;lt; Src.cols; ++j) { if (iLabel[j] == 0) { //********开始该点处的检查********** std::vector&amp;lt;cv::Point2i&amp;gt; GrowBuffer; // 堆栈，用于存储生长点 GrowBuffer.push_back(cv::Point2i(j, i)); Pointlabel.at&amp;lt;uchar&amp;gt;(i, j) = 1; int CheckResult = 0; // 用于判断结果（是否超出大小），0为未超出，1为超出 for (int z = 0; z &amp;lt; GrowBuffer.size(); z++) { for (int q = 0; q &amp;lt; NeihborCount; q++) //检查四个邻域点 { CurrX = GrowBuffer.at(z).x + NeihborPos.at(q).x; CurrY = GrowBuffer.at(z).y + NeihborPos.at(q).y; if (CurrX &amp;gt;= 0 &amp;amp;&amp;amp; CurrX &amp;lt; Src.cols &amp;amp;&amp;amp; CurrY &amp;gt;= 0 &amp;amp;&amp;amp; CurrY &amp;lt; Src.rows) // 防止越界 { if (Pointlabel.at&amp;lt;uchar&amp;gt;(CurrY, CurrX) == 0) { GrowBuffer.push_back(cv::Point2i(CurrX, CurrY)); // 邻域点加入buffer Pointlabel.at&amp;lt;uchar&amp;gt;(CurrY, CurrX) = 1; // 更新邻域点的检查标签，避免重复检查 } } } } if (GrowBuffer.size() &amp;gt; AreaLimit) CheckResult = 2; //判断结果（是否超出限定的大小），1为未超出，2为超出 else { CheckResult = 1; RemoveCount++; } for (int z = 0; z &amp;lt; GrowBuffer.size(); z++) //更新Label记录 { CurrX = GrowBuffer.at(z).x; CurrY = GrowBuffer.at(z).y; Pointlabel.at&amp;lt;uchar&amp;gt;(CurrY, CurrX) += CheckResult; } //********结束该点处的检查********** } } } CheckMode = 255 * (1 - CheckMode); //开始反转面积过小的区域 for (int i = 0; i &amp;lt; Src.rows; ++i) { uchar *iData = Src.ptr&amp;lt;uchar&amp;gt;(i); uchar *iDstData = Dst.ptr&amp;lt;uchar&amp;gt;(i); uchar *iLabel = Pointlabel.ptr&amp;lt;uchar&amp;gt;(i); for (int j = 0; j &amp;lt; Src.cols; ++j) { if (iLabel[j] == 2) { iDstData[j] = CheckMode; } else if (iLabel[j] == 3) { iDstData[j] = iData[j]; } } }// std::cout &amp;lt;&amp;lt; RemoveCount &amp;lt;&amp;lt; &quot; objects removed.&quot; &amp;lt;&amp;lt; std::endl;}五、轮廓提取不论是使用二值化还是边缘检测，最终得到的结果都是一个二值化了的图片，不论其中的点是表示物体信息还是边缘信息，我们都需要知道可能的目标的位置。因此它们最后都会被转化为轮廓，因为对这种边缘信息我们才能分析它的几何和拓扑特征。OpenCV 中提供了轮廓提取函数：void cv::findContours(InputArray image, OutputArrayOfArrays contours, OutputArray hierarchy, int mode, int method, Point offset = Point())其中： mode ： RETR_EXTERNAL：只列举外轮廓 RETR_LIST：用列表的方式列举所有轮廓 RETR_TREE：用列表的方式列举所有轮廓 用树状的结构表示所有的轮廓，在这种模式下会在 hierachy 中记录轮廓 hierachy：对于每一个轮廓， hierarchy 都包含 4 个整型数据，分别表示：后一个轮廓的序号、前一个轮廓的序号、子轮廓的序号、父轮廓的序号。 method ： CHAIN_APPROX_NONE ：绝对的记录轮廓上的所有点 CHAIN_APPROX_SIMPLE ：记录轮廓在上下左右四个方向上的末端点(轮廓中的关键节点) 下面演示如何使用 RETR_TREE 模式按照拓扑关系画出所有轮廓：void dfs(cv::Mat &amp;amp;drawer, const std::vector&amp;lt; std::vector&amp;lt;cv::Point&amp;gt; &amp;gt; &amp;amp;contours, const std::vector&amp;lt; cv::Vec4i &amp;gt; &amp;amp;hierachy, const int &amp;amp;id, const int &amp;amp;depth) { if (id == -1) return; static cv::Scalar COLOR_LIST[3] = { {220, 20, 20}, {20, 220, 20}, {20, 20, 220} }; cv::drawContours(drawer, contours, id, COLOR_LIST[depth % 3], 1); for (int i = hierachy[id][2]; i + 1; i = hierachy[i][0]) { dfs(drawer, contours, hierachy, i, depth + 1); // 向内部的子轮廓递归 }}cv::Mat src = cv::imread(PROJECT_DIR&quot;/assets/energy.jpg&quot;);cv::Mat hsv;cv::cvtColor(src, hsv, cv::COLOR_BGR2HSV); // 将颜色空间从BGR转为HSVcv::Mat hsv_part1, hsv_part2;cv::inRange(hsv, cv::Scalar(0, 43, 46), cv::Scalar(25, 255, 255), hsv_part1);cv::inRange(hsv, cv::Scalar(156, 43, 46), cv::Scalar(180, 255, 255), hsv_part2); // 提取红色和橙色cv::Mat ones_mat = cv::Mat::ones(cv::Size(src.cols, src.rows), CV_8UC1);cv::Mat hsv_result = 255 * (ones_mat - (ones_mat - hsv_part1 / 255).mul(ones_mat - hsv_part2 / 255)); // 对hsv_part1的结果和hsv_part2的结果取并集std::vector&amp;lt;std::vector&amp;lt;cv::Point&amp;gt;&amp;gt; contours;std::vector&amp;lt;cv::Vec4i&amp;gt; hierachy;cv::findContours(hsv_result, contours, hierachy, cv::RETR_TREE, cv::CHAIN_APPROX_NONE);cv::Mat drawer = cv::Mat::zeros(cv::Size(src.cols, src.rows), CV_8UC3);for (int i = 0; i + 1; i = hierachy[i][0]) dfs(drawer, contours, hierachy, i, 0); // 遍历所有轮廓cv::imshow(&quot;src&quot;, src);cv::imshow(&quot;contours&quot;, drawer);cv::waitKey(0);实现效果如图：六、筛选仅仅使用开闭运算，对三个目标中的前两点的改善十分有限，为了进一步从大量边缘中找到目标边缘，我们在进行完轮廓提取后，还会进行形状筛选。即根据目标的形状信息，剔除形状不正确的的轮廓（这里的形状同样包括大小等各种目标独特的特征）。形状筛选的方式通常有：计算轮廓面积、计算最小外接矩形、椭圆拟合、多边形拟合等。更准确地说，我们对提取出的轮廓使用先验信息和分类器进行筛选，从而找到我们所需要的目标。具体使用什么方法是和目标有关的。下面列举几个常用轮廓筛选的手段：1）面积/周长大小约束面积/周长大小约束是最简单的约束之一，即通过轮廓所包含区域的大小或是轮廓的周长大小筛选指定的轮廓。这种方法虽然简单粗暴，但对于一些环境干扰小的简单环境往往能够取得相当不错的效果。下面是一个简单的例子：bool judgeContourByArea(const std::vector&amp;lt;cv::Point&amp;gt; &amp;amp;contour){ if (cv::contourArea(contour) &amp;gt; 2000) // 舍弃小轮廓 return true; return false;}它对能量机关的轮廓提取如图：这种方法简单高效，但也尤其缺点，确定是鲁棒性低，容易受干扰，对于每一个场景往往需要针对输入调参后才能使用。2）轮廓凹凸性约束这种方法能通过轮廓的凹凸性对凹轮廓或凸轮廓进行有针对性的筛选。一般来说可以通过将轮廓的凸包与轮廓本身进行比较来实现。常用的比较方法有： 面积比例比较 对于凸轮廓，轮廓的凸包面积与轮廓本身的面积比应该接近 $1:1$ ，而一般的凹轮廓的比值应该明显大于 $1$ 。 周长比值比较 一般来说，对于凸轮廓，轮廓的凸包周长和轮廓本身的周长相近，而凹轮廓的轮廓本身周长应当明显大于凸包周长。 下面是一个简单的例子，筛选轮廓中的凹轮廓：bool judgeContourByConvexity(const std::vector&amp;lt;cv::Point&amp;gt; &amp;amp;contour){ if (contourArea(contour) &amp;lt; 500) // 去除过小轮廓的干扰 return false; double hull_area, contour_area; std::vector&amp;lt;cv::Point&amp;gt; hull; cv::convexHull(contour, hull); hull_area = cv::contourArea(hull); contour_area = cv::contourArea(contour); if (hull_area &amp;gt; 1.5 * contour_area) // 判断凹凸性 return true; return false;}它对能量机关的提取如图：3）与矩形相似性约束在轮廓筛选时常常会需要筛选一些较规则的形状，如矩形轮廓等。在这种情况下，一般来说我们可以通过将轮廓的最小外接矩形与轮廓本身进行比较来实现筛选。常见的筛选方法与凹凸性约束相似，也是通过面积和周长比较来实现。此外，由于矩形的特殊性，也可以通过矩形的长宽比进行筛选。下面是一个简单的例子，筛选能量机关的装甲板轮廓：bool judgeContourByRect(const std::vector&amp;lt;cv::Point&amp;gt; &amp;amp;contour){ if (cv::contourArea(contour) &amp;lt; 500) // 排除小轮廓的干扰 return false; double rect_area, contour_area, rect_length, contour_length; cv::RotatedRect rect = cv::minAreaRect(contour); rect_area = rect.size.area(); contour_area = cv::contourArea(contour); if (rect_area &amp;gt; 1.3 * contour_area) // 轮廓面积约束 return false; rect_length = (rect.size.height + rect.size.width) * 2; contour_length = cv::arcLength(contour, true); if (std::fabs(rect_length - contour_length) / std::min(rect_length, contour_length) &amp;gt; 0.1) // 轮廓周长约束 return false; if (std::max(rect.size.width, rect.size.height) / std::min(rect.size.width, rect.size.height) &amp;gt; 1.9) // 长宽比约束 return false; return true;}运行结果如图：以上几种方法是主要的几种基于单个轮廓本身几何性质的筛选方法，下面介绍几种轮廓间几何关系的约束。4）拓扑关系约束在一张复杂的图片中，轮廓中往往有各种复杂的拓扑关系。例如一个轮廓，它的拓扑关系可能有以下几种主要性质： 是否是最外层轮廓 是否是最内层轮廓 是否有子轮廓 子轮廓的个数是多少 它是谁的子轮廓 ……例如当我们想筛选未被激活的装甲板，我们会发现他有两个拓扑关系： 它是最外层轮廓 它有一个子轮廓再或者我们想筛选已经被激活的装甲板，我们会发现他也有连个拓扑关系： 它是最外层子轮廓 它有三个子轮廓下面是一个简单的例子，筛选已经被激活的装甲板：bool judgeContourByTuopu(const std::vector&amp;lt;cv::Vec4i&amp;gt; &amp;amp;hierachy, const int &amp;amp;id, const int &amp;amp;dep){ if (dep != 0) // 判断是否是最外层轮廓 return false; int cnt = 0; for (int i = hierachy[id][2]; i+1; i = hierachy[i][0]) // 子轮廓计数 cnt++; if (cnt != 3) // 判断子轮廓个数是否为3 return false; return true;}运行结果如图：5）通过与其他轮廓的几何关系判断这种方法整体上灵活多变，要根据具体情况选择具体方法，整体的思想是通过与另一个已知轮廓（也可能未知）的几何关系进行筛选。这里以筛选已激活装甲板中的空白区域为例：观察发现，已激活装甲板中的空白区域为一个接近矩形的四边形，其中的长边与扇叶的最小外接矩形的长边有着接近垂直的几何关系。而在上一问中，我们已经筛选出了已激活装甲板，因此这里我们可以利用这一性质完成空白区域的筛选。下面是一个简单的例子：bool judgeContourByRelation(const std::vector&amp;lt;std::vector&amp;lt;cv::Point&amp;gt;&amp;gt; &amp;amp;contours, const std::vector&amp;lt;cv::Vec4i&amp;gt; &amp;amp;hierachy, const int &amp;amp;id, const int &amp;amp;dep){ if (!(hierachy[id][3] + 1)) // 去除最外层轮廓 return false; if (dep != 1) // 判断是否是第二层轮廓 return false; if (!judgeContourByTuopu(hierachy, hierachy[id][3], dep - 1)) // 判断外轮廓是否为已激活扇叶 return false; cv::RotatedRect rect_father = cv::minAreaRect(contours[hierachy[id][3]]); cv::RotatedRect rect_this = cv::minAreaRect(contours[id]); cv::Point2f direction_father; cv::Point2f direction_this;// 寻找父轮廓最小外接矩形的短边 cv::Point2f pts[4]; rect_father.points(pts); double length1 = std::sqrt((pts[0].x - pts[1].x) * (pts[0].x - pts[1].x) + (pts[0].y - pts[1].y) * (pts[0].y - pts[1].y)); double length2 = std::sqrt((pts[2].x - pts[1].x) * (pts[2].x - pts[1].x) + (pts[2].y - pts[1].y) * (pts[2].y - pts[1].y)); if (length1 &amp;lt; length2) direction_father = {pts[1].x - pts[0].x, pts[1].y - pts[0].y}; else direction_father = {pts[2].x - pts[1].x, pts[2].y - pts[1].y}; // 寻找当前轮廓最小外接矩形的长边 rect_this.points(pts); length1 = std::sqrt((pts[0].x - pts[1].x) * (pts[0].x - pts[1].x) + (pts[0].y - pts[1].y) * (pts[0].y - pts[1].y)); length2 = std::sqrt((pts[2].x - pts[1].x) * (pts[2].x - pts[1].x) + (pts[2].y - pts[1].y) * (pts[2].y - pts[1].y)); if (length1 &amp;gt; length2) direction_this = {pts[1].x - pts[0].x, pts[1].y - pts[0].y}; else direction_this = {pts[2].x - pts[1].x, pts[2].y - pts[1].y};// 计算[父轮廓最小外接矩形的短边]与[当前轮廓最小外接矩形的长边]夹角的余弦值 double cosa = (direction_this.x * direction_father.x + direction_this.y * direction_father.y) / std::sqrt(direction_this.x * direction_this.x + direction_this.y * direction_this.y) / std::sqrt(direction_father.x * direction_father.x + direction_father.y * direction_father.y); std::cout &amp;lt;&amp;lt; cosa &amp;lt;&amp;lt; std::endl; if (std::fabs(cosa) &amp;gt; 0.1) // 筛选不符合条件的轮廓 return false; return true;}运行结果如图：对于轮廓筛选的部分就介绍到这里，传统视觉的奥妙远不止于此。以上内容有一部分是笔者的个人总结，并不一定是主流方法。读者可以在实践中慢慢探索，寻找自己的传统视觉的思路。六、传统视觉原则传统方法一般不怕多，就怕少。多出来的加上分类器总有办法筛选掉，但少的就没办法补上了。因此，及时你想得到一个完美的结果，也不应该将阈值设置到一个非常严苛的程度，不然算法的鲁棒性将收到影响。七、总结对于传统图像处理，我们有两种方式，一种基于二值化，一种基于边缘检测。不论哪种方法，我们之后需要对图像进行滤波或形态学处理，在更佳的图像上进行轮廓提取，最后根据轮廓的几何性质等设置分类器提取出我们想要的目标。八、作业链接: https://pan.baidu.com/s/1S94gVEPPdB1m4mwlFA7ImA 提取码: 49w9 苹果识别，请识别下图中的苹果 识别链接中两个视频中的能量机关，框出亮起扇叶的顶部矩形块位置 如果觉得本教程不错或对您有用，请前往项目地址 https://github.com/Harry-hhj/Harry-hhj.github.io 点击 Star :) ，这将是对我的肯定和鼓励，谢谢！九、参考文献 opencv中mat详细解析 【Opencv】Opencv中的Mat类介绍 OpenCV中HSV颜色模型及颜色分量范围 图像处理中常见的形态学方法 opencv getStructuringElement函数 opencv中的开运算，闭运算，形态学梯度，顶帽和黑帽简介 opencv 形态学变换 morphologyEx函数 Opencv–形态学图像处理–膨胀与腐蚀，开操作与闭操作作者列表： xinyang，Github主页：传送门 E-T-E-R-N-A-L-B-L-U-E，传送门 Harry-hhj，Github主页：传送门" }, { "title": "RM 教程 2 —— 安装 OpenCV", "url": "/posts/RM-Tutorial-2-Install-OpenCV/", "categories": "Course, RM", "tags": "getting started, robomaster, opencv", "date": "2021-10-02 13:30:00 +0800", "snippet": "RM 教程 2 —— 安装 OpenCV 机械是血肉，电控是大脑，视觉是灵魂。一、简介OpenCV 是计算机视觉中经典的专用库，其支持多语言，跨平台，功能强大。 opencv-python 为OpenCV 提供了 Python 接口，使得使用者在 Python 中能够调用 C/C++ ，在保证易读性和运行效率的前提下，实现所需的功能。OpenCV 现在支持与计算机视觉和机器学习有关的多种算法，并且正在日益扩展。OpenCV 支持多种编程语言，例如 C++、 Python 、 Java 等，并且可以在 Windows 、 Linux 、 OS X 、 Android 和 IOS 等不同平台上使用。基于 CUDA 和 OpenCL的高速GPU操作的接口也在积极开发中。二、快速安装注意：仅适合新手，队员参与实际项目时还请按照【三】完成安装。C++打开终端，输入以下命令：sudo apt-get install libopencv-dev python-opencv libopencv-contrib-dev以 Clion IDE 为例，配置 toolchains ，如下图所示。需要说明的是： 如果你的 cmake 是系统自带的，那么 cmake 路径选择 /usr/bin/cmake ，如果是编译安装的，那么选择 /usr/local/bin/cmake 。示例代码：链接: https://pan.baidu.com/s/1MDLwgGJ57cG3NfxDAfZASg 提取码: cph8测试方式：点击 IDE 右上角运行或命令行进入项目目录：mkdir buildcmake ..make./example如果出现一张苹果的图片表示安装成功。Python打开终端，输入以下命令：pip install opencv-python opencv-contrib-python -i https://pypi.tuna.tsinghua.edu.cn/simple如果你有 conda 环境的话，可以先创建一个新的环境：conda env listconda create -n opencv python=3.9conda activate opencv以 Pycharm IDE 为例，如果非系统默认的环境，请记得配置项目设置-python 解释器的路径，例如 conda 环境的解释器路径一般都为 ``//envs//bin/python3` 。示例代码：链接: https://pan.baidu.com/s/1AlPkGtZ-4HkRjhwuFB86eQ 提取码: v7dj测试方法：点击 IDE 右上角运行或者命令进入项目目录# 如果有 conda 环境记得先激活python3 main.py如果出现一张苹果的图片表示安装成功。p.s. ：这篇教程讲述了如何编译安装。三、备注Clion 和 Pycharm 的安装教程在对应的安装包中都有提供，这里给出申请学生免费账号的方法。首先进入官方申请网站，选择 For students and teachers 下的 learn more ，用自己的学校邮箱申请，然后打开邮箱内的确认邮件。然后创建自己的 JetBrains Account ，在软件安装完之后的 activate 过程中输入账号密码就可以使用了。注意：目前交大邮箱只能通过人工认证的方式验证。如果觉得本教程不错或对您有用，请前往项目地址 https://github.com/Harry-hhj/Harry-hhj.github.io 点击 Star :) ，这将是对我的肯定和鼓励，谢谢！作者：Harry-hhj，github主页：传送门" }, { "title": "RM 教程 1 —— Linux 教程", "url": "/posts/RM-Tutorial-1-Linux-Introduction/", "categories": "Course, RM", "tags": "getting started, robomaster, ubuntu", "date": "2021-09-24 16:00:00 +0800", "snippet": "RM 教程 1 —— Linux 教程 机械是血肉，电控是大脑，视觉是灵魂。一、Why Linux &amp;amp; Why UbuntuUbuntu 是一个十分流行并且好用的 Linux 桌面发行版本。截止到目前，Ubuntu 已经发行了 Ubuntu 20.04 的版本，并且其稳定性和支持已经很不错了。你可以在这里下载各个版本的 Ubuntu 系统镜像文件，虚拟机的话一般下载桌面版本。常言道，不要重复造轮子。在实际大型项目的开发过程中，总是不可避免的会使用到大量的第三方库，而一旦用到第三方库，就不可避免的会遇到依赖的问题，这个问题在编写 C/C++ 程序的时候尤为明显。在 Windows 下使用 Visual Studio 开发 C++ 程序时，每创建一个工程都必须不厌其烦地挨个设置每个第三方库的头文件目录、库文件目录、以及库文件名。这样的事情是极为繁琐的。这时使用 Ubuntu 系统和 Cmake ，可以让你感受到无与伦比的遍历。所以，使用 Ubuntu 系统的第一个好处就是开发环境配置方便。然而 Linux 的桌面发行版层出不穷，为何偏偏要采用 Ubuntu 呢？这是因为 Ubuntu 作为最受欢迎的 Linux 桌面发行版之一，几乎所有软件包都会原生支持在 Ubuntu 上的安装，同时由于使用的人多，社区很广，遇到问题在网络上也总能搜索到 Ubuntu 下的解决方法。想象一下，如果安装一个不太热门的 Linux 发行版，想在上面安装 CUDA （一个极为流行的 GPU 编程库），然而官方没有原生支持，自行安装过程中的各种坑，在网络上又难以搜索到，这将会是一件多么令人恼火的事情。总之，视觉部推荐使用 Ubuntu 20.04 系统作为基本的开发环境。二、Ubuntu 基础知识网上有比较全面的 Ubuntu 入门介绍，这里不做过多的介绍，重点说一下实际使用过程中最为经常使用到的地方。1. Ubuntu 硬盘与文件目录结构区别于 Windows 系统，每个硬盘分区单独一个盘符，不同分区间相互独立，Linux 下所有硬盘分区要么直接作为根目录，要么是根目录下的一个子目录。如 硬盘分区 1 挂载到根目录，即：/ 硬盘分区 2 挂载到根目录的子目录，如：/data在没有其他挂载的情况下，目录 / ，下面的所有文件（除了目录 /data ）都是保存在硬盘分区 1 中。而目录 /data ，下面的所有文件都是保存在硬盘分区 2 中。2. Ubuntu 常用文件目录及其作用 /home ：该目录下保存不同账户的用户文件。假如你的 Ubuntu 有一个叫 user 的账户，那么 /home/user 下就保存着 user 账户的用户文件。如果还有一个叫 foo 的账户，那么 /home/foo 下就保存着 foo 账户的用户文件。 /root ：该目录下保存着 root 账户的用户文件。root 账户是 Ubuntu 中的一个特殊账户，拥有最高读写权限，类似与 Windows 中的管理员。 /etc ：该目录下保存着各种软件的配置信息。 /usr ：该目录下通常保存用户安装的各个软件、开发包等。 /proc ：该目录下都是虚拟文件，用于监控系统的运行状态。 /dev ：该目录下也是虚拟文件，用于保存各个设备驱动。 /mnt ：该目录下通常保存外部存储设备。如 U 盘等设备，通常可以在该目录下访问。3. Ubuntu 账户账户相当于是标记了这台电脑的不同使用者，当多人公用一台电脑时，可以通过不同账户来划分权限，这种情况在服务器上最为常见，因为服务器通常都会有很多个用户。但在个人电脑上，则通常仅有一个账户。每个账户，可以属于一个或多个组，就好比将多个同类的用户归为一类，同样是方便进行权限管理。4. Ubuntu 权限管理这里的权限包括文件权限和用户权限。通常来说，一个文件有 9 个权限可以设置，而这 9 个权限可以分为 3 类，分别是文件所有者权限，组权限和其他用户权限。其中这三类中，每类都包含 3 个权限，即读、写、执行，分别简写为 r 、 w 、x 。由于读、写、执行可以用 3 个二进制比特表示，所以这三个权限可以用一个 八进制数表示，而一共有 3 类权限，所以一个文件的权限可以由三个八进制数表示。我们可以使用命令 ls -l 来查看当前目录下所有文件的权限。我们可以通过 chmod 命令修改文件的权限，基本用法是 chmod &amp;lt;权限&amp;gt; &amp;lt;文件名&amp;gt; ，比如 chmod 755 ./run 。在上面我们提到，一个文件的权限可以由 3 个八进制数表示，这里就是一个典型的例子。由于有权限限制，在默认的用户权限下，我们通常只能修改目录 /home 下对应用户文件夹里的文件，而其他地方的文件都是无法修改的。为了获取修改任意文件的权限，我们可以使用 sudo 命令。该命令会使得用户获得临时的 root 权限，也就是类似于 Windows 下的管理员权限。这时我们就可以修改那些原本不能修改的文件了。注意：如果使用 sudo 命令创建文件，创建出的文件的所有者将是 root 用户，也就是意味着在用户权限下不能修改它。所以，非必要情况下，尽量不使用 sudo 命令。5. APT 包管理工具apt 是 Ubuntu 中的一个软件，负责管理系统中安装的各类软件包，开发包。包括但不限于安装：可执行软件、开发库（头文件，链接库等）、运行库（动态链接库）。其基本命令有：apt search &amp;lt;包名&amp;gt; # 搜索某个包apt update # 更新包数据库apt upgrade # 升级包apt install &amp;lt;包名&amp;gt; # 安装某个包apt remove &amp;lt;包名&amp;gt; # 删除某个包主要常用的命令就是上面几个。由于apt安装的包，默认并不是安装到用户目录，也就是意味着在安装/删除包时，需要 root 权限。所以，实际使用 apt 命令时还需要在前面加上 sudo 。三、常用 Linux 命令请读者进入 Ubuntu 系统，并打开终端： 方式一：按下 Command 键，搜索 Terminal ，回车 方式二：Ctrl + Alt + T ，这个快捷键和系统打开方式有关，比如原生系统、虚拟机，还和电脑键盘有关一个新打开的终端应该如下图所示，从现在开始你应该适应一个只有字符组成的世界。你会发现你刚进入时，你的默认工作目录是 ~ ，即 /home/&amp;lt;username&amp;gt; ，不信你可以验证一下：1. pwdpwd你会发现输出是 /home/&amp;lt;username&amp;gt; 。这时你希望进入到文档的目录，于是你需要用到：2. cdcd ~/Documents仔细观察，左侧的路径已经改变了。那么在这个文件夹里存在什么呢？我们可以这样查看：3. lsls打印出的结果如下图。如果你的系统是新的，那么你可能看不到任何结果。这空空如也的目录，我们改如何放入我们的东西呢？4. mkdirmkdir demo我们创建一个 demo 目录，用于存放以后要用的文件。我们进入此目录中：cd demo此时我们有一个想法需要记录，我们需要创建一个 test.txt 文件。5. touchtouch test.txtls 看一下，此时文件已经创建好了，那么我们怎么输入我们的想法呢？6. geditgedit test.txt注意 gedit 与其说是一个命令，不如说是一个软件。我们会打开一个图形化编辑窗口，在其中随意输入内容，保存并关闭。那么我们刚刚的操作是否成功， test.txt 中是否存在了我们希望的内容呢？当然可以再次打开文件，但我们有更简单的方式：7. catcat test.txt在终端会输出文件内容，而无需图形化界面。我们再次编辑刚刚的文件，将内容修改为：#include &amp;lt;iostream&amp;gt;int main() { std::cout &amp;lt;&amp;lt; &quot;Hello!&quot; &amp;lt;&amp;lt; std::endl; return 0;}保存并关闭。这是一个 C++ 文件，但此时文件的后缀不太正确，我们先将文件重命名：8. mvmv test.txt test.cppls 看一下，文件名称已经改变了。注意， mv 的本意是移动文件，但是当移动前后位置相同，且指定了移动后的名字时，我们可以将其用于重命名。此时我们编译它：g++ test.cpp -o test产生了可执行文件 test 。运行它，但我们希望把结果记录下来：9. &amp;gt;./test &amp;gt; test.log程序输出被重定向到了 test.log 中，不信你 cat test.log 看看是不是这样的。好了，看到效果后，我们已经不需要这些文件了，于是我们可以删掉它们了。10. rmrm test.logls 看一下 test.log 已经被删除了，但一个个删太麻烦了，我们来点更快的：rm -rf *此时会把当前目录下的所有东西都删除（慎用，或许我不该教你的）。Tips：如果你想偷懒复制粘贴，但又对 Ubuntu 不熟悉，或许我该提示你一般在终端中复制的快捷键是 shift+crtl+c ，粘贴的快捷键是 shfit+ctrl+v ，而 ctrl+c 其实是终止。这里旨在让读者熟悉 RM 日常需求中高频使用的命令，更多命令用法请查看这篇教程。如果觉得本教程不错或对您有用，请前往项目地址 https://github.com/Harry-hhj/Harry-hhj.github.io 点击 Star :) ，这将是对我的肯定和鼓励，谢谢！作者：唐欣阳，github主页：传送门第二作者：Harry-hhj，github主页：传送门" }, { "title": "RoboMaster 课程目录", "url": "/posts/RM-Tutorial-Catalogue/", "categories": "Course, RM", "tags": "catalog", "date": "2021-09-23 00:00:00 +0800", "snippet": "RM Tutorial Catalogue 机械是血肉，电控是大脑，视觉是灵魂。一、培训安排本课程依据由基础到复杂以及技术点难易设置，课程局限在 RM 比赛中所必须要知道的知识点，项目的功利性强，旨在帮助新队员快速掌握核心技能参与项目研发。学习最好的方式就是动手实践，看完一本书的作用并不比你做一个项目强，尤其是对比赛而言！建议观看者依据教程顺序接受课程，并按照要求完成课后作业。依据学生的时间安排，以下课程以一周一节的进度展开。课程包括以下技术点： Ubuntu 系统简单介绍、环境搭建 OpenCV 传统视觉思路简介 摄像机成像原理、相机畸变与相机内参、相机标定 四个坐标系介绍、基于 PNP 的单目定位、仿射变换与透视变换 三角形法则与双目视觉、特征点匹配 卡尔曼滤波介绍、ceres 库介绍 神经网络简介、trt 加速二、培训教程 RM 教程 1 —— Linux 教程 RM 教程 2 —— 安装 OpenCV RM 教程 3 —— OpenCV 传统视觉 RM 教程 4 —— 相机 RM 教程 5 —— 单目视觉如果觉得本教程不错或对您有用，请前往项目地址 https://github.com/Harry-hhj/Harry-hhj.github.io 点击 Star :) ，这将是对我的肯定和鼓励，谢谢！作者：Harry-hhj，github主页：传送门" }, { "title": "Linux Commands", "url": "/posts/Linux-Commands/", "categories": "Tutorial, Linux", "tags": "tools, linux", "date": "2021-09-22 22:00:00 +0800", "snippet": "Linux 常用命令一、目录 命令 意义 shutdown （立即/定时）关机，重启 poweroff 立即关机 reboot 立即重启 man 帮助 cd 进入目录 ls 枚举目录 mkdir 创建目录 rm 删除目录/文件 mv 移动目录/文件，重命名 cp 拷贝目录/文件 touch 新建目录/文件 rm 删除目录/文件 vi/vim 命令行操作文件 cat 查看文件 more 分页查看文件 less 随意查看文件 tail 查看文件尾部，适用实时更新 chmod 改变目录/文件权限 chown 改变拥有者 tar 打包/解包/压缩/解压 grep 搜索过滤 find 递归搜索 locate 搜索路径 whereis 命令路径 which 命令位置 su 用户切换 sudo 单次 root 权限 service 配置服务 chkconfig 开机自启 crontab 定时任务 pwd 打印当前路径 ps 查看进程信息 kill 杀死进程 ifconfig 查看网卡配置 ping 查看连接情况 netstat 查看端口 clear 清空输出 &amp;gt; 重定向符 | 管道 二、基本命令1. 关机shutdown or poweroffshutdown -h now # 立即关机shutdown -h 5 # 5 分钟后关机poweroff # 立即关机2. 重启shutdown or rebootshutdown -r now # 立即重启shutdown -r 5 # 5 分钟后重启reboot # 立即重启3. 帮助--help or manshutdown --helpman shutdown # 打开命令说明书之后，使用按键 q 退出三、目录操作1. 切换cd [&amp;lt;destination&amp;gt;]cd / # 切换到根目录cd /usr # 切换到根目录下的 usr 目录cd .. # 切换到上级目录cd ~ # 切换到 home 目录cd # 同上cd - # 切换到上次访问的目录2. 查看ls [-al] [&amp;lt;target&amp;gt;]ls # 查看当前目录下的所有目录和文件ls -a # 查看当前目录下的所有目录和文件（包含隐藏文件）ls -l # 查看当前目录下的所有目录和文件（列表，包含更多信息）ll # 同上ls /usr # 查看指定目录 /usr 下的所有目录和文件3. 增删改查1) 创建目录mkdir &amp;lt;folder_name&amp;gt;mkdir aaa # 在当前目录下创建一个名为 aaa 的目录mkdir /usr/aaa # 在指定目录 /usr 下创建一个名为 aaa 的目录2) 删除目录rm [-rf] &amp;lt;target&amp;gt;为了方便实用你可以一直带上 -rf 参数，不管你的对象是目录还是压缩包还是文件。rm -r aaa # 递归删除当前目录下的 aaa 目录，有些文件会询问是否确认删除rm -rf aaa # 递归删除当前目录下的 aaa 目录，不询问# 以下命令务必慎用！！！rm -rf * # 将当前目录下的所有目录和文件全部删除rm -rf /* # 将根目录下的所有文件全部删除（只是为了让你明白后果，你不可能会用到这个命令的！）3) 目录复制/移动mv &amp;lt;source&amp;gt; &amp;lt;destination&amp;gt;除了移动之外，还具有重命名的效果。mv &amp;lt;old_path/folder_or_file&amp;gt; &amp;lt;new_path&amp;gt; # 将 folder_or_file 从 &amp;lt;old_path&amp;gt; 移动到 &amp;lt;new_path&amp;gt;mv aaa bbb # 将目录/文件 aaa 重命名为 bbbcp [-r] &amp;lt;source&amp;gt; &amp;lt;destination&amp;gt;cp &amp;lt;path/of/file&amp;gt; &amp;lt;target_folder&amp;gt; # 将文件 &amp;lt;path/of/file&amp;gt; 拷贝到 &amp;lt;target_folder&amp;gt;cp -r &amp;lt;path/of/folder&amp;gt; &amp;lt;target_path&amp;gt; # 将目录 &amp;lt;path/of/folder&amp;gt; 拷贝到 &amp;lt;target_path&amp;gt;4) 搜索目录find &amp;lt;folder&amp;gt; &amp;lt;opt&amp;gt; &amp;lt;param&amp;gt;find /usr/tmp -name &#39;a*&#39; # 查找 /usr/tmp 目录下的所有以 a 开头的目录或文件四、文件操作1. 增删该查1) 新建文件touch &amp;lt;name&amp;gt;touch a.txt # 在当前目录下新建 a.txt 文件touch a # 在当前目录下新建 a 目录2) 删除文件rm [-f] &amp;lt;name&amp;gt;rm &amp;lt;file&amp;gt; # 删除文件 filerm -f &amp;lt;file&amp;gt; # 删除文件 file 且不询问3) 修改文件vi or vimvi &amp;lt;file_name&amp;gt;vim &amp;lt;file_name&amp;gt;基本上 vi 可以分为三种状态： 命令模式 Command mode ：控制屏幕光标的移动，字符、字或行的删除，查找，移动复制某区段 光标移动 $\\leftarrow$ 、 $\\rightarrow$ 、 $\\uparrow$ 、$\\downarrow$ ，分别对应 h 、l 、 k 、 j 删除当前行： dd 查找： /&amp;lt;string&amp;gt; 进入编辑模式： i ：在光标所在字符前开始插入 a ：在光标所在字符后开始插入 o ：在光标所在行的下面另起一新行插入 进入底行模式： : 插入模式 Insert mode ：只有在插入模式下才能做文字输入 回到命令模式：[ESC] 底行模式 last line mode ：将文件保存或退出，也可以设置编辑环境，如寻找字符串、列出行号等 退出： :q 强制退出： :q! 保存并退出： :wq 注意只有命令模式才能随意进入其他两种模式。4) 查看文件cat or more or less or tailcat /etc/bash.bashrc # 一次性显示文件全部内容more /etc/bash.bashrc # 以一页一页的形式显示文件，按 b 后退，按 space 前进less /etc/bash.bashrc # 随意浏览文件，支持翻页和搜索tail -10 /etc/bash.bashrc # 显示 /etc/bash.bashrc 的最后 10 行tail -f &amp;lt;filename&amp;gt; # 把 filename 文件里的最尾部的内容显示在屏幕上，并且不断刷新，适用于查阅正在改变的日志文件2. 修改权限Linux 下的权限类型有三种： r 代表可读， w 代表可写， x 代表该文件是一个可执行文件， - 代表不可读或不可写或不可执行文件。Linux 下的权限粒度有三类： User 、 Group 、 Other 。 User 表示某一登陆用户， Group 表示和 User 同组的其他用户，其他用户都属于 Other 。举个例子，公司的一个员工是 User ，公司的同事就是 Group ，而公司之外的人就是 Other 。在 Linux 中一般用 10 个字符表示一个文件/目录的权限，格式如下：【表示文件类型，d 表示是目录，l 是符号链接文件】-/d/s/p/l/b/c | 【User 的权限】-rwx/-rwx/-rwx ｜ 【Group 的权限】-rwx/-rwx/-rwx ｜ 【Other 的权限】-rwx/-rwx/-rwx例如下图中，红色部分表示 vim.txt 是一个文件， User 和 Group 可读可写，但不可执行，Group 可读，但不可修改删除、不可执行。补充知识：权限也可以用数字来表示，成为 8421 表示法。规则是 $\\text r = 4, \\text w = 2, \\text x = 1$ ，如上图中可以表示为 $664$ 。补充知识：附加权限位。chmod or chown [-R] user[:group] filechmod u+x a.txt # 仅 User 追加执行权限chmod a+x a.txt # 所有用户追加执行权限chmod 100 a # 仅 User 可执行 a ，所有人不可读不可修改chown tom:users file d.key # 设置文件 d.key 的拥有者设为 users 群体的 tomchown -R James:users * # 设置当前目录下与子目录下的所有文件的拥有者为 users 群体的 James五、压缩/解压1. 打包压缩Linux 中的打包文件的后缀为 .tar ，压缩文件的后缀为 .gz ，打包并压缩的文件后缀为 .tar.gz 。tar [-zcvf]参数说明： z ：调用 gzip 压缩命令进行压缩 c ：打包 v ：显示运行过程 f ：指定文件名tar -cvf &amp;lt;target.tar&amp;gt; &amp;lt;sources&amp;gt; # 仅打包不压缩 &amp;lt;sources&amp;gt; 的全部文件及目录，生成 &amp;lt;target.tar&amp;gt;tar -zcvf &amp;lt;target.tar.gz&amp;gt; &amp;lt;sources&amp;gt; # 打包 &amp;lt;sources&amp;gt; 中的全部文件及目录，并压缩为 &amp;lt;target.tar.gz&amp;gt;2. 解压tar [-zxvf] &amp;lt;target&amp;gt;参数说明： z ：调用 gzip 压缩命令进行解压 x ：解包 v ：显示运行过程 f ：指定文件名 -C ：指定解压的位置tar -xvf &amp;lt;source.tar&amp;gt; # 将 &amp;lt;source.tar&amp;gt; 解压到当前目录下tar -xvf &amp;lt;source.tar&amp;gt; -C &amp;lt;destination&amp;gt; # 将 &amp;lt;source.tar&amp;gt; 解压到指定目录 &amp;lt;destination&amp;gt; 下六、查找1. grep强大的文本搜索工具ps -ef | grep sshd | grep -v grep # 查找指定服务进程，排除gerp身ps -ef | grep sshd # -c 查找指定进程个数grep &amp;lt;file&amp;gt; -E [-v] &amp;lt;regex&amp;gt; # 在文件 file 中查找包含 regex 的行并输出， -v 表示不包含2. find默认搜索当前目录及其子目录，并且不过滤任何结果（也就是返回所有文件），将它们全都显示在屏幕上。find . -name &quot;*.log&quot; -ls # 在当前目录查找以.log结尾的文件，并显示详细信息。 find /root/ -perm 600 # 查找/root/目录下权限为600的文件 find . -type f -name &quot;*.log&quot; # 查找当目录，以.log结尾的普通文件 find . -type d | sort # 查找当前所有目录并排序 find . -size +100M # 查找当前目录大于100M的文件3. locate让使用者可以很快速的搜寻某个路径。默认每天自动更新一次，可以在使用 locate 之前，先使用 updatedb 命令，手动更新数据库。可能需要先安装命令： apt install mlocate 。locate /etc/sh # 搜索etc目录下所有以sh开头的文件 locate pwd # 查找和 pwd 相关的所有文件4. whereis定位可执行文件、源代码文件、帮助文件在文件系统中的位置。whereis ls # 将和 ls 文件相关的文件都查找出来5. which在 PATH 变量指定的路径中，搜索某个系统命令的位置，并且返回第一个搜索结果。which pwd # 查找pwd命令所在路径 七、用户切换1. su用于用户之间的切换。但是切换前的用户依然保持登录状态。如果是 root 向普通或虚拟用户切换不需要密码，反之普通用户切换到其它任何用户都需要密码验证。su test # 切换到test用户，但是路径还是/root目录su - test # 切换到test用户，路径变成了/home/testsu # 切换到root用户，但是路径还是原来的路径su - # 切换到root用户，并且路径是/rootexit # 退出返回之前的用户2. sudo为所有想使用root权限的普通用户设计的。可以让普通用户具有临时使用root权限的权利。只需输入自己账户的密码即可。配置文件：sudo vi /etc/sudoerssudo visudo配置案例如下：hadoop ALL=(ALL) ALL # 允许 hadoop 用户以 root 身份执行各种应用命令，需要输入 hadoop 用户的密码hadoop ALL=NOPASSWD: /bin/ls, /bin/cat # 只允许 hadoop 用户以 root 身份执行 ls 、cat 命令，并且执行时候免输入密码八、系统服务service iptables status # 查看 iptables 服务的状态service iptables start # 开启 iptables 服务service iptables stop # 停止 iptables 服务service iptables restart # 重启 iptables 服务 chkconfig iptables off # 关闭 iptables 服务的开机自启动chkconfig iptables on # 开启 iptables 服务的开机自启动九、网络管理1. 主机名配置vi /etc/sysconfig/networkNETWORKING=yesHOSTNAME=node12. IP 地址配置vi /etc/sysconfig/network-scripts/ifcfg-eth03. 域名映射/etc/hosts 文件用于在通过主机名进行访问时做 ip 地址解析之用。所以，你想访问一个什么样的主机名，就需要把这个主机名和它对应的 ip 地址。vi /etc/hosts# 在最后加上192.168.52.201 node1192.168.52.202 node2192.168.52.203 node3十、定时任务crontab [-u &amp;lt;user&amp;gt;] &amp;lt;file&amp;gt; or crontab [-u user] [-e|-l|-r]通过 crontab 命令，可以在固定间隔时间，执行指定的系统指令或 shell 脚本。时间间隔的单位可以是分钟、小时、日、月、周及以上的任意组合。首先你需要先安装 crontab ：apt install crontabs服务操作说明：service crond start # 启动服务 service crond stop # 关闭服务 service crond restart # 重启服务参数说明： [-u &amp;lt;user&amp;gt;] ：用来设定某个用户的 crontab 服务 &amp;lt;file&amp;gt; ：crontab 的任务列表文件 -e ：编辑某个用户的 crontab 文件内容。如果不指定用户，则表示编辑当前用户的 crontab 文件。 -l ：显示某个用户的 crontab 文件内容。如果不指定用户，则表示显示当前用户的 crontab 文件内容。 -r ：删除定时任务配置，从 /var/spool/cron 目录中删除某个用户的 crontab 文件，如果不指定用户，则默认删除当前用户的 crontab 文件。crontab file [-u user] # 用指定的文件替代目前的 crontabcrontab -l [-u user] # 列出用户目前的 crontabcrontab -e [-u user] # 编辑用户目前的 crontab配置： 第 1 列表示分钟 1～59 ，每分钟用 * 或者 */1 表示 第 2 列表示小时 0～23 （ 0 表示 0 点） 第 3 列表示日期 1～31 第 4 列表示月份 1～12 第 5 列标识号星期 0～6 （ 0 表示星期天） 第 6 列要运行的命令# 每分钟执行一次date命令 */1 * * * * date &amp;gt;&amp;gt; /root/date.txt # 每晚的21:30重启apache。 30 21 * * * service httpd restart # 每月1、10、22日的4 : 45重启apache。 45 4 1,10,22 * * service httpd restart # 每周六、周日的1 : 10重启apache。 10 1 * * 6,0 service httpd restart # 每天18 : 00至23 : 00之间每隔30分钟重启apache0,30 18-23 * * * service httpd restart# 晚上11点到早上7点之间，每隔一小时重启apache* 23-7/1 * * * service httpd restart十一、其他1. 重定向&amp;gt; or &amp;gt;&amp;gt; or 2&amp;gt;&amp;amp;1输出重定向到一个文件或设备。ls &amp;gt; a.txt # 将 ls 结果输出到 a.txt 文件echo &quot;This the end of the file.&quot; &amp;gt;&amp;gt; a.txt # 在 a.txt 末尾追加 This the end of the file. 这句话./main 2&amp;gt;&amp;amp;1 main.log # 将 main 运行时的标准输出和标准错误都输出到 main.log 中2. 管道|将一个命令的输入变成另一个命令的输出。find . -type f -readable -regex &#39;.*\\.c\\|.*\\.h&#39; | xargs -I {} grep -c -H &#39;hello&#39; {} # 从当前目录开始递归寻找可读的 .c 和 .h 结尾的文件，查看文件并输出具有 hello 的总行数3. 查看当前路径pwd # 打印出当前路径4. 查看进程ps -ef # 输出所有进程信息5. 结束进程kill [-9] &amp;lt;pid&amp;gt; # 杀死进程号为 pid 的进程， -9 表示强制。6. 网络通信ifconfig # 查看网卡信息，一般用来看 dhcp 的 ip 地址ping &amp;lt;ip&amp;gt; # 查看与机器 &amp;lt;ip&amp;gt; 的连接情况netstat -an # 查看当前系统端口7. 关闭防火墙chkconfig iptables offservice iptables stop8. 清屏clear快捷键： ctrl+l如果觉得本教程不错或对您有用，请前往项目地址 https://github.com/Harry-hhj/Harry-hhj.github.io 点击 Star :) ，这将是对我的肯定和鼓励，谢谢！十二、参考资料 Linux常用命令 Linux 命令大全 Linux权限详解（chmod、600、644、666、700、711、755、777、4755、6755、7755） Linux中重定向 Linux Shell管道详解作者：Harry-hhj，github主页：传送门" }, { "title": "Skills about MacOS", "url": "/posts/Skills-about-MacOS/", "categories": "Tutorial, MacOS", "tags": "skills", "date": "2021-09-20 18:40:00 +0800", "snippet": "MacOS 使用技巧开盖自动开机sudo nvram AutoBoot=%00 # 关闭sudo nvram AutoBoot=%03 # 打开从关闭到打开后，会自动打开开机声音。开机声音sudo nvram BootAudio=%00 # 关闭sudo nvram BootAudio=%01 # 打开查看硬盘寿命smartctl -a /dev/disk1设置截图保存位置defaults write com.apple.screencapture location /path/ # 默认~/Desktopdefaults write com.apple.screencapture type jpg # 默认png遇到没有声音的问题打开活动监视器，找到 coreaudiod ，强制退出。SSH public key 存放位置~/.ssh/known_hostsSSH 免 RSA key fingerprint-o &quot;StrictHostKeyChecking no&quot;切换 zsh 和 bash环境变量配置： bash 的环境变量是 .bash_profile 文件 zsh 的环境变量是 .zshrc 文件从一个交互式终端的角度来讲， zsh 更为强大，但是作为脚本解释器， bash 更加符合 posix 标准，因此，建议读者日常使用 zsh （配合 oh-my-zsh ），但是使用 bash 做脚本解释器。chsh -s /bin/zshchsh -s /bin/bash注意不要加 sudo ，此时为切换 root 用户默认解释器。更多关于 zsh 的内容可以查看这篇教程。隐藏终端主机名sudo vim /etc/zshrc修改 PS1 ，例如：PS1=&quot;%F{green}%n:%F{cyan}%~%F{green}%F{white} %# &quot;如果觉得本教程不错或对您有用，请前往项目地址 https://github.com/Harry-hhj/Harry-hhj.github.io 点击 Star :) ，这将是对我的肯定和鼓励，谢谢！参考资料 优化mac下的terminal的zsh路径显示作者：Harry-hhj，github主页：[传送门](" }, { "title": "Pytorch Network Parameter Statistics", "url": "/posts/Pytorch-Network-Parameter-Statistics/", "categories": "Tutorial, Pytorch", "tags": "computer science, pytorch, tools", "date": "2021-09-20 18:40:00 +0800", "snippet": "PyTorch 统计网络参数量神经网络的参数统计是很重要的，它反映了一个网络的硬件需求与性能。PyTorch 可以使用第三方库 torchsummary 来统计参数并打印层结构。但是想要正确统计出参数量，需要对如何统计参数有一定的了解。Case1 无参数共享（最常见）import torchimport torch.nn as nnimport torchsummaryfrom torch.nn import initclass BaseNet(nn.Module): def __init__(self): super(BaseNet,self).__init__() self.conv1=nn.Conv2d(in_channels=1,out_channels=1,kernel_size=3,stride=1,padding=1,bias=False) self.conv2=nn.Conv2d(in_channels=1,out_channels=1,kernel_size=3,stride=1,padding=1,bias=False) for m in self.modules(): if isinstance(m, nn.Conv2d): nn.init.kaiming_uniform_(m.weight.data) if m.bias is not None: m.bias.data.zero_() elif isinstance(m, nn.BatchNorm2d): init.normal_(m.weight.data, 1.0, 0.02) init.constant_(m.bias.data, 0.0) def forward(self,x): x=self.conv1(x) out_map=self.conv2(x) return out_map def count_parameters(model): &#39;&#39;&#39; model.parameters() 取得模型的参数，在参数可求导 p.requires_grad 的情况下，使用 numel()统计 numpy 数组里面的元素的个数。 &#39;&#39;&#39; return sum(p.numel() for p in model.parameters() if p.requires_grad)model = BaseNet()torchsummary.summary(model, (1, 512, 512))print(&#39;parameters_count:&#39;,count_parameters(model))结果：在这个案例中，使用 torchsummary 和自己统计得到相同的结果。Case2 参数共享import torchimport torch.nn as nnimport torchsummaryfrom torch.nn import initclass BaseNet(nn.Module): def __init__(self): super(BaseNet,self).__init__() self.conv1=nn.Conv2d(in_channels=1,out_channels=1,kernel_size=3,stride=1,padding=1,bias=False) for m in self.modules(): if isinstance(m, nn.Conv2d): nn.init.kaiming_uniform_(m.weight.data) if m.bias is not None: m.bias.data.zero_() elif isinstance(m, nn.BatchNorm2d): init.normal_(m.weight.data, 1.0, 0.02) init.constant_(m.bias.data, 0.0) def forward(self,x): x=self.conv1(x) out_map=self.conv1(x) return out_map def count_parameters(model): return sum(p.numel() for p in model.parameters() if p.requires_grad)model = BaseNet()torchsummary.summary(model, (1, 512, 512))print(&#39;parameters_count:&#39;,count_parameters(model))结果：在这里例子中， parameter_count 统计的是 9 个参数，而 torchsummary 统计的是 18 个参数，为什么会出现这种问题？在这个网络中，我们只初始化了一个卷积层对象 conv1 ，然后在网络构建时（ forward 函数中），重复调用了conv1 ，以实现参数共享，即 Conv2d-1 和 Conv2d-2 层共享了 conv1 的参数。因此本例中 parameter_count 的计算是对的，而 torchsummary 计算时是先把层结构打印下来，然后统计各个层的参数并求和，不区分 Conv2d-1 和 Conv2d-2 层的参数是否相同。结论：在遇到参数共享的时候， torchsummary 统计的是不正确的！Case3 初始化无用变量import torchimport torch.nn as nnimport torchsummaryfrom torch.nn import initclass BaseNet(nn.Module): def __init__(self): super(BaseNet,self).__init__() self.conv1=nn.Conv2d(in_channels=1,out_channels=1,kernel_size=3,stride=1,padding=1,bias=False) self.conv2=nn.Conv2d(in_channels=1,out_channels=1,kernel_size=3,stride=1,padding=1,bias=False) for m in self.modules(): if isinstance(m, nn.Conv2d): nn.init.kaiming_uniform_(m.weight.data) if m.bias is not None: m.bias.data.zero_() elif isinstance(m, nn.BatchNorm2d): init.normal_(m.weight.data, 1.0, 0.02) init.constant_(m.bias.data, 0.0) def forward(self,x): x=self.conv1(x) out_map=self.conv1(x) return out_mapdef count_parameters(model): return sum(p.numel() for p in model.parameters() if p.requires_grad)model = BaseNet()torchsummary.summary(model, (1, 512, 512))print(&#39;parameters_count:&#39;,count_parameters(model))结果：这个例子中我们在初始化时多初始化了一个 conv2 卷积层对象，但是没有在 forward 中使用。此时 parameter_count 出现了错误，即使没有在 forward 中调用，但是也会被算在 model.parameters() 中。但是要注意，尽管 torchsummary 和 parameter_count 都出现了同样结果的错误，两者出现错误的原因是不同的。如果觉得本教程不错或对您有用，请前往项目地址 https://github.com/Harry-hhj/Harry-hhj.github.io 点击 Star :) ，这将是对我的肯定和鼓励，谢谢！参考文献 PyTorch几种情况下的参数数量统计可以下载本文的例子自行实践：链接: https://pan.baidu.com/s/1eet8b_HVmc_WMdIGxCibqA 提取码: p1j3作者：Harry-hhj，github主页：传送门" }, { "title": "Install VNC", "url": "/posts/Install-VNC/", "categories": "Tutorial, VNC", "tags": "install, tools, vnc", "date": "2021-09-19 11:48:00 +0800", "snippet": "Install VNC前言边缘计算平台通常没有显示设备，其本身就以小巧轻便为目的，配置一个显示器反而有些舍本求末了，再加上一些工作环境本身就不适合显示器存在，于是一种不通过显示器就能访问桌面的需求就产生了。借助 VNC 工具，我们可以仅通过一根网线访问运算平台的桌面，这在一些场景将会很有帮助。我们知道，连接网线之后配置好 IP 地址、子网掩码和路由器，我们可以轻松地通过 ssh 登陆目标设备。但是，当目标设备是 Ubuntu 系统且没有自动登录时，我们无法建立 ssh 连接的。对于这些特殊的场景，我觉得，配置一个 VNC ，将会省去你很多的麻烦。更何况配置过程本身就不复杂，何乐而不为呢！这里以 Tegra 处理器为例，理论上任何 ARM 架构的处理器上的 Linux 系统都通用。安装步骤 for Tegra安装 VNC 服务器sudo apt updatesudo apt install vino启用 VNC 服务器启用每次登录时启动 VNC 服务器：mkdir -p ~/.config/autostartcp /usr/share/applications/vino-server.desktop ~/.config/autostart配置 VNC 服务器：gsettings set org.gnome.Vino prompt-enabled falsegsettings set org.gnome.Vino require-encryption false设置访问 VNC 服务器的密码（将 &amp;lt;your_password&amp;gt; 替换为你的密码）：gsettings set org.gnome.Vino authentication-methods &quot;[&#39;vnc&#39;]&quot;gsettings set org.gnome.Vino vnc-password $(echo -n &#39;&amp;lt;your_password&amp;gt;&#39;|base64)重启系统使设置生效：sudo reboot只有在本地登录 Jetson 后，VNC 服务器才可用。如果您希望 VNC 自动可用，请使用系统设置应用程序启用自动登录。连接到 VNC 服务器在你希望在远程操作的操作系统上安装 VNC 客户端应用程序。为了连接，你需要知道 Linux 系统的 IP 地址：ifconfig在输出中搜索文本 inet addr: 后跟四个序列数字（可以这样实现 ifconfig | grep &amp;lt;eth0&amp;gt;），用于相关网络接口（例如 eth0 用于有线以太网， wlan0 用于 WiFi，或 l4tbr0 用于 USB 设备模式以太网连接）。设置静态 IP 地址操作主机为了防止 Linux 系统在不同的 Wi-Fi 中有不同的 IP 地址，或是 DHCP 每次分配了不一样的 IP 地址，我们可以使用网线来连接它，这样，我们可以通过这根网线配置一个局域网，而 IP 地址都是手动静态的了。在你的电脑主机上，配置网口或者拓展坞的 IP 地址、子网掩码和路由器。我们以常见的 Windows 系统和 MacOS 系统为例。对于 MacOS 系统，一般较新的苹果电脑是没有网口的，因此需要插上拓展坞，这里给出一个可用的产品（非广告，不提供链接）：然后插上电脑后，点击设置-&amp;gt;网络，会出现一个新的网卡连接，配置 IPv4 为手动，然后按照你的需求设置其他选项，点击应用就完成了。对于 Windows 系统，以 Windows 10 为例。打开控制面板：进入 网络和Internet-&amp;gt;网络和共享中心 。选择网线接口对应的连接，我这里选择 以太网3 。要注意的是，只有在网线连接电脑和对应设备时，才会有这一选项出现：在 以太网3状态 窗口中，选择 属性 。在弹出的 以太网3属性 窗口中选择 Internet协议版本4 ，并点击下方的按钮 属性 ：在弹出的窗口中部署 ip ， 子网掩码 ， 默认网关 。其中 ip 地址的前三位( 192.168.*** )需要保持与需要配置 VNC 的设备保持一致。最后一位需要与 VNC设备 不同，建议设置成 1 ，子网掩码为 255.255.255.0 ，默认网关与 ip 一致即可。点击确认保存，完成配置。目标机在 Linux 系统中，以 Ubuntu 系统中为例，运行 Settings 软件，点击 Network ，点击 Wired 中右侧设置图标：点击 IPv4 ，点击 Manual ，在 Addresses 中添加 IP 地址、子网掩码和网关，注意这里的子网和网关必须和远程操作机上的一致，而 IP 地址必须不同，且都不和网关 IP 冲突：设置桌面分辨率如果未连接显示器，则默认为选择了 $640\\times480$ 的分辨率。要使用不同的分辨率，请编辑 /etc/X11/xorg.conf 并附加以下几行：Section &quot;Screen&quot; Identifier &quot;Default Screen&quot; Monitor &quot;Configured Monitor&quot; Device &quot;Tegra0&quot; SubSection &quot;Display&quot; Depth 24 Virtual 1280 800 # 将这些值 EndSubSectionEndSection如果觉得本教程不错或对您有用，请前往项目地址 https://github.com/Harry-hhj/Harry-hhj.github.io 点击 Star :) ，这将是对我的肯定和鼓励，谢谢！参考文献 链接: https://pan.baidu.com/s/11QKGlXG_p99FQEzr7eV2tQ 提取码: 0omm作者：Harry-hhj，github主页：传送门第二作者：E-T-E-R-N-A-L-B-L-U-E，github主页：传送门" }, { "title": "CNN 中的解释性问题", "url": "/posts/Interpretative-Questions-in-CNN/", "categories": "Question, CNN", "tags": "computer science, questions", "date": "2021-09-18 16:20:00 +0800", "snippet": "目录 为什么 CNN 中卷积核的大小一般为奇数？Q&amp;amp;AQ1：为什么 CNN 中卷积核的大小一般为奇数？卷积核大小一般是奇数，原因是： 容易找到卷积锚点（主要）： 使用奇数尺寸的滤波器可简化索引，并更为直观，因为滤波器的中心落在整数值上。奇数相对于偶数，有中心点，对边沿、对线条更加敏感，可以更有效的提取边沿信息。因此，奇数大小的卷积核效率更高。 便于进行 padding （次要）： padding 的做法是双边填充，这就导致不管我们怎么填充最终图像增长的长度是偶数。然而我们知道在卷积时如果最后的剩余部分比卷积核小，那么就会损失部分边缘信息，这是我们不希望看到的。我们假设卷积大小 $(k \\times k)$ ，令 $\\text{stride}=1$ ， $\\text{dilation}=1$ ，则 $\\text{padding} = \\frac{\\text{kernel_size}-1}{2}$ 。 如果觉得本教程不错或对您有用，请前往项目地址 https://github.com/Harry-hhj/Harry-hhj.github.io 点击 Star :) ，这将是对我的肯定和鼓励，谢谢！参考文献 deeplearning.ai 《卷积神经网络》作者：Harry-hhj，github主页：传送门" }, { "title": "Docker", "url": "/posts/Docker/", "categories": "Tutorial, Docker", "tags": "getting started, install, tools, docker", "date": "2021-09-13 22:14:00 +0800", "snippet": "DockerDocker 是一个开源的、轻量级的容器引擎，主要运行于 Linux 和 Windows，用于创建、管理和编排容器。和 VMware 虚拟机相比，Docker 使用容器承载应用程序，而不使用操作系统，所以它的开销很少，性能很高。但是，Docker 对应用程序的隔离不如虚拟机彻底，所以它并不能完全取代 VMware。Docker 简介Docker 公司的由来 “Docker”一词来自英国口语，意为码头工人（Dock Worker），即从船上装卸货物的人。Docker 公司起初是一家名为 dotCloud 的平台即服务（Platform-as-a-Service, Paas）提供商，其平台利用了 Linux 容器技术。为了方便创建和管理这些容器， dotCloud 开发了一套内部工具 “Docker”。后来由于业务不景气，公司在聘请了新的 CEO Ben Golub 后，将公司改名为 Docker ，放弃了 Paas 平台，专注于 Docker 技术。如今 Docker 公司被普遍认为是一家创新型科技公司，已经过多轮融资。Docker 运行时与编排引擎多数技术人员在谈到 Docker 时，主要是指 Docker 引擎。运行虚拟机的核心管理程序是 ESXi ，而 Docker 引擎是运行容器的核心容器运行时。Docker 引擎位于中心，其他产品基于 Docker 引擎的核心功能进行集成Docker 引擎主要有两个版本：企业版（EE）和社区版（CE）。每个季度，企业版和社区版都会发布一个稳定版本。从 2017 年第一季度开始，Docker 版本号遵循 YY.MM-xx 格式，类似于 Ubuntu 等项目。Docker 开源项目 —— Moby开源 Docker 项目在 2017 年于 Austin 举办的 DockerCon 上正式命名为 Moby 项目，并且拥有了项目自己的 Logo，如下图所示。Moby 项目的目标是基于开源的方式，发展成为 Docker 上游，并将 Docker 拆分为更多的模块化组件。多数项目及其工具都是基于 Golang 编写的，这是谷歌推出的一种新的系统级编程语言，又叫 Go 语言。使用 Go 语言的读者，将更容易为该项目贡献代码。容器生态Docker 公司的一个核心哲学通常被称为“含电池，但可拆卸”（Batteries included but removable），意思是许多 Docker 内置的组件都可以替换为第三方的组件。随着 Docker 提供的内置组件越来越好，越来越不需要将它们移除了。这也导致了生态内部的紧张关系和竞争的加剧。这是一个好现象！因为良性的竞争是创新之母。开放容器计划如果不谈及开放容器计划（The Open Container Initiative, OCI）的话，对 Docker 和容器生态的探讨总是不完整的。OCI 是一个旨在对容器基础架构中的基础组件（如镜像格式与容器运行时）进行标准化的管理委员会。一个名为 CoreOS 的公司不喜欢 Docker 的某些行事方式。因此它就创建了一个新的开源标准，称作“appc”，该标准涉及诸如镜像格式和容器运行时等方面。此外它还开发了一个名为 rkt 的实现。两个处于竞争状态的标准将容器生态置于一种尴尬的境地。这使容器生态陷入了分裂的危险中，同时也令用户和消费者陷入两难。虽然竞争是一件好事，但是标准的竞争通常不是。因为它会导致困扰，降低用户接受度，对谁都无益。考虑到这一点，所有相关方都尽力用成熟的方式处理此事，共同成立了 OCI 。OCI 已经发布了两份规范（标准）：镜像规范和运行时规范。公平地说，这两个 OCI 规范对 Docker 的架构和核心产品设计产生了显著影响。到目前为止，OCI 已经取得了不错的成效，将容器生态团结起来。然而，标准总是会减慢创新的步伐！尤其是对于超快速发展的新技术来说更是如此。Docker 安装因为 Linux 常作为开发平台，这里以 Linux 安装为例。Linux在 Linux 上安装 Docker 是常见的安装场景，并且安装过程非常简单。唯一的两个需求就是： Linux 操作系统 能够访问 https://get.docker.comDocker 有两个版本可供选择：社区版（CE）和企业版（EE），其中 CE 是免费的，下面演示 CE 的安装过程。注：在开始下面的步骤之前，要确认系统升级到最新的包，并且打了相应的安全补丁。接下来的示例基于 Ubuntu 版本 Linux，同样适用于更低或者更高的版本。 在 Linux 机器上打开一个新的 Shell。 使用 wget 从 https://get.docker.com 获取并运行 Docker 安装脚本，然后采用 Shell 中管道（pipe）的方式来执行这个脚本。 wget -qO- https://get.docker.com/ | sh 最好通过非 root 用户来使用 Docker。这时需要添加非 root 用户到本地 Docker Unix 组当中。下面的命令展示了如何把名为 &amp;lt;username&amp;gt; 的用户添加到 Docker 组中，以及如何确认操作是否执行成功。 sudo usermod -aG docker &amp;lt;username&amp;gt;cat /etc/group | grep docker 输出： docker:x:998:&amp;lt;username&amp;gt; 如果当前登录用户就是要添加到 Docker 组中的用户的话，则需要重新登录，组权限设置才会生效。 至此 Docker 已经在 Linux 上安装成功。运行下面命令来确认安装结果。 docker --versiondocker system info 分别输出： 如果上述步骤在自己的 Linux 发行版中无法成功执行，可以访问 Docker Docs 网站并单击与自己的版本相关的那个链接。接下来页面会跳转到 Docker 官方提供的适合当前版本的安装指南页面，这个安装指南通常会保持更新。Docker 网站上提供的指令使用了包管理器，相比前面的例子需要更多的步骤才能完成安装操作。更多其他在 Linux 上安装 Docker 的方式，可以打开 Docker 主页面，单击页面中 Get Started 按钮来获取。Docker 引擎升级升级步骤： 停止 Docker 守护程序 移除旧版本 Docker 安装新版本 Docker 配置新版本的 Docker 为开机自启动 确保容器重启成功下面以 Ubuntu 20.04 为例（刚安装完的 Docker 不需要更新版本）。更新 APT 包：sudo apt update卸载当前 Docker ：sudo apt-get remove docker docker-engine docker-ce docker.io -y安装新版本 Docker ，使用 get.docker.com 的脚本完成最新版本 Docker CE 的安装和配置：wget -qO- https://get.docker.com/ | sh将 Docker 配置为开机自启动：systemctl enable dockersystemctl is-enabled docker重启 Ubuntu 。检查并确保每一个容器和服务都已经重启成功（没有容器时无需检查）：docker container lsdocker service lsDocker Storage Drive：存储驱动如果觉得本教程不错或对您有用，请前往项目地址 https://github.com/Harry-hhj/Harry-hhj.github.io 点击 Star :) ，这将是对我的肯定和鼓励，谢谢！" }, { "title": "Deconvolution", "url": "/posts/Deconvolution/", "categories": "Tutorial, Nerual Network Theory", "tags": "getting started, computer science, nerual network", "date": "2021-09-06 12:00:00 +0800", "snippet": "Deconvolution一、概念逆卷积（Deconvolution）一般和转置卷积（transposed conv）、微步卷积（fractionally strided conv）的叫法等价。其常见的用处包括： 在 ZF-Net 中用于对 feature map 做可视化 在 FCN 中用于生成等于原图 shape 的图像 无监督的 autoencoder 和 deconvNet 中用于解码器 DSSD、GAN中的应用 ……从上面可以看出，deconvolution 最大的用处是：对 feature map 进行升采样，这和双线性插值（bilinear interpolation）类似。注意，它虽然叫做逆卷积，但是它并不是卷积的逆过程，不能完全还原出卷积前的输入，与原输入仅仅在大小上相同，在数值上虽然具有一定的相关性，但是没有可逆关系。deconv 仅仅是一个普通的卷积层，在神经网络中也是需要通过梯度下降去学习的。在 Pytorch 中通过 torch.nn.ConvTranspose2d 实现，使用方法参考这篇教程。二、最基本的三种形式注：以下推导时，假设长和宽大小相等，如果大小不等，只需要按照以下操作分别计算就行了。1. 无 padding 、无 stride 首先我们来看看最基本的卷积形式：对于 $(m \\times m)$ 的特征图 $I$ ，用大小为 $(k \\times k)$ 的核做卷积，则得到的特征图 $O$ 大小为 $((m-k+1) \\times (m-k+1))$ 。怎么让特征图 $O$ 经过同样大小的卷积核以后的到和特征图 $I$ 一样的大小呢？我们先对特征图 $O$ 做 $padding=k-1$ 的填充，大小变为 $((m+k-1) \\times (m+k-1))$ ，再用等大的 $(k \\times k)$ 核做卷积，则得到的特征图 $I’$ 的大小是 $(m \\times m)$ 。2. 无 padding 、有 stride 然后我们来看看加入 stride 后如何 deconv ：对于 $(m \\times m)$ 的特征图 $I$ ，用 $(k \\times k)$ 大小的核做卷积，记 stride 为 $s$ ，则得到的特征图 $O$ 的大小为 $((\\lfloor \\cfrac{m-k}{s}+1 \\rfloor) \\times (\\lfloor \\cfrac{m-k}{s}+1 \\rfloor))$ 。怎么让特征图 $O$ 经过同样大小的卷积核以后的到和特征图 $I$ 一样的大小呢？与之前不同的是，我们需要根据 stride 对 $I$ 做内部扩充（填 $0$），具体的规则是：在两个元素之间加入 $s-1$ 个 $0$ ，共有 $\\lfloor \\cfrac{m-k}{s}+1 \\rfloor - 1$ 个插入点。再和之前一样，加入 $padding=k-1$ 的填充，得到 $O’$ 。此时计算可得 $O’$ 的边长为为 $\\lfloor \\cfrac{m-k}{s}+1 \\rfloor + 2(k-1) + (s-1)(\\lfloor \\cfrac{m-k}{s}+1 \\rfloor-1) = m+k-1$ ，即大小为 $(m-k+1, m-k+1)$ ，用等大的 $(k \\times k)$ 核做卷积之后得到的特征图 $I’$ 的大小是 $(m \\times m)$ 。另 s=1 就得到 [1] 中的情况。3. 有 padding 、无 stride 为了方便了解加入 padding 之后我们应该如何操作，我们先不考虑 stride 带来的影响，即令 stride=1 。对于大小为 $(m \\times m)$ 的特征图 $I$ ，先做大小为 $p$ 的 padding ，用 $(k \\times k)$ 的核做卷积，则得到的特征图 $O$ 的大小为 $((m+2p-k+1) \\times (m+2p-k+1))$ 。怎么让特征图 $O$ 经过同样大小的卷积核以后的到和特征图 $I$ 一样的大小呢？我们先假设我们对 $O$ 做大小为 $p’$ 的 padding 得到 $O’$ ，再用等大的 $(k \\times k)$ 的核做 stride=1 的卷积，则得到的特征图 $I’$ 的边长是 $(m+2p-k+1)+2p’-k+1$ ，最终需要得到大小为 $(m \\times m)$ 的特征图 $I’$ 。那么得到以下等式：\\((m+2p-k+1)+2p&#39;-k+1 = m\\)得到 \\(p&#39; = k-1-p\\) 。三、公式推导接下来我们考虑最一般的情况（不考虑长宽不等，因为计算过程相同）。对于大小为 $(m \\times m)$ 的特征图 $I$ ，先做大小为 $p$ 的 padding ，得到 $I’$ 的大小为 $((m+2p) \\times (m+2p))$ ，卷积后得到特征图 $O$ 的大小为 $((\\cfrac{m+2p-k}{s}+1) \\times (\\cfrac{m+2p-k}{s}+1))$ 。对 $O’$ 进行 deconv ，先做大小为 $p’$ 的 padding 得到 $O’$ ，边长为 $\\lfloor \\cfrac{m+2p-k}{s}+1 \\rfloor + 2p’$ 。然后根据 stride 填充得到 $O’’$ ，边长为 $\\lfloor \\cfrac{m+2p-k}{s}+1 \\rfloor + 2p’+(s-1)(\\lfloor \\cfrac{m+2p-k}{s}+1 \\rfloor - 1)$ 。再用等大的 $(k \\times k)$ 的核做 stride=1 的卷积，则得到的特征图 $I’’$ 的边长是 $\\lfloor \\cfrac{m+2p-k}{s}+1 \\rfloor + 2p’+(s-1)(\\lfloor \\cfrac{m+2p-k}{s}+1 \\rfloor - 1) -k+1$ ，令 $I’’$ 的边长为 $m$ （我们的目标），可得等式：\\(\\lfloor \\cfrac{m+2p-k}{s}+1 \\rfloor + 2p&#39;+(s-1)(\\lfloor \\cfrac{m+2p-k}{s}+1 \\rfloor - 1) -k+1 = m\\)解得 \\(p&#39;=k-1-p\\) 。四、总结我们来做一个总结，假设特征图 $I$ 大小为 $(m \\times m)$ ，经过大小为 $(k \\times k)$ 卷积核 kernel ，padding 的大小为 $p$ ， stride 的大小为 $s$ 的卷积，得到特征图 $O$ 。 deconv 的操作可以归为两步，分别是： 将卷积核 kernel 做行列转置，得到 kernel&#39; 对特征图 $O$ 根据 stride 做内部填充，填充规则是：在每两行/列元素之间插入 $s-1$ 行/列的 $0$ ，得到特征图 $O’$ 对特征图 $O’$ 做 padding ，大小为 $k-1-p$ ，得到特征图 $I’$ ，此时 $I’$ 的大小和 $I$ 相同，但数据不同我们可以发现：stride 仅和填充的大小有关，而 deconv 的实际卷积操作是 stride=1 的。五、解释为什么逆卷积可以一定程度上还原卷积操作呢？这里简单说明一下逆卷积和卷积的关系： 特征图大小相似 保证了同样的连通性什么是同样的连接性？这是指从 $I$ 到 $O$ （ $I$ 、 $O$ 分别表示卷积前和卷积后的特征图），如果中 $I$ 一个位置与 $O$ 中一个位置通过 kernel 有关系，那么在卷积核逆卷积中有相同的连通。六、一般情况如果我们不需要 deconv 的输出与原输入卷积的特征图大小相同，那么这就是最一般的情况。此时我们不再限制 stride 和 padding 的大小，而是根据它们计算 deconv 输出的大小，其实这在 [三] 中已经推导过了：输入大小：$(N, C_{in}, H_{in}, W_{in})$输出大小：$(N, C_{out}, H_{out}, W_{out})$其中：\\(H_{out} = (H_{in}-1) \\times \\text{stride}[0] - 2 \\times \\text{padding}[0] + \\text{dilation}[0] \\times (\\text{kernel\\_size[0]}-1) + \\text{out\\_padding}[0] + 1 \\\\W_{out} = (W_{in}-1) \\times \\text{stride}[1] - 2 \\times \\text{padding}[1] + \\text{dilation}[1] \\times (\\text{kernel\\_size[1]}-1) + \\text{out\\_padding}[1] + 1\\)七、out_padding在上面的式子中，出现了一个新的参数 - out_padding ，但其只用于查找输出形状，但实际上并不向输出添加零填充。我们先来提出一个问题：假定输入特征图为 $(6 \\times 6)$ ， stride=2 ， kernel_size=3 ，进行 same 卷积操作得到输出特征图的大小为 $(3 \\times 3)$ 。再假讨论另一种情况，假定输入特征图为 $(5 \\times 5)$ ， stride=2 ， kernel_size=3 ，这时候设置 padding=1 ，那么也会得到输出特征图为 $(3 \\times 3)$ 。如果继续考虑 valid 卷积，那么会有更多的情况得到相同大小的输出特征图。这在进行逆卷积的时候就出现了问题，因为卷积时是多种情况对应到了一种情况，那么逆卷积时该如何对应回去呢？解决的方法就是使用 out_padding 参数，它的作用是：当 $\\text{stride} \\gt 1$ 时， Conv2d 将多个输入形状映射到相同的输出形状。output_padding 通过在一边有效地增加计算出的输出形状来解决这种模糊性。首先我们要认可一个前提：在大多数情况下我们都希望经过卷积/反卷积处理后的图像尺寸比例能够被步长整除，即 $输入特征图大小/输出特征图大小=stride$ ，也就是 same 模式。所以我们通过添加 out_padding 这一参数来使得结果满足这一前提，那么 deconv 的输出特征图大小就能够满足为 $其输入大小*stride$ ，而不是任意可能的大小。这样的好处是：网络在后面进行预尺寸相关的操作时，输入的大小是已知且固定的。实现方法：对于 conv 一般推荐的 padding 是 (kernel_size-1)/2 ，那么对于 deconv 来说为了满足前提有如下的等式（假设 dilation 为 $1$）：\\(\\begin{equation}\\begin{split}H_{out} &amp;amp; = (H_{in}-1) \\times \\text{stride}[0] - 2 \\times \\text{padding}[0] + \\text{dilation}[0] \\times (\\text{kernel\\_size[0]}-1) + \\text{out\\_padding}[0] + 1 \\\\ &amp;amp; = (H_{in}-1) \\times \\text{stride}[0] - (\\text{kernel\\_size}[0]-1) + \\text{dilation}[0] \\times (\\text{kernel\\_size[0]}-1) + \\text{out\\_padding}[0] + 1 \\\\\\end{split}\\end{equation}\\)得到 \\(\\text{out\\_padding}[0] = \\text{stride}[0]-1\\)。out_padding[1] 同理。当然可以取其他值，不妨碍 deconv 的计算，但是需要注意，网络后面进行尺寸有关的操作时输入的大小可能不能确定。如果觉得本教程不错或对您有用，请前往项目地址 https://github.com/Harry-hhj/Harry-hhj.github.io 点击 Star :) ，这将是对我的肯定和鼓励，谢谢！八、参考文献 Deconvolution（逆卷积） Convolution arithmetic ConvTranspose2d原理，深度网络如何进行上采样？ nn.ConvTranspose2d的参数output_padding的作用作者：Harry-hhj，github主页：传送门" }, { "title": "Netron", "url": "/posts/Netron/", "categories": "Tutorial, Netron", "tags": "install, tools, netron", "date": "2021-09-04 20:25:00 +0800", "snippet": "NetronNetron 是一款深度神经网络可视化工具，这样一款神器的开发作者是微软的大神 Lutz Roeder ，并且在自己的家中完成的。Netron 强大的原因在于： 所支持的平台广泛。不像 tensorboard 等较为“专一”的可视化平台，当前主流的深度学习框架，Netron 都能得到很好的支持； 操作简单快捷。不需要写一行代码，只需要下载软件安装，然后打开需要可视化的文件，一步操作即可，当然也可以通过代码实现； 保存快捷。对于可视化的结果，就像保存普通的文件一样，一步到位，保存在自己的电脑上。一、支持的框架Netron 最为强大的功能，就在于它所支持的框架十分广泛： ONNX： .onnx 、 .pb 、 ,pbtxt Keras： .h5 、 .keras CoreML： .mlmodel Caffe2： predict_net.pb 、 predict_net.pbtxt MXNet： .model 、 -symbol.json Tensorflow Lite： tflite Caffe： .caffemodel 、 .prototxt PyTorch： .pth Torch： .t7 CNTK： .model 、 .cntk PaddlePaddle： __model__ Darknet： cfg scikit-learn： .pkl TensorFlow.js： .model.json 、 .pb TensorFlow： .pb 、 .meta 、 .pbtxt二、安装1. 在线使用这种方式最为简单，只需要打开网页，放入模型就可以浏览了。2. python 安装打开终端，输入：pip install netron进入 python 解释器或新建一个 python 脚本，输入：import netronnetron.start(r&quot;&amp;lt;path/to/model&amp;gt;&quot;)运行该代码会跳出一个服务网址，并自动打开浏览器，得到如下的效果：这里提供一个 onnx 模型（链接: https://pan.baidu.com/s/1C2abik9L9e0XRJVhPIJFZA 提取码: 17ka），供读者体验效果。如果觉得本教程不错或对您有用，请前往项目地址 https://github.com/Harry-hhj/Harry-hhj.github.io 点击 Star :) ，这将是对我的肯定和鼓励，谢谢！三、参考文献 【神经网络可视化01】——用Netron实现可视化作者：Harry-hhj，github主页：传送门" }, { "title": "Pytorch Building Nueral Network", "url": "/posts/Pytorch-Building-Neural-Network/", "categories": "Tutorial, Pytorch", "tags": "getting started, computer science, pytorch", "date": "2021-09-04 08:00:00 +0800", "snippet": "Pytorch 搭建神经网络一、热身torch.nn 包依赖 autograd 包来定义模型并求导。 一个 nn.Module 包含： 各个层 一个 forward(input) 方法，该方法返回网络的 output在模型中必须要定义 forward() 函数， backward() 函数（用来计算梯度）会被 autograd 自动创建。 可以在 forward() 函数中使用任何针对 Tensor 的操作。神经网络的典型训练过程如下： 定义包含一些可学习的参数（权重）神经网络模型； 在数据集上迭代； 通过神经网络处理输入； 计算损失（输出结果和正确值的差值大小）； 将梯度反向传播回网络的参数； 更新网络的参数，主要使用如下简单的更新原则： weight = weight - learning_rate * gradient本篇将着重于模型定义，而下一篇将着重于网络训练。在讲解 pytorch 的网络包之前，我们先尝试使用 torch.nn 包自己搭建一个简单的网络。我们先来看这样一个网络：import torchimport torch.nn as nnimport torch.nn.functional as Fclass Net(nn.Module): def __init__(self): super(Net, self).__init__() self.conv1 = nn.Conv2d(3, 6, 5) # 3 通道输入，6 通道输出，5x5 卷积核 self.conv2 = nn.Conv2d(6, 16, 5) self.fc1 = nn.Linear(16 * 5 * 5, 120) # 全连接层 y = Wx + b self.fc2 = nn.Linear(120, 84) self.fc3 = nn.Linear(84, 10) def forward(self, x): x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2)) # (2, 2) 最大池化 x = F.max_pool2d(F.relu(self.conv2(x)), 2) # 方形卷积核可以用一个数字代替大小 x = x.view(-1, self.num_flat_features(x)) x = F.relu(self.fc1(x)) x = F.relu(self.fc2(x)) x = self.fc3(x) return x def num_flat_features(self, x): size = x.size()[1:] # 第 0 维是 batch 大小 num_features = 1 for s in size: num_features *= s return num_featuresnet = Net()print(net)为了更好地观察网络结构，我们可以借助可视化工具 Netron 来输出网络的结构图。使用如下的代码，有关 Netron 的更多内容，可以查看这篇教程。x = torch.randn(1, 3, 32, 32)torch.onnx.export(net, x, &quot;example.onnx&quot;)import netronimport osmodel_path = os.path.join(os.getcwd(),&quot;example.onnx&quot;)netron.start(model_path)运行这段代码会自动跳出一个网页，如下图：先请读者思考一个问题，这个网络的输入大小是多少，为什么？想要了解网络的结构，我们需要看 forward() 的函数，注意不是看 init() 。 __init__() 中可以定义网络的比较关键的部件，这样的做的好处是：便于变量名称管理（见 【三】 ）和规定层的参数，增加代码的可读性。解析：对于大小为 $(w, h, c)$ 的输入 x ，首先经过 conv1 ，可以看出 conv1 的输入通道是 $3$ ，因此 $c=3$ ，输出 $6$ 通道。经过 $(5 \\times 5)$ 的卷积，大小变为 $(w-4, h-4, 6)$ 。经过 $(2,2)$ 的最大池化层，默认 stride=kernel_size=2，大小缩减一半，通道数不变，为 $(\\cfrac{w-4}{2}, \\cfrac{h-4}{2}, 6)$ 。再经过一层 $(5 \\times 5)$ 卷积，卷积核数量为 $16$ ，此时特征图尺寸 $(\\cfrac{w-4}{2}-4, \\cfrac{h-4}{2}-4, 16)$ 。再经过 $(2,2)$ 的最大池化层，变为 $(\\cfrac{\\cfrac{w-4}{2}-4}{2}, \\cfrac{\\cfrac{h-4}{2}-4}{2}, 16)$ 。全连接层的输入大小是固定的，因此我们得到以下的等式：\\(\\left \\{\\begin{array}{c}\\cfrac{\\cfrac{w-4}{2}-4}{2} = 5\\\\\\cfrac{\\cfrac{h-4}{2}-4}{2} = 5\\\\\\end{array}\\right .\\)得到 $w=h=32$ ，因此答案是 $(32, 32, 3)$ 。如果对于上面的推导没有看懂的读者，建议先学习神经网络原理，再来看本篇教程。在定义一个自己的网络时，我们二、torch.nn1. 卷积层1) nn.Conv2d二维输入卷积层class torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode=&#39;zeros&#39;, device=None, dtype=None)参数： in_channels (int) – 输入的通道数量 out_channels (int) – 输出的通道数量 kernel_size (int or tuple) – 卷积核的大小 stride (int or tuple，可选) – 卷积步长，默认为 1 padding (int or tuple or str，可选) – 向输入四边添加的填充宽度，默认为 0 padding_mode (string**，可选) – &#39;zeros&#39;, &#39;reflect&#39;, &#39;replicate&#39; or &#39;circular&#39;，默认&#39;zeros&#39; dilation (int or tuple，可选) – 内核元素之间的距离，默认 1 groups (int，可选) – 从输入通道到输出通道到阻塞连接数，默认为 1 bias (bool，可选) – 如果 bias=True ，添加科学系的偏置到输出中，默认为 true参数说明： dilation ：空洞卷积。下图蓝色为输入，绿色为输出（注意参考文献 4 中的阐述有误） dilation=1 dilation=2 以此类推 其实这里 dilation 的定义和 stride 是一致的， dilation 并不代表跳过多少个元素，而代表两个内核元素之间的距离，因此默认值是 1 。 好处：使用 dilation 的好处是增大单次计算时的感受域（即覆盖的面积），在增大感受域的同时却没有增加计算量，保留了更多的细节信息。例如在上面的例子中， dilation=1 时感受域为 $33=9$ ， dilation=2 时感受域为 $55=25$ 。 groups ：深度可分离卷积。 groups=1 ：输出是所有的输入的卷积 conv = nn.Conv2d(in_channels=6, out_channels=3, kernel_size=1, groups=1)conv.weight.data.size() # torch.Size([3, 6, 1, 1]) groups=2 ：此时相当于有并排的两个卷积层，每个卷积层计算输入通道的一半，并且产生的输出是输出通道的一半，随后将这两个输出连接起来得到结果 conv = nn.Conv2d(in_channels=6, out_channels=6, kernel_size=1, groups=2)conv.weight.data.size() # torch.Size([6, 3, 1, 1]) groups=in_channels ：每一个输入通道和它对应的卷积核进行卷积，该对应的卷积核大小为 \\(\\cfrac{C_{out}}{C_{in}}\\) conv = nn.Conv2d(in_channels=6, out_channels=6, kernel_size=1, groups=6)conv.weight.data.size() # torch.Size([6, 1, 1, 1]) 提示一下，**一般卷积网络中出现的大小都是四维数组，他们分别表示 $(数量N, 通道C, 高度H, 宽度W)$ **。注意顺序。 groups 的值必须能同时整除 in_channels 和 out_channels 。 【理解】其规律是共有 out_channels 个卷积核，被分为 groups 组，即每组有 out_channels/groups 个卷积核，输入的通道也被分为 groups 组，每组的通道数为in_channels/groups ，因此每个卷积核的通道数为 in_channels/groups 组，每一组卷积核负责输入的一组，最后将 groups 组的卷积结果拼接起来，就得到了最终的输出。具体的实验结果可以查看这篇教程。 好处：深度可分离卷积的目的是减少卷积操作的参数量和计算量，从而提升运算速度。在实际实验中，同样的网络结构下，这种分组的卷积效果是好于未分组的卷积的效果的。 参数 kernel_size ， stride ， padding ， dilation 可以是一个 int 的数据，此时卷积 height 和 width 值相同 也可以是一个 tuple 数组， tuple 的第一维度表示 height 的数值， tuple 的第二维度表示 width 的数值 大小推导：假设输入大小为 $(N, C_{in}, H_{in}, W_{in})$ ，输出为 $(N, C_{out}, H_{out}, W_{out})$ ，满足以下关系：\\[H_{out} = \\lfloor \\cfrac{H_{in}+2 \\times \\text{padding}[0]-\\text{dilation}[0] \\times (\\text{kernel\\_size}[0]-1)-1}{\\text{stride}[0]}+1 \\rfloor\\]\\[W_{out} = \\lfloor \\cfrac{W_{in}+2 \\times \\text{padding}[1]-\\text{dilation}[1] \\times (\\text{kernel\\_size}[1]-1)-1}{\\text{stride}[1]}+1 \\rfloor\\]卷积层含有两个变量： ~Conv2d.weight (Tensor)：权重，可学习参数，大小为 $(\\text{out_channels}, \\frac{\\text{in_channels}}{\\text{groups}}, \\text{kernel_size}[0], \\text{kernel_size}[1])$ ~Conv2d.bias (Tensor)：偏置，可学习参数用法：m = nn.Conv2d(16, 33, (3, 5), stride=(2, 1), padding=(4, 2), dilation=(3, 1))2) nn.ConvTranspose2d微步卷积（fractionally-strided convolutions）或解卷积（deconvolutions），也可以看作是输入卷积的梯度。注意，解卷积并不是卷积的逆过程， 不能还原卷积前的数据。class torch.nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride=1, padding=0, output_padding=0, groups=1, bias=True, dilation=1, padding_mode=&#39;zeros&#39;, device=None, dtype=None)参数： in_channels (int) – 输入的通道数量 out_channels (int) – 输出的通道数量 kernel_size (int or tuple) – 卷积核的大小 stride (int or tuple，可选) – 卷积步长，默认为 1 padding (int or tuple，可选) – 向输入四边添加 dilation * (kernel_size - 1) - padding 零填充，默认为 0 output_padding (int or tuple，可选) – 向输出图片一边添加的填充，默认为 0 groups (int，可选) – 从输入通道到输出通道到阻塞连接数，默认为 1 bias (bool，可选) – 如果 bias=True ，添加科学系的偏置到输出中，默认为 true dilation (int or tuple，可选) – 内核元素之间的距离，默认 1参数说明： 本质同样是卷积，很多参数的意义都和 conv 一样 out_padding ：这种填充只会填充一边，目的是规定输出的大小。 在进行卷积时，对于不同大小的输入，规定不同的 padding 、 stride 和卷积类型，可能得到相同大小的输出。举个例子，对于 $6\\times6$ 的输入特征图，定义 stride 为 $2$ ，kernel_size 为 $3$ ，padding 为 $2$，输出的特征图大小为 $3\\times3$ 。对于 $5\\times5$ 的输入特征图，定义 stride 为 $2$ ，kernel_size 为 $3$ ，padding 为 $1$，输出的特征图大小也为 $3\\times3$ 。既然不同大小的图片经过卷积运算能够得到相同尺寸的输出，那么作为解卷积，同样的一样图片可以得到不同尺寸的合法输出，这就引发了歧义。当我们后续的操作涉及到尺寸有关的行为时，就无法保证网络按照预期进行计算。为了解决这种模糊性，pytorch 巧妙地引入了参数 out_padding 来获得固定大小的输出。 这里有一个默认前提，一般情况下我们希望经过卷积/解卷积处理后的图像尺寸比例与步长相等，即 $输入特征图大小/输出特征图大小=\\text{stride}$ 。 我们先来算为了满足这个前提 padding 应该设置为多少。根据公式\\(H_{out} = \\lfloor \\cfrac{H_{in}+2 \\times \\text{padding}[0]-\\text{dilation}[0] \\times (\\text{kernel\\_size}[0]-1)-1}{\\text{stride}[0]}+1 \\rfloor = \\cfrac{H_{in}}{\\text{stride}[0]}\\)得到：\\(\\text{padding}[0] = \\cfrac{\\text{dilation}[0] \\times (\\text{kernel\\_size[0] - 1}) + 1 - \\text{stride}[0]}{2}\\)根据这个 padding 求 outpadding ，代入公式\\(H_{out} = (H_{in}-1) \\times \\text{stride}[0] - 2 \\times \\text{padding}[0] + \\text{dilation}[0] \\times (\\text{kernel\\_size}[0]-1) + \\text{out\\_padding}[0] + 1 = H_{in} \\times \\text{stride}[0]\\)得到：\\(\\text{out\\_padding}[0] = 0\\)这说明，当按照完全相同的尺寸逆卷积，且规定网络参数一致，输入输出特征图的比例互为倒数（即整个大小运算中应没有使用到下取整），此时无需 out_padding 。而当运算使用到了下取整，就意味着我们需要通过 out_padding 补足这部分被舍弃的大小。 而这一点，参考文献6的表述就略有问题了，请读者注意。 大小推导：假设输入大小为 $(N, C_{in}, H_{in}, W_{in})$ ，输出为 $(N, C_{out}, H_{out}, W_{out})$ ，满足以下关系：\\[H_{out} = (H_{in}-1) \\times \\text{stride}[0] - 2 \\times \\text{padding}[0] + \\text{dilation}[0] \\times (\\text{kernel\\_size}[0]-1) + \\text{out\\_padding}[0] + 1\\]\\[W_{out} = (W_{in}-1) \\times \\text{stride}[1] - 2 \\times \\text{padding}[1] + \\text{dilation}[1] \\times (\\text{kernel\\_size}[1]-1) + \\text{out\\_padding}[1] + 1\\]逆卷积层含有两个变量： ~ConvTranspose2d.weight (Tensor)：权重，可学习参数，大小为 $(\\text{in_channels}, \\frac{\\text{out_channels}}{\\text{groups}}, \\text{kernel_size}[0], \\text{kernel_size}[1])$ ~ConvTranspose2d.bias (Tensor)：权重，可学习参数，大小为 $(\\text{out_channels})$更详细的说明可以查看这篇 Deconvolution教程 。用法：upsample = nn.ConvTranspose2d(16, 16, 3, stride=2, padding=1)2. 池化层1) nn.MaxPool2d下采样的一种。torch.nn.MaxPool2d(kernel_size, stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=False)参数： kernel_size – 取最大值的窗口大小 stride – 窗口滑动的步幅。默认值为 kernel_size （注意不是 $1$ ） padding – 要在两侧添加隐式零填充 dilation – 控制窗口中元素步幅的参数 return_indices – 如果True，将返回最大索引和输出。对之后的 torch.nn.MaxUnpool2d 有用。 ceil_mode – 当为 True 时，将使用上取整 ceil （即填充数据）而不是下取整 floor （即舍弃数据）来计算输出形状参数说明： stride ：默认值等于卷积核的大小 ceil_mode ：当 ceil_mode = true 时，将保存剩余的不足为 kernel_size 大小的数据保存，自动补足 $\\text{NAN}$ 至 kernel_size 大小；当 ceil_mode = False 时，剩余数据不足 kernel_size 大小时，直接舍弃。 举例：对于如下原始数据，进行 $(2\\times2)$ MaxPool2d： 0 0 | 0 0 | 0 1 1 | 1 1 | 1 ————————————----———————————— 2 2 | 2 2 | 2 3 3 | 3 3 | 3 —————————————---———————————— 4 4 | 4 4 | 4 当ceil_mode = True时： 0 0 | 0 0 | 0 × 1 1 | 1 1 | 1 × ————————————----————————————---- 2 2 | 2 2 | 2 × 3 3 | 3 3 | 3 × —————————————---————————————---- 4 4 | 4 4 | 4 × × × | × × | × × ————————————————————————————---- 输出： [ 1 1 1 3 3 3 4 4 4 ] 即：当数据不足以构成 2*2 时，仍然对剩余数据进行计算 当ceil_mode = False时： 0 0 | 0 0 1 1 | 1 1 ————————————----——- 2 2 | 2 2 3 3 | 3 3 输出： [ 1 1 3 3 ] 即：当数据不足以构成 2*2 时，舍弃 大小推导：假设输入大小为 $(N, C_{in}, H_{in}, W_{in})$ ，输出为 $(N, C_{out}, H_{out}, W_{out})$ ，满足以下关系：\\(H_{out} = \\lfloor \\cfrac{H_{in}+2 \\times \\text{padding}[0]-\\text{dilation}[0] \\times (\\text{kernel\\_size}[0]-1)-1}{\\text{stride}[0]}+1 \\rfloor\\)\\[W_{out} = \\lfloor \\cfrac{W_{in}+2 \\times \\text{padding}[1]-\\text{dilation}[1] \\times (\\text{kernel\\_size}[1]-1)-1}{\\text{stride}[1]}+1 \\rfloor\\]用法：m = nn.MaxPool2d((3, 2), stride=(2, 1))2) nn.MaxUnpool2d一种上采样方法， MaxPool2d 的部分逆运算，因为非最大值已经丢失了。MaxUnpool2d 将MaxPool2d 包含最大值索引的输出作为输入，并计算部分逆，其中所有非最大值都设置为零。参数： kernel_size ( int or tuple ) – 最大池化窗口的大小 stride ( int or tuple ) – 最大池化窗口的步幅。默认设置为 kernel_size 。 padding ( int or tuple ) – 添加到输入的填充，可以通过输入 output_size 来确定输入： input ：输入张量 indices ：MaxPool2d 返回 output_size (optional)：目标输出大小用法：pool = nn.MaxPool2d(2, stride=2, return_indices=True)unpool = nn.MaxUnpool2d(2, stride=2)input = torch.tensor([[[[ 1., 2, 3, 4], [ 5, 6, 7, 8], [ 9, 10, 11, 12], [13, 14, 15, 16]]]])output, indices = pool(input)unpool(output, indices, output_size=torch.Size([1, 1, 5, 5]))# tensor([[[[ 0., 0., 0., 0., 0.],# [ 6., 0., 8., 0., 0.],# [ 0., 0., 0., 14., 0.],# [ 16., 0., 0., 0., 0.],# [ 0., 0., 0., 0., 0.]]]])3) nn.AvgPool2d平均池化。\\(\\text{out}(N_i, C_j, h, w) = \\frac{1}{kH*kW}\\sum_{m=0}^{kH-1}\\sum_{n=0}^{kW-1} \\text{input}(N_i, C_j, \\text{stride}[0] \\times h+m, \\text{stride}[1] \\times w+n)\\)class torch.nn.AvgPool2d(kernel_size, stride=None, padding=0, ceil_mode=False, count_include_pad=True, divisor_override=None)参数： kernel_size – 窗口的大小 stride – 窗口的步幅，默认值为 kernel_size padding – 要在两侧添加的隐式零填充 ceil_mode – 当为 True 时，将使用 ceil 而不是 floor 来计算输出形状 count_include_pad – 当为 True 时，将在平均计算中包括零填充 divisor_override – 除法因子，如果指定，它将被用作平均时的除数，否则 kernel_size 将被使用用法：m = nn.AvgPool2d(3, stride=2)4) nn.AdaptiveMaxPool2d二维自适应最大池化。对于任何大小的输入，可以产生指定输出大小。class torch.nn.AdaptiveMaxPool2d(output_size, return_indices=False)参数： output_size – H 和 W 可以是 int，或者 None 表示大小将与输入相同。 return_indices – 如果True，将返回索引和输出。传递给 nn.MaxUnpool2d 很有用。默认：FalseAdaptiveMaxPool2d 自动计算了 kernel_size 、 stride 、 padding ，它可以用以下公式与 MaxPool2d 转换：\\(\\begin{equation}\\begin{split}&amp;amp; \\text{kernel\\_size} = \\text{input\\_size} - (\\text{output\\_size}-1) * \\text{stride}\\\\&amp;amp; \\text{stride} = \\lfloor \\frac{\\text{input\\_size}}{\\text{output\\_size}} \\rfloor\\\\&amp;amp; padding = 0\\end{split}\\end{equation}\\)用法：m = nn.AdaptiveMaxPool2d((None, 7))5) nn.AdaptiveAvgPool2d3. 非线性激活函数1) nn.ELU2) nn.Hardshrink3) nn.Hardsigmoid4) nn.Hardtanh5) nn.Hardwish6) nn.LeakyReLu7) nn.LogSigmoid8) nn.MultiheadAttention9) nn.PReLu10) nn.ReLu11) nn.ReLu612) RReLu13) nn.SELU14) nn.CELU15) nn.GELU16) nn.Sigmoid17) nn.SiLU18) nn.Mish19) nn.Softplus20) nn.Softsign21) nn.Tanh22) nn.Tanhshrink23) nn.Threshold4. 其他非线性操作1) nn.Softmax2) nn.LogSoftmax3) nn.AdaptiveLogSoftmaxWithLoss5. 标准化层1) nn.BatchNorm2dclass torch.nn.BatchNorm2d(num_features, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, device=None, dtype=None)论文来源： Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift 。对于一个 4D 的输入（小批量的带通道的二维输入）：\\(y = \\cfrac{x-\\mathbf{E}[x]}{\\sqrt{\\mathbf{Var}[x]+\\epsilon}}*\\gamma+\\beta\\)平均值和标准差是在小批量上的每个维度计算的，并且 $\\gamma$ 和 $\\beta$ 是大小为 $C$ 的可学习参数向量（其中 $C$ 是输入大小）。默认情况下，元素 $\\gamma$ 被设置为 1 和元素 $\\beta$ 被设置为 $0$ 。标准偏差是通过偏置估计器计算的，相当于 torch.var(input, unbiased=False) 。此外，默认情况下，在训练期间，该层不断运行其计算出的均值和方差的估计值，然后在评估期间将其用于归一化。运行估计保持默认值 momentum 0.1。更新规则：$\\hat x_{new} = 1 - \\text{momentum} \\times \\hat x + \\text{momentum} \\times x_t$ ，其中 $\\hat x$ 是估计值， $x_t$ 是新的观测值。参数： num_features – 输入大小 $(N, C, H, W)$ 中的 $C$ eps – 为数值稳定性添加到分母的值（当分母趋近于 $0$ 时会出现数值爆炸）。默认值：1e-5 momentum – 用于 running_mean 和 running_var 计算的值。可以设置 None 为累积移动平均（即简单平均）。默认值：0.1 affine – bool，当设置为 True 时，该模块具有可学习的仿射参数。默认：True track_running_stats – bool，当设置为 True ，该模块跟踪运行的均值和方差，当设定为 False ，该模块不跟踪这些统计数据，并初始化统计缓冲区 running_mean 和 running_var 作为 None 。当这些缓冲区为 None 时，此模块始终使用 batch 统计信息。在训练和评估模式中。默认：True参数说明： afine ： 当 afine=true 时， weight($\\gamma$) 和 bias($\\beta$) 将被使用，即进行缩放和平移 举例： import torchfrom torch import nn m = nn.BatchNorm2d(2,affine=True)# 通过梯度下降更新，初始化为不缩放、不平移print(m.weight) # tensor([1., 1.], requires_grad=True)print(m.bias) # tensor([0., 0.], requires_grad=True) # 操作 m.weight 和 m.bias ，你将看到网络产生不同的输出input = torch.arange(1*2*3*4, dtype=torch.float).view(1,2,3,4)output = m(input)print(output) 当 afine=true 时， weight($\\gamma$) 和 bias($\\beta$) 都为 None 举例： m = torch.nn.BatchNorm2d(2,affine=False)print(m.weight) # Noneprint(m.bias) # None track_running_stats ：如果为 True ，则针对每次 mini-batch 结合上次的历史信息动态统计，如果为 false ，则使用该次 mini-batch 的静态统计信息。 计算步骤： 先对输入按照通道进行归一化， $\\mathbf E(x)$ 为计算的均值， $\\mathbf{Var}(x)$ 为计算的方差 然后对归一化的结果按照通道进行缩放和平移，设置 affine=True ，即意味着 weight($\\gamma$) 和 bias($\\beta$) 将被使用大小推导：输入：$(N, C, H, W)$ ，输出：$(N, C, H, W)$用法：m = nn.BatchNorm2d(100) # 输入通道 100 batch &amp;amp; mini-batch这里顺便聊聊 batch 和 mini-batch 的区别： batch ：整个数据集，遍历一次完整的数据集称为一个 epoch 。遍历完所有输入数据后才进行参数更新。 mini-batch ：将整个数据集分成几组，每次同时送入的一批数据称为一个 mini-batch 。每次迭代进行参数更新。其中 mini-batch 的方案在现在应用更为广泛，它是以下两种方案的折中： 批梯度下降 Batch gradient descent ： 遍历全部数据集算一次损失函数，然后计算梯度更新参数。这种方法每更新一次参数需要遍历整个数据集，计算量开销大，计算速度慢，不支持在线学习。但是由于梯度下降方向稳定，不容易震荡。 随机梯度下降 Stochastic gradient descent ： 每输入一个数据就更新参数。这种方法速度比较快，但不容易收敛，会在最有点附近剧烈晃动，且梯度下降过程震荡剧烈。 为了结合上述两种方法的优势，克服各自的缺点，我们采用小批量梯度下降。一个 mini-batch 中的数据共同决定了本次梯度的方向，下降起来就不容易跑偏，减少了随机性。另一方面因为 mini-batch 的样本数与整个数据集相比小了很多，每次更新所需的计算量也不是很大。2) nn.GroupNormclass torch.nn.GroupNorm(num_groups, num_channels, eps=1e-05, affine=True, device=None, dtype=None)论文来源： Group Normalization 。\\(y = \\cfrac{x-\\mathbf E[x]}{\\sqrt{\\mathbf{Var}[x]+\\epsilon}} * \\gamma + \\beta\\)输入通道被分成 num_groups 个组，每组有 num_channels / num_groups 个通道，有各自独立计算的均值和标准差。 $\\gamma$ 和 $\\beta$ 是针对每个通道可学习的参数： num_groups ( int ) – 将通道分成的组数 num_channels ( int ) – 输入中预期的通道数 eps – 为数值稳定性添加到分母的值。默认值：1e-5 affine – bool，当设置为 时 True ，该模块具有可学习的每通道仿射参数，初始化为 1（对于权重）和 0（对于偏差）。默认值：True。大小推导：输入：$(N, C, *)$ ，输出：$(N, C, *)$用法：m = nn.GroupNorm(3, 6) # Separate 6 channels into 3 groups6. 循环层1)Vision Layers（上采样）1) nn.PixelShuffle2) nn.Upsamplehttps://samuel92.blog.csdn.net/article/details/82855946https://zhuanlan.zhihu.com/p/98081181三、各层变量命名规则PyTorch 在对于网络中的参数，采用以下的规则命名变量。了解一下规则，能够帮助我们在需要时知道该如何调用某个变量，比如某层的权重。1) init对于 __init__() 中使用 self 定义的变量会使用这个变量的名字作为存储时的名字。举例：self.conv1 = torch.nn.Conv2d(3, 12, kernel_size=3, stride=1, padding=1) # 卷积层有 2 个参数，对应 conv1.weight 和 conv.bias self.bn1 = torch.nn.BatchNorm2d(12) # 标准化层油 5 个参数，对应 bn1.weight, bn1.bias, bn1.running_mean, bn1.running_var, bn1.num_batches_tracked 2) nn.Sequential使用 nn.Sequential 时会根据传入 list 的顺序对其进行标号。举例：conv1 = nn.Conv2d(3, 12, kernel_size=3, stride=1, padding=1)bn1 = nn.BatchNorm2d(12)s1 = [conv1, bn1]self.stage1 = nn.Squential(*s1)# stage1.0.weight, stage1.0.bias# stage1.1.weight, stage1.1.bias, stage1.1.running_mean, stage1.1.running_var, stage1.1.num_batches_tracked注意此时的 conv1 和 bn1 都没有 self ， stage1 有 self ，而 s1 是 python 基本数据类型。3) DataParallel/DistributedDataParallel当一个 module 被 from torch.nn import DataParallel 或者 from torch.nn.parallel import DistributedDataParallel 包围住后，会在这个变量名后面加上 module. 。举例：conv1 = nn.Conv2d(3, 12, kernel_size=3, stride=1, padding=1)bn1 = nn.BatchNorm(12)s1 = [conv1, bn1]stage1 = nn.Sequential(*s1)self.stage2 = DataParallel(stage1)# stage2.module.0.weight, stage2.module.0.bias# stage2.module.1.weight, stage2.module.1.bias, stage2.module.1.running_mean, stage2.module.1.running_var, stage2.module.1.num_batches_tracked注意只有 stage2 前面有 self 。4) 综合下面举两个综合起来的例子供读者练习。Example 1：import torchimport torch.nn as nnimport torch.nn.functional as Fimport numpy as npfrom torch.nn import DataParallelfrom torch.nn.parallel import DistributedDataParallelimport torch.distributed as dist class CNN(nn.Module): def __init__(self): super(CNN, self).__init__() self.conv1 = nn.Conv2d(3, 12, kernel_size=3, stride=1, padding=1) self.bn1 = nn.BatchNorm2d(12) self.s1 = [self.conv1, self.bn1] self.stage1 = nn.Sequential(*self.s1) self.conv2 = nn.Conv2d(12, 24, kernel_size=3, stride=1, padding=1) self.bn2 = nn.BatchNorm2d(24) self.fc1 = nn.Linear(24 * 5 * 5, 128) self.fc2 = nn.Linear(128, 10) def forward(self, x): x = F.relu(self.bn1(self.conv1(x))) x = F.relu(self.bn2(self.conv2(x))) x = x.view(-1, 24 * 5 * 5) x = F.relu(self.fc1(x)) x = self.fc2(x) return x if __name__ == &#39;__main__&#39;: model = CNN() for name in model.state_dict(): print(name)解析： self.conv1 和 self.bn1 通过 self.s1 传入 Sequential ，所以 self.stage 会根据出现顺序进行编号，但原本的 self.conv1 和 self.bn1 仍然存在，同时 self.s1 并没有，虽然它有 self ，但是它不是 pytorch 自带的层，是 python 的基本数据结构。conv1.weight、conv1.biasbn1.weight、bn1.bias、bn1.running_mean、bn1.running_var、bn1.num_batches_trackedstage1.0.weight、stage1.0.biasstage1.1.weight、stage1.1.bias、stage1.1.running_mean、stage1.1.running_var、stage1.1.num_batches_trackedconv2.weight、conv2.biasbn2.weight、bn2.bias、bn2.running_mean、bn2.running_var、bn2.num_batches_trackedfc1.weight、fc1.biasfc2.weight、fc2.biasExample2：import torchimport torch.nn as nnimport torch.nn.functional as Fimport numpy as npfrom torch.nn import DataParallelfrom torch.nn.parallel import DistributedDataParallelimport torch.distributed as dist class CNN(nn.Module): def __init__(self): super(CNN, self).__init__() conv1 = nn.Conv2d(3, 12, kernel_size=3, stride=1, padding=1) bn1 = nn.BatchNorm2d(12) s1 = [conv1, bn1] self.stage1 = nn.Sequential(*s1) self.stage2 = DataParallel(self.stage1) self.conv2 = nn.Conv2d(12, 24, kernel_size=3, stride=1, padding=1) self.bn2 = nn.BatchNorm2d(24) self.fc1 = nn.Linear(24 * 5 * 5, 128) self.fc2 = nn.Linear(128, 10) def forward(self, x): x = self.stage2(x) x = F.relu(self.bn2(self.conv2(x))) x = x.view(-1, 24 * 5 * 5) x = F.relu(self.fc1(x)) x = self.fc2(x) return x if __name__ == &#39;__main__&#39;: model = CNN() model = DataParallel(model) for name in model.state_dict(): print(name)解析：self.stage1 按照 Sequential 进行编号， self.stage 通过 DataParallel 进行包裹，因此会在 stage2 后面多出 module. ，由于最后的 model 也被 DataParallel 包裹，所以 CNN 里面所有变量前面都多了 module. 。module.stage1.0.weight、module.stage1.0.biasmodule.stage1.1.weight、module.stage1.1.bias、module.stage1.1.running_mean、module.stage1.1.running_var、module.stage1.1.num_batches_trackedmodule.stage2.module.0.weight、module.stage2.module.0.biasmodule.stage2.module.1.weight、module.stage2.module.1.bias、module.stage2.module.1.running_mean、module.stage2.module.1.running_var、module.stage2.module.1.num_batches_trackedmodule.conv2.weight、module.conv2.biasmodule.bn2.weight、module.bn2.bias、module.bn2.running_mean、module.bn2.running_var、module.bn2.num_batches_trackedmodule.fc1.weight、module.fc1.biasmodule.fc2.weight、module.fc2.bias如果觉得本教程不错或对您有用，请前往项目地址 https://github.com/Harry-hhj/Harry-hhj.github.io 点击 Star :) ，这将是对我的肯定和鼓励，谢谢！、参考文献 TORCH.NN pytorch中存储各层权重参数时的命名规则，为什么有些层的名字中带module. pytorch中文文档-torch.nn常用函数-待添加 pytorch的函数中的dilation参数的作用 pytorch卷积操作nn.Conv中的groups参数用法解释 nn.ConvTranspose2d的参数output_padding的作用 Batch、Mini-batch和随机梯度下降的区别和Python示例 https://github.com/vdumoulin/conv_arithmetic Pytorch池化层Maxpool2d中ceil_mode参数 作者：Harry-hhj，github主页：传送门" }, { "title": "Markdown Fomula", "url": "/posts/Markdown-Formula/", "categories": "Tutorial, MathJax", "tags": "tools, latex, markdown", "date": "2021-09-03 18:00:00 +0800", "snippet": "Markdown 公式编辑教程Markdown 中的数学公式，其背后是由 MathJax 提供支持的。MathJax 是一个开源的 web 数学公式渲染器，由 JS 编写而成，提供和 LaTex 一样的公式书写方式。一般公式分为两种，可以理解为一种特殊的代码块： 行内公式：由 $ 将公式代码块括起 效果：$\\Gamma(z) = \\int_0^\\infty t^{z-1}e^{-t}dt$ 源代码： $\\Gamma(z) = \\int_0^\\infty t^{z-1}e^{-t}dt$ 行间公式：由 $$ 将公式代码块括起 效果：\\(\\Gamma(z) = \\int_0^\\infty t^{z-1}e^{-t}dt\\) 源代码： $$\\Gamma(z) = \\int_0^\\infty t^{z-1}e^{-t}dt$$ 一、希腊字母 大写 code 小写 code 名称 $A$ A $\\alpha$ \\alpha alpha $B$ B $\\beta$ \\beta beta $\\Gamma$ \\Gamma $\\gamma$ \\gamma gamma $\\Delta$ \\Delta $\\delta$ \\delta delta $E$ E $\\epsilon$ \\epsilon epsilon $Z$ Z $\\zeta$ \\zeta zeta $H$ H $\\eta$ \\eta eta $\\Theta$ \\Theta $\\theta$ \\theta theta $I$ I $\\iota$ \\iota iota $K$ K $\\kappa$ \\kappa kappa $\\Lambda$ \\Lambda $\\lambda$ \\lambda \\lambda $M$ M $\\mu$ \\mu \\mu $N$ N $\\nu$ \\nu nu $\\Xi$ \\Xi $\\xi$ \\xi xi $O$ O $\\omicron$ \\omicron omicron $\\Pi$ \\Pi $\\pi$ \\pi pi $P$ P $\\rho$ \\rho rho $\\Sigma$ \\Sigma $\\sigma$ \\sigma sigma $T$ T $\\tau$ \\tau tau $\\Upsilon$ \\Upsilon $\\upsilon$ \\upsilon upsilon $\\Phi$ \\Phi $\\phi$ \\phi phi $X$ X $\\chi$ \\chi chi $\\Psi$ \\Psi $\\psi$ \\psi psi $\\Omega$ \\Omega $\\omega$ \\omega omega 二、符号位置（1）上下标上标：^{}下标：_{}当上下标仅为一个元素时，{} 可以省略。举例：x_i^2 表示 $x_i^2$（2）底部符号在符号底部写符号： \\underset{}{}在符号顶部写符号： \\overset{}{}举例： \\underset{0\\le j \\le k-1}{\\arg \\min} 表示 $\\underset{0\\le j \\le k-1}{\\arg \\max}$ ， a\\overset{?}=b 表示 $a\\overset{?}=b$（3）底部换行在符号下部换行： \\understack{}举例： \\sum_{\\substack{0 \\le i \\le n \\\\ 0 \\le j \\le n}} A_{ij} 表示 $\\sum_{\\substack{0 \\le i \\le n \\ 0 \\le j \\le n}} A_{ij}$三、括号1. 小括号、方括号使用原始的 () 、[]举例：(2+3)[4*4] 表示 $(2+3)[4*4]$。2. 大括号需使用转义符号 \\ 阻止解析：\\{\\} 或使用 \\lbrace 和 rbrace举例：\\{a*b\\}:a*b 或 \\lbrace a*b \\rbrace:a*b 表示 $\\lbrace ab \\rbrace:ab$3. 尖括号\\langle 和 \\rangle举例：\\langle x \\rangle 表示 $\\langle x \\rangle$4. 上取整\\lceil 和 rceil举例：\\lceil x \\rceil 表示 $\\lceil x \\rceil$5. 下取整\\lfloor 和 \\rceil举例：\\lceil x \\rceil 表示 $\\lceil x \\rceil$四、求和、乘积、求导、积分1. 求和\\sum_{}^{} ，其下标表示求和下限，上标表示求和上限使用 \\limits 控制下标是在符号右侧还是上下侧举例：\\sum_1^n 表示 $\\sum_1^n$ ， \\sum\\limits_{i=1} 表示 $\\sum\\limits_{i=1}$2. 乘积\\prod_{}^{} ，其下标表示乘积下限，上标表示乘积上限使用 \\limits 控制下标是在符号右侧还是上下侧举例：\\prod_i^n 表示 $\\prod_i^n$ ，\\prod\\limits_i^n 表示 $\\prod\\limits_i^n$3. 求导导数： \\cfrac{\\mathrm{d}y}{\\mathrm{d}x}偏导数： \\cfrac{\\partial y}{\\partial x}举例：导数 $\\cfrac{\\mathrm{d}y}{\\mathrm{d}x}$ ，偏导数 $\\cfrac{\\partial y}{\\partial x}$4. 积分\\int_{}^{} ，其下标表示积分下限，上标表示积分上限举例：\\int_0^\\infty 表示 $\\int_0^\\infty$多重积分：\\iint 表示 $\\iint$ 、 \\iiint 表示 $\\iiint$ 、 \\iiiint 表示 $\\iiiint$5. 其他\\bigcup 表示 $\\bigcup$\\bigcap 表示 $\\bigcap$五、分式与根式1. 分式\\frac{}{} 或 {}\\over{}举例：\\frac ab 表示 $\\frac ab$ ，a \\over b 表示 $a \\over b$2. 连分数\\cfrac 而不要使用 \\frac举例：x=a_0 + \\cfrac {1^2}{a_1 + \\cfrac {2^2}{a_2 + \\cfrac {3^2}{a_3 + \\cfrac {4^2}{a_4 + \\cdots}}}} 表示 $x=a_0 + \\cfrac {1^2}{a_1 + \\cfrac {2^2}{a_2 + \\cfrac {3^2}{a_3 + \\cfrac {4^2}{a_4 + \\cdots}}}}$3. 根式\\sqrt[]{} ，其中 [] 表示根式的次数， {} 表示根式的内容举例：\\sqrt[4]{\\frac xy} 表示 $\\sqrt[4]{\\frac xy}$六、多行表达式1. 分类表达式\\begin{cases} 和 \\end{cases} ，其中使用 \\\\ 换行，使用 &amp;amp; 指示需要对齐的位置，\\ 表示空格。举例：f(n)\\begin{cases}\\cfrac n2, &amp;amp;if\\ n\\ is\\ even\\\\3n + 1, &amp;amp;if\\ n\\ is\\ odd\\end{cases}表示\\(f(n)\\begin{cases}\\cfrac n2, &amp;amp;if\\ n\\ is\\ even\\\\3n + 1, &amp;amp;if\\ n\\ is\\ odd\\end{cases}\\)使用 \\\\[2ex] 代替 \\\\ （相当于 \\\\[1ex]）增大分类之间的垂直距离，以此类推。2. 方程\\begin{equation} 和 \\end{equation}举例：\\begin{equation}a = b + c - d\\end{equation}表示\\(\\begin{equation}a = b + c - d\\end{equation}\\)3. 多行表达式\\begin{split} 和 \\end{split}举例：\\begin{equation}\\begin{split} a&amp;amp;=b+c-d \\\\ &amp;amp;\\quad +e-f\\\\ &amp;amp;=g+h\\\\ &amp;amp; =i \\end{split}\\end{equation}表示\\(\\begin{equation}\\begin{split} a &amp;amp; = b + c - d \\\\ &amp;amp; \\quad + e - f \\\\ &amp;amp; = g + h \\\\ &amp;amp; = i \\end{split}\\end{equation}\\)4. 方程组\\left \\{ 与 \\right . 和 \\begin{array} 和 \\end{array} 配合使用，或使用 \\beign{cases} 与 \\end{cases}举例：\\left \\{ \\begin{array}{c}a_1x+b_1y+c_1z=d_1 \\\\ a_2x+b_2y+c_2z=d_2 \\\\ a_3x+b_3y+c_3z=d_3\\end{array}\\right .表示\\(\\left \\{ \\begin{array}{c}a_1x+b_1y+c_1z=d_1 \\\\ a_2x+b_2y+c_2z=d_2 \\\\ a_3x+b_3y+c_3z=d_3\\end{array}\\right .\\)七、特殊函数与符号1. 三角函数\\sin x 表示 $\\sin x$\\cos x 表示 $\\cos x$\\arctan x 表示 $\\arctan x$以此类推2. 比较符号小于 $\\lt$ ：\\lt大于 $\\gt$：\\gt小于等于 $\\le$：\\le大于等于 $\\ge$ ：\\ge不等于 $\\ne$ ：\\ne3. 集合关系与运算并集 $\\cup$ ：\\cup交集 $\\cap$ ：\\cap差集 $\\setminus$ ：\\setminus子集 $\\subset$ ：\\subset父集 $\\supset$ ：\\supset属于 $\\in$ ：\\in不属于 $\\notin$ ：\\notin包含 $\\subseteq$ ：\\subseteq非包含 $\\subsetneq$ ：\\subsetneq空集 $\\emptyset$ ：\\emptyset空 $\\varnothing$ ：\\varnothing4. 排列组合二项式 $\\binom{n+1}{2k}$ ：\\binom{n+1}{2k} 或 {n+1 \\choose 2k}5. 箭头$\\to$ ：\\to$\\rightarrow$ ：\\rightarrow$\\leftarrow$ ： \\leftarrow$\\leftrightarrow$ ： \\leftrightarrow$\\uparrow$ ： \\uparrow$\\downarrow$ ： \\downarrow$\\updownarrow$ ： updownarrow$\\Rightarrow$ ： \\Rightarrow$\\Leftarrow$ ： \\Leftarrow$\\Leftrightarrow$ ： \\Leftrightarrow$\\Uparrow$ ： \\Uparrow$\\Downarrow$ ： \\Downarrow$\\Updownarrow$ ： Updownarrow$\\longrightarrow$ ： \\longrightarrow$\\longleftarrow$ ： \\longleftarrow$\\longleftrightarrow$ ： \\longleftrightarrow$\\Longrightarrow$ ： \\Longrightarrow$\\Longleftarrow$ ： \\Longleftarrow$\\Longleftrightarrow$ ： \\Longleftrightarrow$\\xleftarrow[T]{n=0}$ ： \\xleftarrow[]{}$\\xrightarrow[T]{n&amp;gt;0}$ ： \\xrightarrow[]{}$\\mapsto$ ： \\mapsto更多箭头符号可以查看这篇教程。6. 逻辑运算符$\\land$： \\land$\\lor$： \\lor$\\lnot$： \\lnot$\\forall$： \\forall$\\exists$： \\exists$\\top$： \\top$\\bot$： \\bot$\\vdash$： \\vdash$\\vDash$： \\vDash7. 定义$\\triangleq$ ： \\triangleq8. 操作符$\\star$： \\star$\\ast$： \\ast$\\oplus$：\\oplus$\\circ$： \\circ$\\bullet$： \\bullet9. 等于$\\approx$： \\approx$\\sim$： \\sim$\\cong$： \\cong$\\equiv$： \\equiv$\\prec$： \\prec10. 范围$\\infty$： infty$\\aleph_o$： aleph_o$\\nabla$ ： \\nabla$\\partial$： \\partial$\\Im$： \\Im$\\Re$： \\Re11. 模运算$\\pmod p$： pmod p12. 点$\\ldots$： ldots$\\cdots$： cdots$\\cdot$： cdot八、顶部符号$\\hat x$： \\hat{}$\\widehat{xy}$： \\widehat{}$\\overline x$： \\overline{}$\\vec x$：\\vec{}$\\overrightarrow x$：\\overrightarrow{}$\\dot x$ ： \\dot{}$\\ddot x$： \\ddot{}九、表格\\begin{array}{列样式} 和 \\end{array}TODO：列样式\\begin{array}{c|lcr}n &amp;amp; \\text{Left} &amp;amp; \\text{Center} &amp;amp; \\text{Right} \\\\\\hline1 &amp;amp; 0.24 &amp;amp; 1 &amp;amp; 125 \\\\2 &amp;amp; -1 &amp;amp; 189 &amp;amp; -8 \\\\3 &amp;amp; -20 &amp;amp; 2000 &amp;amp; 1+10i \\\\\\end{array}效果：\\(\\begin{array}{c|lcr}n &amp;amp; \\text{Left} &amp;amp; \\text{Center} &amp;amp; \\text{Right} \\\\\\hline1 &amp;amp; 0.24 &amp;amp; 1 &amp;amp; 125 \\\\2 &amp;amp; -1 &amp;amp; 189 &amp;amp; -8 \\\\3 &amp;amp; -20 &amp;amp; 2000 &amp;amp; 1+10i \\\\\\end{array}\\)十、矩阵1. 基本\\begin{matrix} 和 \\end{matrix}\\begin{matrix}1 &amp;amp; x &amp;amp; x^2 \\\\1 &amp;amp; y &amp;amp; y^2 \\\\1 &amp;amp; z &amp;amp; z^2 \\\\\\end{matrix}效果：\\(\\begin{matrix}1 &amp;amp; x &amp;amp; x^2 \\\\1 &amp;amp; y &amp;amp; y^2 \\\\1 &amp;amp; z &amp;amp; z^2 \\\\\\end{matrix}\\)2. 加括号可以使用 \\left 和 \\right 配合表示括号符号，也可以使用特殊矩阵：pmatrix： \\(\\begin{pmatrix}1&amp;amp;2\\\\3&amp;amp;4\\\\\\end{pmatrix}\\)bmatrix： \\(\\begin{bmatrix}1&amp;amp;2\\\\3&amp;amp;4\\\\\\end{bmatrix}\\)Bmatrix： \\(\\begin{Bmatrix}1&amp;amp;2\\\\3&amp;amp;4\\\\\\end{Bmatrix}\\)vmatrix： \\(\\begin{vmatrix}1&amp;amp;2\\\\3&amp;amp;4\\\\\\end{vmatrix}\\)Vmatrix： \\(\\begin{Vmatrix}1&amp;amp;2\\\\3&amp;amp;4\\\\\\end{Vmatrix}\\)3. 省略元素$\\cdots$ ： \\cdots$\\vdots$ ： \\vdots$\\ddots$ ：\\ddots举例：\\begin{pmatrix}1&amp;amp;a_1&amp;amp;a_1^2&amp;amp;\\cdots&amp;amp;a_1^n\\\\1&amp;amp;a_2&amp;amp;a_2^2&amp;amp;\\cdots&amp;amp;a_2^n\\\\\\vdots&amp;amp;\\vdots&amp;amp;\\vdots&amp;amp;\\ddots&amp;amp;\\vdots\\\\1&amp;amp;a_m&amp;amp;a_m^2&amp;amp;\\cdots&amp;amp;a_m^n\\\\\\end{pmatrix}效果：\\(\\begin{pmatrix}1&amp;amp;a_1&amp;amp;a_1^2&amp;amp;\\cdots&amp;amp;a_1^n\\\\1&amp;amp;a_2&amp;amp;a_2^2&amp;amp;\\cdots&amp;amp;a_2^n\\\\\\vdots&amp;amp;\\vdots&amp;amp;\\vdots&amp;amp;\\ddots&amp;amp;\\vdots\\\\1&amp;amp;a_m&amp;amp;a_m^2&amp;amp;\\cdots&amp;amp;a_m^n\\\\\\end{pmatrix}\\)4. 增广矩阵\\left 与 \\right 和 \\begin{array} 与 \\end{array}举例：\\left[\\begin{array}{cc|c}1&amp;amp;2&amp;amp;3\\\\4&amp;amp;5&amp;amp;6\\end{array}\\right]效果：\\(\\left[\\begin{array}{cc|c}1&amp;amp;2&amp;amp;3\\\\4&amp;amp;5&amp;amp;6\\end{array}\\right]\\)十一、公式标记与引用\\tag{} 来标记公式，如果以后需要引用此公式，还需要加上 \\label{} 在 \\tag{} 之后。举例：a := x^2 - y^3 \\tag{10}\\label{10}效果：\\(a := x^2 - y^3 \\label{10}\\)\\stackrel{\\eqref{}}{} 引用公式。举例：a + y^3 \\stackrel{\\eqref{10}}= x^2效果：\\(a + y^3 \\stackrel{\\eqref{10}}= x^2\\)\\stackrel{\\ref{}}{} 不带括号引用。举例a + y^3 \\stackrel{\\ref{10}}= x^2效果：\\(a + y^3 \\stackrel{\\ref{10}}= x^2\\)十二、字体1. 黑板粗体字\\mathbb 或 \\Bbb ，此字体常用来表示实数、整数、有理数、复数和大写字母。举例：\\mathbb CHNQRZ\\Bbb CHNQRZ效果：\\(\\mathbb CHNQRZ\\)2. 黑体字\\mathbf举例：\\mathbf CHNQRZ效果：\\(\\mathbf CHNQRZ\\)3. 打印机字体\\mathtt举例：\\mathtt ABCDEFGHIJKLMNOPQRSTUVWXYZ效果：\\(\\mathtt ABCDEFGHIJKLMNOPQRSTUVWXYZ\\)4. 罗马字体\\mathrm举例：\\mathrm abcdefghijklmnopqrstuvwxyz效果：\\(\\mathrm abcdefghijklmnopqrstuvwxyz\\)5. 手写字体\\mathscr举例：\\mathscr abcdefghijklmnopqrstuvwxyz效果：\\(\\mathscr abcdefghijklmnopqrstuvwxyz\\)6. Fraktur 字母（一种德国字体）\\mathfrak举例：\\mathfrak ABCDEFGHIJKLMNOPQRSTUVWXYZ效果：\\(\\mathfrak ABCDEFGHIJKLMNOPQRSTUVWXYZ\\)十三、颜色\\color{}举例： 颜色 源码 效果 黑色 \\color{black}{text} \\(\\color{black}{text}\\) 灰色 \\color{grey}{text} \\(\\color{grey}{text}\\) 银色 \\color{silver}{text} \\(\\color{silver}{text}\\) 白色 \\color{white}{text} \\(\\color{white}{text}\\) 褐红色 \\color{maroon}{text} \\(\\color{maroon}{text}\\) 红色 \\color{red}{text} \\(\\color{red}{text}\\) 黄色 \\color{yellow}{text} \\(\\color{yellow}{text}\\) 绿黄色 \\color{lime}{text} \\(\\color{lime}{text}\\) 橄榄色 \\color{olive}{text} \\(\\color{olive}{text}\\) 绿色 \\color{green}{text} \\(\\color{green}{text}\\) 深蓝绿 \\color{teal}{text} \\(\\color{teal}{text}\\) 水绿色 \\color{aqua}{text} \\(\\color{aqua}{text}\\) 蓝色 \\color{blue}{text} \\(\\color{blue}{text}\\) 海军蓝 \\color{navy}{text} \\(\\color{navy}{text}\\) 紫色 \\color{purple}{text} \\(\\color{purple}{text}\\) 浅莲红 \\color{fuchsia}{text} \\(\\color{fuchsia}{text}\\) 十四、其他1. 空格MathJax 通过内部策略管理自己的公式内的空间，因此公式中无论空多少格最后都不会有效果，可以插入\\, 增加些许间隙，插入 \\; 插入较宽的间隙，\\quad 与 \\qquad 会增肌更大的间隙。2. 括号任何运算符后的 {} 在只有单个字符时可以省略，但此时如果为单个字母则需加入空格分隔。如：\\frac12 表示 $\\frac12$ ，\\frac ab 表示 $\\frac ab$。3. 转义对于 MathJax 的保留字符，如 \\ 、 {} 等，如果不是为了解析，那么需要在前面添加转义字符 \\ 。如果觉得本教程不错或对您有用，请前往项目地址 https://github.com/Harry-hhj/Harry-hhj.github.io 点击 Star :) ，这将是对我的肯定和鼓励，谢谢！十五、参考文献 Mathjax公式教程作者：Harry-hhj，github主页：传送门" }, { "title": "Install OpenCV", "url": "/posts/Install-OpenCV/", "categories": "Tutorial, Computer Vision, OpenCV", "tags": "install, computer science, opencv", "date": "2021-08-31 14:15:00 +0800", "snippet": "OpenCV 安装教程 机械是血肉，电控是大脑，视觉是灵魂。一、安装环境 Ubuntu 系统版本：20.04 LTS，链接: https://pan.baidu.com/s/1ojBoCBSHbMVZHhD8HOHYyA 提取码: 76wv（不建议下载，因为反而慢） OpenCV 版本：4.5.3，链接: https://pan.baidu.com/s/1foen04ULGOwGpwLJUwvS2A 提取码: vwmq OpenCV_contrib版本：需与 OpenCV 一致，链接: https://pan.baidu.com/s/1wI7IgSBt3sSBjE374Gnksg 提取码: 7mef通过 Github 访问可能会非常缓慢，所以我们提供了百度网盘下载地址。二、前言OpenCV （开源的计算机视觉库）是基于 BSD 协议，因此它可免费用于学术和商业用途。其提供 C++ 、 C 、 Python 和 Java 接口，支持 Windows 、 Linux 、 Mac OS 、 iOS 和 Android 。OpenCV 致力于高效运算和即时应用开发。因其是用优化的 C/C++ 编写的，故其可以充分利用多核处理优势，并且还启用了 OpenSL ，它可以利用底层异构计算平台的硬件加速。可以说，想要入门机器视觉，安装 OpenCV 是躲不掉的第一步。我在 RoboMaster 的组员一年后还在参考此教程，足见它的实用性了。配置环境是做项目的第一步，也是非常重要的一步，如果你希望培养自己的这种能力，我非常鼓励你先自己查找资料探索整个安装步骤，并给出你可能需要查阅资料用到的关键词：Git 、 OpenCV 、 OpenCV_contrib 、 cmake/cmake-gui 、以及可能出现的问题：权限不足、文件下载失败（TimeOut）等，这些问题一般只需要搜索关键字或将报错的句子复制到搜索引擎中，就能找到解决方法，其中大部分问题在 CSDN 中都有解答，少部分问题需要查阅 Overstackflow 查看英文解决方法，查阅官方资料（实际上这是最重要的一种方式）和论坛也是一种不错的方法。三、OpenCV 安装详细步骤准备阶段一般来说我们的电脑都是 Windows 和 MacOS 为操作系统的，虽然在它们上面也能进行开发，但是使用体验不如 Linux 系统方便畅快。我这么说的原因是： 大部分开发环境对于 Linux 的支持更好，操作以终端命令为主，环境部署效率高，而Windows 和 MacOS 则对图形化界面更友好，舒适度取决于软件开发商 Linux 本身就是面向服务器而非个人电脑的，因此更适合于大型项目的开发，其系统运行效率更高 相比较而言 Linux 更加简洁，很适合喜欢简洁的程序员 当然，这都看个人喜好，只要你用得顺手，对个人开发而言其实无所谓为了拥有一个我们自己的 Linux 系统，有三种方法： 安装双系统 配置虚拟机 再买一台电脑重装 Linux ：和安装双系统差不多，不做介绍如果您的主机性能良好，那么这两个方案都是可选的，如果它的性能不足以同时运行两个系统，那么安装双系统可能是一个比较合理的选择。如果这两个方案都是可选的，那么首先你需要明白它们的优劣： 双系统 优点：硬件使用效率更高，所有电脑的硬件将只被一个系统使用；能够使用 GPU ，如果你的开发需要使用 GPU ，如深度学习，那么安装双系统将是你唯一的选择。 缺点：无法同时使用日常的操作系统，切换系统需要重启。 虚拟机： 优点：可以快速进行操作系统间的切换，以及之间的文件传输；虚拟机环境损坏后重装更方便一些，且拥有系统快照功能，方便一键还原 缺点：同时运行两个系统，消耗系统资源；虚拟机支持软件需要付费（VM 对学生免费） 由于虚拟机安装更快且坑较少，所以本篇教程现以虚拟机安装为主，而对双系统教程将会另外出一篇教程讲述。一般配置的 Linux 虚拟机至少需要分配 1 核 2 GB 才能运行起来，如果要运行比较耗资源的项目的话， 2 核 4 GB 是推荐的选择，当然，SSD 的速度能在一定程度上弥补内存的不足。在安装完虚拟机后，仍应留有一定的资源供主机使用。一种直观的感受是，如果你的虚拟机运行卡顿，那么首先看你装在哪里，如果是机械硬盘，那么情有可原，试着提高分配的内存，不行再提高分配的核心，如果是固态硬盘，那么就意味着分配的核心或内存太少了，根据情况提高核心或内存或同时提高。如果你选择了双系统，那么请提前规划好你的硬盘容量，因为双系统会在安装时需要固定死系统容量，当然以后改的方法还是有点。如果你选择了虚拟机，那么你需要一个底层的支撑软件，比如 VMware 、 Parallel Desktop 等，前者作为交大的学生可以在网络信息服务中心申请免费使用。安装完虚拟机之后，就可以正式开始安装 OpenCV 了。首先，我们先确保系统安装了一些基本的依赖库，打开终端输入以下命令：sudo apt install git gcc g++ ffmpeg cmake cmake-gui make python3-dev python3-numpy python3-pip libavcodec-dev libavformat-dev libswscale-dev libgstreamer-plugins-base1.0-dev libgstreamer1.0-dev libgtk-3-dev libpng-dev libjpeg-dev libopenexr-dev libtiff-dev libwebp-dev libavresample-dev libtbb-devsudo add-apt-repository &quot;deb http://security.ubuntu.com/ubuntu xenial-security main&quot;sudo apt updatesudo apt install libjasper1 libjasper-dev如果想要升级 gcc/g++ 版本，请看这篇文章中的相关部分。如果想要安装最新版的 cmake ，可以参考这篇教程。（非必须，推荐）安装 aptitude ：sudo apt install aptitude（非必须）安装 Boost 和 Eigen3：sudo apt install libboost-all-devsudo apt-get install libeigen3-dev（非必须）安装 ceres：首先打开终端，添加源：sudo gedit /etc/apt/sources.list不然你可能会遇到以下问题：在文件中加入：deb http://cz.archive.ubuntu.com/ubuntu trusty main universe然后关闭，在终端输入以下命令，更新源并安装依赖库：sudo apt updatesudo apt-get install liblapack-dev libsuitesparse-dev libcxsparse3.1.2 libgflags-dev libgoogle-glog-dev libgtest-dev然后 git clone https://github.com/ceres-solver/ceres-solver.git 从 GitHub 下载 ceres-solver 至 Applications 文件夹，在项目目录下打开终端：mkdir buildcd buildcmake ..make -j$(nproc)sudo make install（非必须）安装 qt5，这样 OpenCV 将会和 Qt 一同编译：sudo apt install qt5-default qtcreator（虚拟机安装不了）CUDA：教程将会另外发布。当然还有一些其他的 Ubuntu 配置，比如中文输入法等，有需要的话自己查资料配置。这里提一下，如果你以后希望使用 JetBrain 全家桶（e.g. Clion、Pycharm）的话，那么请不要安装搜狗输入法，会导致程序异常退出。另外，搜狗输入法也不支持 Ubuntu 20.04 ，请安装 fcitx 下的 Google 输入法。编译阶段在安装了所需的依赖后，我们终于可以编译 OpenCV 了。先从 GitHub 下载最新版的 OpenCV 和 OpenCV_contrib ，点击下图红框，选择下拉按钮 master -&amp;gt; Tags -&amp;gt;4.5.3 。然后点击右侧绿色按钮 Code，如果你打算选择最新的版本，直接复制地址，如果你选择了特定的版本，那么点击 Download ZIP ，解压至之后的 Applications 文件夹下。在 Ubuntu 中打开终端（Terminal），输入以下命令：cd ~mkdir Applicationscd Applications# 以下命令针对复制网址下载的git clone &amp;lt;path/of/opencv&amp;gt;git clone &amp;lt;path/of/opencv_contrib&amp;gt;将 opencv_contrib 目录移动到 opencv 目录中，以下使用 &amp;lt;opencv&amp;gt; 和 &amp;lt;opencv_contrib&amp;gt; 分别代表着两个文件夹名，根据实际情况带入修改：cd ~/Applications/&amp;lt;opencv&amp;gt;mkdir build最终应该如下图：接下来借助 cmake-gui 编译，打开终端输入：cmake-gui在出现的界面中，点击 Browse Source 选择源文件目录 opencv ，点击 Browse Build 选择编译文件存放目录 build ，然后点击 Configure 。会跳出一个弹窗，下拉框中选择 Unix Makefiles ，然后点击 Finish 。完成后界面如下：然后我们需要修改两个地方： 通过 search 找到 CMAKE_BUILD_TYPE 处，输入 Release 。 在 OPENCV_EXTRA_MODULES_PATH 处加入 opencv_contrib 模块路径。注意，不是选 opencv_contrib 文件夹，而是需要选中 opencv_contrib 里面的 modules 文件夹！ 这里说明一下，CMAKE_INSTALL_PREFIX 为安装路径，系统默认为 /usr/local ，如若对 Ubuntu 不熟悉，则不要更改，默认就好。确认无误后，点击 Configure ；先排除四个常见的问题： ade* 无法下载：手动下载（链接: https://pan.baidu.com/s/1oVUeBL6cbxeczRAd22-CHw 提取码: j2v7），存放在 Downloads 文件夹里，打开 &amp;lt;opencv&amp;gt;/modules/gapi/cmake/DownloadADE.cmake ，把第 10 行更换成自己下载的文件目录路径，例如 /home/&amp;lt;username&amp;gt;/Downloads/ ，其中 &amp;lt;username&amp;gt; 代表你的用户名。重新 Configure 。 ippicv_* 无法下载：手动下载（链接: https://pan.baidu.com/s/1g6gZ8CrvdE9VWGmp8XmDyw 提取码: hbor），存放在 Downloads 文件夹里，打开 &amp;lt;opencv&amp;gt;/3rdparty/ippicv/ippcv.cmake ，把 42 行路径更换成自己的下载的文件目录路径，例如 /home/&amp;lt;username&amp;gt;/Downloads/ ，其中 &amp;lt;username&amp;gt; 代表你的用户名。重新 Configure 。 face_landmark_model.dat 无法下载：手动下载（链接: https://pan.baidu.com/s/1DKkQTfAY-F91r9vZ6qPUYw 提取码: pe82），存放在 Downloads 文件夹里，打开相应的配置文件 &amp;lt;opencv&amp;gt;/&amp;lt;opencv_contrib&amp;gt;/modules/face/CMakeLists.txt ，将 CMakeLists.txt 文件的第 19 行修改为本地路径，即将原来的网址修改为下载的文件保存的路径，&quot;/home/&amp;lt;username&amp;gt;/Downloads/&quot; ，其中 &amp;lt;username&amp;gt; 代表你的用户名。重新 Configure 。 boostdesc_*.i 、 vgg_generated_*.i ：手动下载（链接: https://pan.baidu.com/s/1VCdMUUm2ipu-fbL2189lFg 提取码: 88eo），存放在 &amp;lt;opencv&amp;gt;/&amp;lt;opencv_contrib&amp;gt;/modules/xfeatures2d/src/ 路径下即可，无需修改文件。 显示 Configuring done 后（注意上翻看看有没有红色的报错，因为即使报错也是会显示 Configuring done 的，当然以上这些报错你不解决其实不会影响多少），点击 Generate 生成文件；这时资源文件就出现在 build 文件夹中，我们可以关闭 cmake 界面了。在 &amp;lt;opencv&amp;gt;/build 中打开终端，输入：make -j$(nproc)此步骤将花费较长时间，尤其是开启 CUDA 选项时。完成后，输入：sudo make install至此 OpenCV 已经完成安装了，你可以删除 &amp;lt;opencv&amp;gt; 整个文件夹。四、IDE 安装从事项目开发，一款得心应手的 IDE 是必不可缺的。笔者目前使用下来有两款 IDE 比较好用： Clion 胜在集成功能全面，配置方便，几乎不用配置任何调试环境就能使用 安装方式：Jetbrain 全家桶对于高校学生免费开放，你可以进入官网申请。选择 For students and teachers 下的 learn more ，用自己的学校邮箱申请，然后打开邮箱内的确认邮件。然后创建自己的 JetBrains Account ，在软件安装完之后的 activate 过程中输入账号密码就可以使用了。 VScode 胜在插件多，支持自定义，适合编程熟练的老手或追求自定义效果的用户，但需另外为项目配置 C++ 调试环境。 安装方式：进入官网下载， Clion 环境配置初次进入 Clion ，需要配置 Toolchains ，创建一个新项目会出现以下弹窗，一般系统会自动检测 cmake 路径，如果没有那么手动选择以下，其余的会自动检测的。如果没有跳出以上弹窗，那么点击左上角 CLion -&amp;gt; Settings 或 Preferences -&amp;gt; Build, Execution, Deployment -&amp;gt; Toolchains ，配置 Default 。VScode 环境配置前往 Ubuntu Software 下载 Visual Studio Code ，然后打开界面如下：点击图中红色区域的按，进入 Extensions ，分别搜索安装以下三个插件：安装完毕后，在任意位置创建一个空目录。VScode 不支持单文件编译，必须具有项目目录。创建完毕后，用 VScode 打开项目目录，点击 Shift+Ctrl+P （Ubuntu 版本快捷键），搜索 cmake:configure ：对每个项目首次进入时，会提示选择工具包，这里我们选择 GCC：在左侧可以先建文件，使用以下示例代码测试。以后每次编译项目，只需要简单地右击 CMakeLists.txt ，选择 Build All Projects ：编译完成后，点击下方 Terminal ，输入以下命令运行程序：cd build./&amp;lt;name/of/binary_file&amp;gt; # 一般与项目同名五、示例代码点击下载，链接: https://pan.baidu.com/s/1nCnebXdNe1XW4e1xzbrXOA 提取码: 80dc。最终运行程序应该出现一张图片显示.apple.png 的窗口。恭喜你安装成功！如果觉得本教程不错或对您有用，请前往项目地址 https://github.com/Harry-hhj/Harry-hhj.github.io 点击 Star :) ，这将是对我的肯定和鼓励，谢谢！六、参考教程 OpenCV学习笔记（一） OpenCV简介及安装 VSCode + CMake搭建C/C++开发环境（MacOS篇）作者：Harry-hhj，github主页：传送门" }, { "title": "PyTorch Basics", "url": "/posts/PyTorch-Basics/", "categories": "Tutorial, PyTorch", "tags": "getting started, computer science, pytorch", "date": "2021-08-29 11:12:00 +0800", "snippet": "PyTorch - BasicsPyTorch 是什么Torch 是一个有大量机器学习算法支持的科学计算框架，是一个与 Numpy 类似的张量 Tensor 操作库。PyTorch 是一个基于 Torch 的 Python 开源机器学习库，用于自然语言处理等应用程序。优点： 作为 Numpy 的替代品，可以使用 GPU 的强大计算能力 提供最大的灵活性和高速的深度学习研究平台缺点： 全面性：目前 PyTorch 还不支持快速傅里叶、沿维翻转张量和检查无穷与非数值张量 性能：针对移动端、嵌入式部署以及高性能服务器端的部署其性能表现有待提升 文档：社区还没有那么强大，其 C 库大多数没有文档环境搭建Miniconda3 + PyTorch首先去 Miniconda 官网下载对应系统和 Python 版本的安装包，打开终端运行脚本，按照指令完成 conda 环境搭建。然后前往 PyTorch 官网，按照需求选择，其中 Language 选择 Python ，Compute Platform 根据自己的硬件选择，有 Nvidia GPU 的选择 CUDA 版，有 AMD GPU 的选择 ROC 版（还需另外安装 ROC 环境），不需要或者没有 GPU 的选择 CPU 版。注意 MacOS 系统只能安装 CPU 版。复制命令并在命令行执行即可安装。预备知识TensorTensors （张量），与 Numpy 中的 ndarrays 类似，但是在 PyTorch 中 Tensors 可以使用 GPU 进行计算。在讨论其语法之前，先来说说什么是张量。 标量：一个单独的数 向量：一列有序排列的数，通过次序中的索引可以确定一个数 矩阵：二维数组，每个元素被两个索引唯一确定 张量：几何代数中定义的张量是基于向量和矩阵的推广，通俗一点理解的话，标量是零阶张量，矢量是一阶张量，矩阵是二阶张量举个例子，对于任意一张彩色照片，可以表示成一个三阶张量，三个维度分别是图片的高度、宽度和 RGB 通道。下图是一个白色图片的示例：我们继续将这一例子拓展：即：我们可以用四阶张量表示一个包含多张图片的数据集，这四个维度分别是：图片在数据集中的编号，图片高度、宽度，以及 RGB 通道。这种数据表示形式在计算机视觉中非常常见，你可以在这里先有个印象。张量在深度学习中是一个很重要的概念，因为它是一个深度学习框架中的一个核心组件，后续的所有运算和优化算法几乎都是基于张量进行的。常用操作：import torch# 创建一个未初始化的 Tensorx = torch.empty(5, 3)# 创建一个随机初始化的 Tensorx = torch.rand(5, 3) # torch.rand(*sizes, out=None)-&amp;gt;Tensor: [0, 1) 均匀分布x = torch.randn(5, 3) # torch.randn(*sizes, out=None)-&amp;gt;Tensor: 标准正态分布（均值为 0 ，方差为 1 ，即高斯白噪声）x = torch.randint(1, 4, (2, 3, 2)) # torch.randint(low = 0, high, size, out=None, dtype=None)-&amp;gt;Tensor: 整数范围 [low, high)x = torch.randperm(3) # torch.randperm(n, out=None, dtpe=torch.int64)-&amp;gt;LongTensor: 1 到 n 这些数的一个随机序列# 创建 Tensor 并使用现有数据初始化x = torch([5.5, 3])# 其他特殊的创建 Tensor 的方法x = torch.zeros(5, 3, dtype=torch.long) # 全 0 x = torch.ones(5, 3, dtype=torch.double) # 全 1 x = torch.eye(5, 3) # 对角线为 1 x = torch.arange(2, 10, 2) # torch.arange(s, e, step)-&amp;gt;Tensor: 从 s 到 e ，步长为 step x = torch.linspace(2, 10, 3) # torch.linspace(s, e, step)-&amp;gt;Tensor: 从 s 到 e ，均匀切分成 steps 份x = torch.normal(0, 3, (5, 3)) # torch.normal(mean:float, std:float, size:tuple)-&amp;gt;Tensor: 均值为 mean ，方差为 std ，大小为 size x = torch.Tensor(5, 3).uniform_(-1, 1) # 均匀分布 [from, to)# new_* 方法来创建对象x = torch.new_ones(5, 3, dtype=torch.double)# 根据现有的张量创建张量，重用输入张量的属性，例如 dtype ，除非设置新的值进行覆盖x = torch.randn_like(x, dtype=torch.float) # 覆盖 dtype ，但 size 相同# 获取 sizex.size() # torch.Size 返回值是 tuple 类型, 所以它支持 tuple 类型的所有操作运算# 加法x = torch.rand(5, 3)y = torch.rand(5, 3)# Method 1z = x + y# Method 2z = torch.add(x, y)# Method 3z = torch.empty(5, 3)torch.add(x, y, out=z) # 提供输出tensor作为参数# Method 4y.add_(x) # 会改变原变量的值# 索引x[:, 1] # 与 Numpy 索引方式相同x = torch.randn(5, 3).index_select(0, torch.linspace(0, 4, 2, dtype=torch.int32)) # .index_select(dim:int, index:Tensor(int32/64))-&amp;gt;Tensor: 从 dim 维选取 index 的数据x = x.masked_select(x&amp;gt;0) # .masked_select(mask)-&amp;gt;Tensor: 选取掩膜为 1 处的元素，不保留原始位置信息x = x.nonzero() # 返回非零元素的下标# torch.gather(input, dim, index:torch.long, out=None)-&amp;gt;Tensor：根据index，在dim维度上选取数据# out[i][j][k]...[i+dim]...[z] = input[i][j][k]...[index[i][j][k]...[z]]_{i+dim}...[z]t = torch.Tensor([[1,2],[3,4]])torch.gather(t, 1, torch.LongTensor([[0,0],[1,0]])) # [[1 1] [4 3]] # index 中元素范围 [0, n_dim-1]，用来指定第 dim 维的选取的位置# 关于 torch.gather 的更多用法请参考教程：https://zhuanlan.zhihu.com/p/352877584# 改变张量的维度和大小x = torch.randn(4, 4)y = x.view(16) # x 和 y 共享数据z = x.view(-1, 8) # size：-1 从其他维度推断# x = x.squeeze()unsqueeze()注意： 任何以 _ 结尾的操作都会用结果替换原变量。例如：x.copy_(y) ， x.t_() ，都会改变 x 。 view() 返回的新 Tensor 与原 Tensor 虽然可能有不同的 size ，但是是共享 data 的（ view 仅仅是改变了对这个张量的观察角度，内部数据并未改变）。如果需要副本先使用 .clone() 。Python 数据类型转换如果你有只有一个元素的张量，使用 .item() 来得到 Python 数据类型的数值。x = torch.randn(1)print(x.item())Numpy 转换将一个 Torch Tensor 转换为 NumPy 数组是一件轻松的事，反之亦然。Torch Tensor 与 NumPy 数组共享底层内存地址，修改一个会导致另一个的变化。# Torch Tensor -&amp;gt; NumPy数组a = torch.ones(5)b = a.numpy()a.add_(1) # 此时 b 发生变化# NumPy Array -&amp;gt; Torch Tensora = np.ones(5)b = torch.from_numpy(a)np.add(a, 1, out=a) # 此时 a 发生变化Broadcasting当对两个形状不同的 Tensor 按元素运算时，可能会触发广播（broadcasting）机制：先适当复制元素使这两个 Tensor 形状相同后再按元素运算。x = torch.arange(1, 3).view(1, 2)y = torch.arange(1, 4).view(3, 1)z = x + y # torch.Size([3, 2])CUDA使用 .to 方法 可以将 Tensor 移动到任何设备中。# is_available 函数判断是否有 cuda 可以使用# `torch.device` 将张量移动到指定的设备中if torch.cuda.is_available(): device = torch.device(&quot;cuda&quot;) # 一个 CUDA 设备对象 y = torch.ones_like(x, device=device) # 直接从 GPU 创建张量 x = x.to(device) # 或者直接使用 `.to(&quot;cuda&quot;)` 将张量移动到 cuda 中 z = x + y print(z) print(z.to(&quot;cpu&quot;, torch.double)) # `.to` 也会对变量的类型做更改更多内容，请查看官网教程。Autograd：自动求导机制PyTorch 中所有神经网络的核心是 autograd 包，它为张量上的所有操作提供了自动求导。 它是一个在运行时定义的框架，这意味着反向传播是根据你的代码来确定如何运行，并且每次迭代可以是不同的。在自动求导计算中有两个重要的类： Tensor 如果设置 .requires_grad 为 True，那么将会追踪所有对于该张量的操作。当完成计算后通过调用 .backward()，自动计算所有的梯度，这个张量的所有梯度将会自动积累到 .grad 属性。 为了防止跟踪历史记录（和使用内存），可以将代码块包装在 with torch.no_grad(): 中。 这在评估模型时特别有用，因为模型可能具有 requires_grad = True 的可训练参数，但是我们不需要梯度计算。 Function Tensor 和 Function 互相连接并生成一个非循环图，它表示和存储了完整的计算历史。 每个张量都有一个 .grad_fn 属性，这个属性引用了一个创建了 Tensor 的 Function ，即该 Tensor 是不是通过某些运算得到的，若是，则 grad_fn 返回一个与这些运算相关的对象（除非这个张量是用户手动创建的，即，这个张量的 grad_fn 是 None ）。 如果需要计算导数，你可以在 Tensor 上调用 .backward() 。 如果 Tensor 是一个标量（即它包含一个元素数据）则不需要为 backward() 指定任何参数， 但是如果它有更多的元素，你需要指定一个 gradient 参数来匹配张量的形状。 注意：在其他的文章中你可能会看到说将 Tensor 包裹到 Variable 中提供自动梯度计算， Variable 这个在 0.41 版中已经被标注为过期了，现在可以直接使用 Tensor ，官方文档在这里。requires_gradx = torch.ones(2, 2, requires_grad=True) # x.grad_fn = Noney = x + 2 # y.grad_fn = &amp;lt;AddBackward0 object at 0x...&amp;gt;z = y * y * 3 # z.grad_fn = &amp;lt;MulBackward0 object at 0x...&amp;gt;out = z.mean() # out.grad_fn = &amp;lt;MeanBackward0 object at 0x...&amp;gt;x 是直接创建的，所以么有 grad_fn ， y 作为操作的结果被创建，因此具有 grad_fn 。像 x 这样的节点被称为叶子节点，叶子节点对应的 grad_fn 是 None 。输入的 requires_grad 在没有给定参数的情况下默认是 False ，可以通过 requires_grad_() 来改变张量的 requires_grad 属性。如果输入的 requires_grad 是 False ，那么之后所有计算结果的变量的 requires_grad 属性都将是 False ，且 grad_fn 为 None。backward()在调用 y.backward() 时，如果 y 是标量，则不需要为 backward() 传入任何参数；否则，需要传入一个与 y 同形的 Tensor 。因为不允许张量对张量求导，只允许标量对张量求导，求导结果是和自变量同形的张量。在数学上，如果我们有向量值函数 $\\vec y = f(\\vec x)$，且 $\\vec y$ 关于 $\\vec x$ 的梯度是一个雅可比矩阵（Jacobian matrix）：\\(J = \\begin{pmatrix}\\frac{\\partial y_1}{\\partial x_1}&amp;amp;\\cdots&amp;amp;\\frac{\\partial y_1}{\\partial x_n}\\\\\\vdots&amp;amp;\\ddots&amp;amp;\\vdots\\\\\\frac{\\partial y_m}{\\partial x_1}&amp;amp;\\cdots&amp;amp;\\frac{\\partial y_m}{\\partial x_n}\\\\\\end{pmatrix}\\)一般来说，torch.autograd 就是用来计算 vector-Jacobian product 的工具。也就是说，给定任一向量 $\\vec v = (v_1\\ v_2\\ \\cdots\\ v_m)^T$ ，计算 $v^T \\cdot J$ 。如果 $v$ 恰好是标量函数 $l = g(\\vec y)$ 的梯度，也就是说 $v = (\\frac{\\partial l}{y_1}\\ \\cdots \\frac{\\partial l}{y_m})^T$ ，那么根据链式法则，vector-Jacobian product 是 $l$ 关于 $\\vec x$ 的梯度：\\(J^T \\cdot v = \\begin{pmatrix}\\frac{\\partial y_1}{\\partial x_1}&amp;amp;\\cdots&amp;amp;\\frac{\\partial y_1}{\\partial x_n}\\\\\\vdots&amp;amp;\\ddots&amp;amp;\\vdots\\\\\\frac{\\partial y_m}{\\partial x_1}&amp;amp;\\cdots&amp;amp;\\frac{\\partial y_m}{\\partial x_n}\\\\\\end{pmatrix}\\begin{pmatrix}\\frac{\\partial l}{\\partial x_1}\\\\\\vdots\\\\\\frac{\\partial l}{\\partial x_n}\\\\\\end{pmatrix}\\)（注意，$v^T \\cdot J$ 给出了一个行向量，可以通过 $J^T \\cdot v$ 将其视为列向量）vector-Jacobian product 这种特性使得将外部梯度返回到具有非标量输出的模型变得非常方便。以下是两个例子： 标量求导 x = torch.ones(2, 2, requires_grad=True)y = x + 2z = y * y * 3out = z.mean()out.backward() # 因为 out 是一个纯量（scalar），out.backward() 等于 out.backward(torch.tensor(1))print(x.grad) # tensor([[4.5000, 4.5000], [4.5000, 4.5000]]) 非标量求导 x = torch.randn(3, requires_grad=True)y = x * 2while y.data.norm() &amp;lt; 1000: y = y * 2gradients = torch.tensor([0.1, 1.0, 0.0001], dtype=torch.float)y.backward(gradients)print(x.grad) 在这个情形中，y 不再是个标量， torch.autograd 无法直接计算出完整的雅可比矩阵，但是如果我们只想要 vector-Jacobian product ，只需将向量作为参数传入 backward 。 中断梯度追踪with torch.no_grad(): 中的变量将不进入梯度计算。直接举个例子说明：x = torch.tensor(1.0, requires_grad=True)print(x, x.requires_grad)y1 = x ** 2print(y1, y1.requires_grad)with torch.no_grad(): y2 = x**2print(y2, y2.requires_grad)y3 = y1 + y2print(y3, y3.requires_grad)y3.backward()print(x.grad) # tensor(2.)此时 y3 的梯度经由 y1 （与 y2 无关）传播给 x ，因此 x 的梯度是 2 而不是 4 。tensor.data此外，如果我们想要修改 tensor 的数值，但是又不希望被 autograd 记录（即不会影响反向传播），那么我么可以对 tensor.data 进行操作。x = torch.tensor(1.0, requires_grad=True)print(x.data) # 依然是一个 tensorprint(x.data.requires_grad) # False，即独立于计算图之外y = 2 * xx.data *= 100 # 只改变了值，不会记录在计算图，所以不会影响梯度传播y.backward()print(x)print(x.grad)如果对 x 本身直接操作，将导致 x 叶子节点身份的丢失。更多内容，请查看官网教程。如果觉得本教程不错或对您有用，请前往项目地址 https://github.com/Harry-hhj/Harry-hhj.github.io 点击 Star :) ，这将是对我的肯定和鼓励，谢谢！参考文档 标量，向量，矩阵与张量 torch.rand()、torch.randn()、torch.randint()、torch.randperm()用法 我对torch中的gather函数的一点理解 pytorch简介和准备知识作者：Harry-hhj，github主页：传送门" }, { "title": "Install dual-OS - Win10", "url": "/posts/Install-dual-OS_Win10/", "categories": "Tutorial, Dual OS", "tags": "install, os, win", "date": "2021-08-26 16:40:00 +0800", "snippet": "安装 Win10 双系统 本篇教程是基于 MacOS 系统安装 Win10 双系统的，当然也适用于 Win10 安装 Win10 双系统，如果你愿意的话，只需要去除和 MacOS 有关的特定内容就可以了。硬件要求： Macbook pro 2019（只要不是2015年前的苹果电脑应该都可以） Windows 虚拟机或主机（我使用的是虚拟机） 一块硬盘，至少 64 GB，接口 USB 3.0 及以上（机械硬盘或者 SSD ，推荐 SSD ，笔者使用的是 SamsumgSSD9801TB ） 外接 USB 鼠标和外接 USB 键盘，外接 USB 无线网卡（可选） 一个U盘或机械硬盘（ exFAT 格式），至少 1.5 TB ，也可以放在 SSD 的非系统分区中 电脑供电电源（过程非常耗电，请插电源操作） USB-C 拓展坞（可选，根据接口需要）软件要求： 启动转换助理（苹果系统自带） WTG 辅助工具（附件1） Windows 10 镜像（附件1）为了便于区分两个 Win 系统，以下将用于制作系统盘的 Windows 系统称作宿主系统，将新制作的 Windows 系统称作目标系统。前言Macbook pro 的存储空间是非常宝贵的，因为苹果的硬盘速度虽然高，价格也非常贵。而且，我也很不喜欢装个系统把硬盘弄糟，甚至把 Mac 系统弄坏，毕竟 Mac OS 才是我日常生活的主力。在经历了两年的虚拟机之后，我终于下决心试试装双系统了。备注：每次用 DiskGenius 操作分区后都需要右击左侧磁盘选择保存分区表，推荐对所有硬盘如此操作。科普机械硬盘和固态硬盘（SSD）和 U 盘机械硬盘和固态硬盘本质不同：机械硬盘本质是电磁存储，固态则是半导体存储。防震抗摔性不同：机械硬盘很怕摔，固态抗震。数据存储速度不同：固态读写速度比机械快。功耗不同：固态硬盘的功耗比机械硬盘低。重量不同：固态硬盘的重量比机械硬盘轻。噪音不同：机械硬盘有噪音，固态硬盘没有噪音。移动硬盘和U盘SSD 硬盘与 U 盘都采用了 Flash （闪存）作为储存介质，他们的区别如下：SSD 采用 SATA 接口主控，而绝大部分优盘采用 USB 接口主控。由于 U 盘和固态硬盘之间所使用的主控芯片、 Flash 颗粒的数量和缓存容量不同造成二者存储速度存在巨大差异。固态硬盘采用了多颗 Flash 颗粒组成，而其内部也是采用了类似于 RAID 的写入方式，可同时在不同的颗粒上写入或者读取数据。而U盘通常就是单通道的写入，所以在性能上完全没有办法和固态硬盘相提并论。U盘和固态硬盘所使用的Flash都有一定的写入次数寿命。一旦当写入次数达到这个数量之后，那么就无法再写入数据了，也就意味着U盘或者固态硬盘的损坏。SSD （固态硬盘）据的主控芯片均具备了一种平均写入数据的算法，以延长使用寿命。而 U 盘就是不具备平均写入数据功能，所以一旦 U 盘用来反复读写数据话，是非常容易造成损坏的。容量与价格不同。文件系统FAT32这一种格式是任何USB存储设备都会预装的文件系统，属 Windows 平台的传统文件格式，兼容性很好。即便 FAT32 格式兼容性好，但它不支持 4 GB 以上的文件，因此对于很多镜像文件或大视频文件之类的也会有无可奈何的状况。NTFSNTFS 格式却是 Windows 平台应用最广泛的文件格式，它的优点在于能够支持大容量文件和超大分区，且集合了很多高级的技术，其中包括长文件名、压缩分区、数据保护和恢复等等的功能。但它会减短闪存的寿命。exFATexFAT 格式才是最适合 U 盘的文件格式，它是微软为了闪存设备特地设计的文件系统，是 U 盘等移动设备最好的选择之一。SSD 和 U 盘同为闪存，但SSD还是用NTFS格式为好！好了，下面正式进入教程。准备工作 - WindowsSupportMacbook 的硬件在 Windows 上是不能直接使用的，因此需要获得相应的驱动程序，这个苹果系统已经有现成的了，我们下载就行。在苹果系统中打开“启动转换助理”，如下图：打开后在左上角点击操作-下载Windows支持软件，下载完毕后，将文件转存到一个 U 盘或机械硬盘上备用（注意容量，未压缩约为 1.26 GB ），以便后续文件传输。然后将待用的硬盘（SSD）全盘格式化为 exFAT 格式，不要含有多个分区，供后续使用。Windows镜像文件网上有很多，如果你是交大学生，附件1SW_DVD5_Win_Pro_Ent_Edu_N_10_1803_64BIT_ChnSimp_-2_MLF_X21-79700 中也包含了，可通过交大网络激活。激活方式：需要连接校园网或 VPN ，用管理员身份打开命令提示符（右击选择以管理员身份运行），进入 C:\\Windows\\System32 文件夹中，输入以下命令：cscript slmgr.vbs /skms kms.sjtu.edu.cncscript slmgr.vbs /ato激活成功。WinToGo 辅助工具将上述的 Windows 镜像文件复制到宿主系统（虚拟机）中，双击打开，这时系统会显示有个 DVD 驱动器，此时先不要操作。使用附件1中的 wtga5590 ，双击 exe 文件，注意网上 4.8 版本的 wtga 不能选择 windows 版本，所以不要使用。打开软件后，第一个候选框选择上图中的 DVD驱动器/sousrces/install.wim 。然后选择版本为 企业版 ，最后选择你的硬盘。右侧高级选项选择 传统 + UEFI+GPT ，其他可以选择默认。最后选择 部署 。需要分区的朋友可以在 分区 里进行设置，需要注意给系统盘留出足够的空间。也可以按之后的教程进行操作。会弹出一个窗口提示你整个硬盘会被格式化，让你确认，点击 是 即可。耐心等待制作完成。关闭安全选项在 MacOS 系统启动时，同时安装 Command + R ，进入到恢复助理的界面，选择知道密码的用户，输入密码后选择左上角的 实用工具 ，选择里面的 允许从外部介质启动 。同时将安全启动那里选择 无安全性 。不然可能会出现以下的错误：安装驱动关机，在开机时按住 option 键，选择 EFI 启动磁盘，然后就进入了 Windows 的启动界面，注意 第一次进入会自动重启，所以在重启时还需要按住 option 键。然后就像正常的 Windows 一样初始化就行了，唯一要注意的是此时 Mac 里自带的网卡、键盘和触控板统统不能使用，需要外接 USB 设备，这就是要准备 USB 鼠标键盘和无线网卡的原因。设置好后进入Win10 桌面，这时候鼠标键盘等依旧不能使用需要安装之前下载好的 Windows支持软件 。找到你U盘里复制过来的支持软件，打开文件夹找到 setup.exe ，双击打开安装 BootCamp 驱动。安装完后，如果遇到没有声音，使用搜索栏搜索 Apple Software Update，更新后应该能解决问题，再不行就多安装几次，再不行点击带❌的音量，自动搜索驱动、重启等，应该是能解决的。安装完驱动后成后已经可以正常使用键盘、鼠标、网卡等等。但是你可能发现无法自定义设置键盘背光、触控板功能等，这是因为 BootCamp 锁定了外置磁盘的控制面板设置。这时下载之前说过的 BootCamp 控制面板工具，名字为 AppleControlPanel.exe 。之后在目录 C:\\Windows\\System32 找到 AppleControlPanel.exe 这个文件，把它替换为之前下载的同名文件。这时候在进入 Boot Camp 控制面板就可以自定义设置触控板功能了。如果没有找到 Boot Camp 控制面板，就去 Mac 上重新下载 WindowsSupport 安装，就能解决。分区分卷如果硬盘过大时我们会希望将一部分硬盘分理出系统盘作为数据盘使用或留作他用，这是我们的操作如下： 首先在宿主系统中的搜索框输入此电脑，然后右键点击管理，如下图： 在新出现的窗口点击存储-&amp;gt;磁盘管理，找到目标磁盘（根据磁盘大小），右击选择压缩卷，将系统盘的容量压缩到你认为合适的大小，这里我预留了 350 GB （仅供参考）。 将多出来的空间右击选择新加卷，格式选 exFAT，即可。 在目标系统中进入同样的界面，重新删除卷，并新建卷，这么做的目的是为了分配盘符，不然会被隐藏，在目标系统中不可见。如果希望进行更细致的格式化可以使用附件1中的 DiskGenius 重新格式化，可以选择簇大小（对簇大小的理解就是：簇大小越大，读写速度越快，但小文件浪费的空间也更多，如果不知道直接选择默认就行）。如下图： （图中我留了 256GB 的未分配空间，操作的方法是使用 DiskGenius 对 DATA 盘新建分区，再通过磁盘管理来删除卷就行了。） 最终的结果如下图所示： 结果最终我的 Windows 界面如下：恭喜成功！如果觉得本教程不错或对您有用，请前往项目地址 https://github.com/Harry-hhj/Harry-hhj.github.io 点击 Star :) ，这将是对我的肯定和鼓励，谢谢！参考教程 为MacBook Pro制作WTG系统盘 在我的U盘上装了 win to go瞬间感觉相见恨晚（WTG安装最详细教程） ssd固态硬盘和U盘的区别是什么呢？ U盘FAT32、NTFS、exFAT格式的区别，你都知道么？如有问题欢迎来交流！作者：Harry-hhj，github主页：传送门 链接: https://pan.baidu.com/s/10wH1h5n9tHYNvo4rWq-7zA 提取码: nwcp &amp;#8617; &amp;#8617;2 &amp;#8617;3 &amp;#8617;4 &amp;#8617;5 " }, { "title": "Building your Blog too", "url": "/posts/Building-your-Blog/", "categories": "Tutorial, Jekyll", "tags": "install, jekyll", "date": "2021-08-24 08:00:00 +0800", "snippet": "按照本篇教程的步骤，搭建属于你自己的 jekyll-theme-chirpy 吧～（其他样式请按照相应的 README.md 进行操作）搭建 GitHub 博客第一步 安装环境按照 Jekyll Docs 官方教程完成环境的搭建，该教程是全英文教程，如果能看懂建议根据该教程操作（因为该教程会保持最新），遇到问题后再来参考本教程。如果对英文教程不熟悉的，可以使用 Chrome 浏览器打开后进行页面翻译。注意：官方教程中有些操作是在普通的句子中而非列表的形式给出，所以在查阅时无比认真阅读每一句话，不要跳句！Ubuntu安装 Ruby 和其他依赖：sudo apt install ruby-full build-essential zlib1g-dev将 gem 安装到当前用户下（不要以 root 用户安装），以下的命令将在 ~/.bashrc 中添加环境变量来指定 gem 的安装路径：echo &#39;# Install Ruby Gems to ~/gems&#39; &amp;gt;&amp;gt; ~/.bashrcecho &#39;export GEM_HOME=&quot;$HOME/gems&quot;&#39; &amp;gt;&amp;gt; ~/.bashrcecho &#39;export PATH=&quot;$HOME/gems/bin:$PATH&quot;&#39; &amp;gt;&amp;gt; ~/.bashrcsource ~/.bashrc查看 ruby 的版本： ruby -v ，确保其版本高于或等于 2.5.0 。最后，通过 gem 安装 jekyll 和 bundler ：gem install jekyll bundler查看 RubyGems 的版本： gem -v ，有版本输出代表安装成功。（可选）安装最新版本的 gcc 和 g++ 。首先添加 ppa 到库，这一步实际是添加了一个 ubuntu 的源：sudo add-apt-repository ppa:ubuntu-toolchain-r/testsudo apt-get update安装新版 gcc/g++ ，目前最新的版本号是 11 ：sudo apt install -y gcc-11 g++-11这里有个小技巧，加个参数 -y 表示不询问并同意，这样就不用在之后输入 y 确认了。查看 Ubuntu 原来的 gcc/g++ 版本，并记住（Ubuntu 20.04 默认应该是 9）：gcc -vg++ -v # 如果你的电脑安装了 g++ 的话默认情况下 Ubuntu 没有安装 g++ ，如果你希望 gcc/g++ 保持配对，可以通过 gcc -v 查看版本下载对应的 g++ 。我们需要将标准的 gcc/g++ 连接到我们期望的 gcc/g++ 程序，有两种连接方式建立连接： ln 命令创建软链接 cd /usr/binsudo rm gccsudo ln -s gcc-11 g++sudo rm g++sudo ln -s g++-11 g++ 通过 update-alternatives 建立文件关联 记住你刚刚查看到的原始版本号，以下命令中的 &amp;lt;版本号&amp;gt; 用下图中你查询到的数字替代： # 首先让系统知道我们安装了多个 gcc 版本sudo update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-&amp;lt;版本号&amp;gt; &amp;lt;版本号*10&amp;gt;sudo update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-11 110# 使用交互方式的命令选择默认使用的版本，默认使用 auto 选择模式，系统将默认使用优先级最高的，无需修改直接按回车（enter）：sudo update-alternatives --config gcc # g++ 同理sudo update-alternatives --install /usr/bin/g++ g++ /usr/bin/g++-&amp;lt;版本号&amp;gt; &amp;lt;版本号*10&amp;gt;sudo update-alternatives --install /usr/bin/g++ g++ /usr/bin/g++-11 110sudo update-alternatives --config g++ 如果不小心有个命令写错了，那么（没关系，我也因为偷懒使用历史命令修改的时候少改了地方错过）： # 如果是优先级写错了，重新 --install 就行了# 如果是把 g++ 装到了 gcc 里或其他类似情况，然后重新 --install 就可以了： sudo update-alternatives --remove &amp;lt;装错的链接名gcc或g++&amp;gt; &amp;lt;装错的路径&amp;gt; 切换 gcc/g++ 版本： sudo update-alternatives --config gccsudo update-alternatives --config g++ 第二步 克隆仓库有两种搭建方式，这里只介绍第二种，因为我们的目的就是为了借助 Github Page 来发布博客： 从 RubyGems 安装：易于更新，隔离不相关的项目文件，可以专注于编写。 从 GitHub 克隆：自定义开发方便，但更新难，只适合web开发者。首先前往原项目仓库，点击屏幕右侧的 fork 按钮：这样，我们的代码库里就有了一个相同的仓库，唯一不同的这个仓库的所有权属于我们自己。找到这个仓库并点击进入。点击 Code ，复制网址，然后打开 Terminal 进入项目目录， git clone &amp;lt;网址&amp;gt; ，如果还没有装过 git 先安装一下：sudo apt install git安装 gem 依赖：cd jekyll-theme-chirpybundle然后执行脚本：bash tools/init.sh 如果你不打算在 Github Pages 部署博客，那么在这个命令后加上参数 --no-gh .这一步所执行的操作是： 删除 .travis.yml 、_post 文件夹下的文件、docs 文档 如果使用了 --no-gh 参数，那么目录 .github 会被删除，否则 .github/workflows/pages-deploy.yml.hook 被删除 .hook 后缀，然后删除 .github 中的其他文件和目录 自动 commit 本次操作第三步 修改设置主要修改 _config.yml 中的变量，例如： url：如果你需要部署在 Github Pages 上，那么请一定将 url 设置为 https://&amp;lt;your-github-username&amp;gt;.github.io avatar：头像，可以使用本地图片，放在 assets/img/favicons/ 目录下，并把此处网址改为相对路径 timezone lang：按照 http://www.lingoes.net/en/translator/langcode.htm 上的缩写设置，中文为 zh修改完后，你可以现在本地预览效果，然后再决定是否保存更改并同步到远程仓库中：bundle exec jekyll s或者使用 Docker 运行网站：docker run -it --rm \\ --volume=&quot;$PWD:/srv/jekyll&quot; \\ -p 4000:4000 jekyll/jekyll \\ jekyll serve打开浏览器访问 http://localhost:4000 。第四步 Github Pages 部署请先务必确保 url 设置正确。首先重新命名 Github 上的远程仓库的名字，修改为 &amp;lt;your-github-username&amp;gt;.github.io （不要加尖括号）。然后重新关联本地项目和远程仓库：git remote set-url https://&amp;lt;your-token&amp;gt;.github.com/&amp;lt;...&amp;gt;.github.io.gitGitHub 目前已经不支持密码登陆。至于 GitHub token 的使用方法，请参考此教程。由于比较简单，这里就不细讲了。如果你对 token 不懂，那么就按照以下步骤操作，这是一种比较不安全的做法，不符合安全理念和最小权限原则：点击网页右上角头像，选择 Settings ，点击左侧 Developer settings ，点击左侧 Personal access tokens ，点击 generate new token ，选择相应的权限（最简单的方法全选，日期设为不限），把生成的 token 复制到上面的 your-token 中就行了。注意，此 token 只能看到一次，请妥善保管，可重复使用。设置完毕后通过 git push 将本地的修改提交到远程仓库，这将触发 GitHub Actions workflow ，一旦操作完成，会产生一个新的分支 gh-pages 。在网页上点击项目的 settings ，找到 Pages ，选择 gh-pages 分支作为 publishing source ，如下图：点击 Github 上的链接就可以访问你的博客啦！第五步 设置百度统计之所以不使用官方推荐的 Google Analysis ，是因为在国内大部分地区都没有办法直接访问，这种统计也就失效了。因此，我选择了更加简便的 Baidu Analysis 来代替，一样可以达到效果。首先前往百度统计注册一个账号，注册完成后新建一个网站。之后会要填写以下信息： 网站域名：&amp;lt;your/github/username&amp;gt;.github.io 网站首页：https://&amp;lt;your/github/username&amp;gt;.github.io 剩下的随便写完后会会自动跳转到获取代码（如何没有自己点击跳转），选择复制代码。接下来修改个人博客项目，需要修改三个地方： 修改 _config.yml ，在其中加入： baidu-analysis: &amp;lt;your-token&amp;gt; 其中 就是那段复制的代码中 ```hm.src = &quot;https://hm.baidu.com/hm.js?...&quot; 后的那串字符。``` 在 _includes 目录下新建 baidu-analysis.html 文件，在其中输入： &amp;lt;!-- The BA snippet--&amp;gt;&amp;lt;script&amp;gt;var _hmt = _hmt || [];(function() { var hm = document.createElement(&quot;script&quot;); hm.src = &quot;https://hm.baidu.com/hm.js?f40851b91841f1abe810a63f8d41c2e2&quot;; var s = document.getElementsByTagName(&quot;script&quot;)[0]; s.parentNode.insertBefore(hm, s);})();&amp;lt;/script&amp;gt; 这里无需修改，直接复制即可。 在页头模版页面中安装百度统计，这里我选择了 head.html ，实际查看代码我发现 Google Analysis 是放在 js-selector.html 中的，但是该部分属于 body 而百度统计官方建议放入 head ，因此在 head.html 最后的 &amp;lt;/head&amp;gt; 前加入以下代码： &amp;lt;!-- BA --&amp;gt; &amp;lt;!-- The BA snippet--&amp;gt;&amp;lt;script&amp;gt;var _hmt = _hmt || [];(function() { var hm = document.createElement(&quot;script&quot;); hm.src = &quot;https://hm.baidu.com/hm.js?f40851b91841f1abe810a63f8d41c2e2&quot;; var s = document.getElementsByTagName(&quot;script&quot;)[0]; s.parentNode.insertBefore(hm, s);})();&amp;lt;/script&amp;gt; 如果你对代码整洁度有很高的要求（其实我就算是，只是配置更新太慢了就算了），你可以尝试在 js-selector.html 中的最后一个 if 语句块中加入以上代码。 至此就完成网站统计的配置了，由于更新 _config.yml 体现在网站上的时间比较久，因此需要耐心等待，笔者等了一个晚上。去百度统计点击首页代码状态检查，如果显示 代码安装正确 ，那么恭喜你，你可以查看你的个人博客的访问情况了。如果本篇教程中有任何不对的地方，欢迎联系我指正！（评论功能可能尚在开发中）如果觉得本教程不错或对您有用，请前往项目地址 https://github.com/Harry-hhj/Harry-hhj.github.io 点击 Star :) ，这将是对我的肯定和鼓励，谢谢！作者：Harry-hhj，github主页：传送门" }, { "title": "First Blog", "url": "/posts/First-Blog/", "categories": "Essay", "tags": "feelings, diary", "date": "2021-08-23 20:30:00 +0800", "snippet": "随笔第一篇博客，不讲技术，先来说说自己为什么要折腾这么一个博客，为了在以后的日子里都能回想起初心，然后好坚持下去。前几天凉快了一阵子，这两天又热了起来。没打算开空调，但这温度多少会让人有些烦躁。今早刚交了简历，想着闲来没事，哦其实也不是闲，就是想放松一下，就开始捣鼓起来。先是装了个 Ubuntu 20.04 的虚拟机，想着之前一直用的是 18.04 ，今天也体验个新鲜。装完觉得这有些简陋，或许是用惯了 Macbook 的缘故，就开始美化起桌面来。弄了小半个上午，总算是弄好了，花的时间也不是很多，弄完也没什么特别的成就感，只是觉得还算不错，但也有些设计不合理的地方。算了，既然是别人写的东西，能用就很不错了，那还有什么怨言呢。虚拟机确实很方便，但不如装个真正的系统让人觉得安心、有份量，前几天也尝试过好多次，一直没成功，想着先歇一歇，等哪天又有了三分钟的热情，在 2 分 59 秒里去把它搞定，暂且以后再说。下午弄得差不多了，突然脑子里想着弄个个人博客，原因？没什么原因，甚至连用来干什么都还没想好，或许是最近写了几篇教程的缘故，又头脑发热了。大腿一拍，说干就干。前些天也搜过一堆模版，比来比去觉得这个模版顺眼，功能也挺符合需求，就用这个了。以前有个前辈（论辈分算是同辈，他对我影响挺大的，有时间可以安排一个访谈）也搭过一个，我也用过，感觉应该不是很麻烦，谁知道这个想法，坑了我一个下午。其实官方教程一个字也没写错，但我总是能很好地漏掉字里行间里的隐藏操作。仓库重新建了四五次，每次都觉得要成，左看右看从页面里看出个 404 。把每句话耐心看完，一试，诶成了。小小的事情蕴涵着多少教训，多少人因为一个冲动带来了长久的生活影响，多少人曾被另一个或一群人影响着，多少人曾因高估自己而吃了苦头，多少人还能有一份平静做自己想做的事，哪怕没有人逼着催着，又有多少成功，就是那么一个不经意而已。博客搭好了，这是它最开始的样子：还算不错。但我也知道，它只是这样了，因为我没有能力去修改它，至少暂时没有。很多的项目，我拿来，会用，但不会改，却满足得不得了。这就是我创建这个博客的原因吧，督促自己有自己的东西，逼迫自己学习新的知识，然后竭尽所能地把它说明白，首先做一个自己的老师。我正渴望着吸收更多的知识，能够和更多的人侃侃而谈，能够被更多的人认可，能够有更大的价值。所以这个博客我不想放弃，也不能放弃。当然，除了技术分享，我还会在这里发些随笔、人生感悟，让自己的博客更加有特色些。如果有志同道合、兴趣相同的朋友，也欢迎交流、投稿，我会在每篇文章下注明作者和联系方式。有关格式规范，请查看本项目 README 文档。总之，我要开始新的旅途了。现在的社会就是这样：意识到自己倾尽全部也无法改变一些现实时会想躺平，但是却又不能心安理得地躺平，于是一直陷入焦虑、浮躁。我希望在这里的世界是豁达平静的，这是一个被精心打造的世界，每个人都能在这里收获独有的回忆，然后满载而归。如果觉得本博客不错或对您有用，请前往项目地址 https://github.com/Harry-hhj/Harry-hhj.github.io 点击 Star :) ，这将是对我的肯定和鼓励，谢谢！作者：Harry-hhj，github主页：传送门" }, { "title": "TODO", "url": "/posts/TODO/", "categories": "NoUse", "tags": "", "date": "2000-01-01 00:00:00 +0800", "snippet": "说明Oops！跳转至的该篇教程正在排队出炉中，抱歉！作者：Harry-hhj，github主页：传送门" } ]
